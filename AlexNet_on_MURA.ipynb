{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce300cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, Activation, BatchNormalization\n",
    "from tensorflow.keras.utils import plot_model,to_categorical\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33f0bec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImagePath</th>\n",
       "      <th>ImageSet</th>\n",
       "      <th>ImageType</th>\n",
       "      <th>Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00001/study...</td>\n",
       "      <td>train</td>\n",
       "      <td>XR_SHOULDER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00001/study...</td>\n",
       "      <td>train</td>\n",
       "      <td>XR_SHOULDER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00001/study...</td>\n",
       "      <td>train</td>\n",
       "      <td>XR_SHOULDER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00002/study...</td>\n",
       "      <td>train</td>\n",
       "      <td>XR_SHOULDER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00002/study...</td>\n",
       "      <td>train</td>\n",
       "      <td>XR_SHOULDER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40000</th>\n",
       "      <td>MURA-v1.1/valid/XR_FINGER/patient11967/study1_...</td>\n",
       "      <td>valid</td>\n",
       "      <td>XR_FINGER</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40001</th>\n",
       "      <td>MURA-v1.1/valid/XR_FINGER/patient11967/study1_...</td>\n",
       "      <td>valid</td>\n",
       "      <td>XR_FINGER</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40002</th>\n",
       "      <td>MURA-v1.1/valid/XR_FINGER/patient11738/study1_...</td>\n",
       "      <td>valid</td>\n",
       "      <td>XR_FINGER</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40003</th>\n",
       "      <td>MURA-v1.1/valid/XR_FINGER/patient11738/study1_...</td>\n",
       "      <td>valid</td>\n",
       "      <td>XR_FINGER</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40004</th>\n",
       "      <td>MURA-v1.1/valid/XR_FINGER/patient11738/study1_...</td>\n",
       "      <td>valid</td>\n",
       "      <td>XR_FINGER</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40005 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               ImagePath ImageSet  \\\n",
       "0      MURA-v1.1/train/XR_SHOULDER/patient00001/study...    train   \n",
       "1      MURA-v1.1/train/XR_SHOULDER/patient00001/study...    train   \n",
       "2      MURA-v1.1/train/XR_SHOULDER/patient00001/study...    train   \n",
       "3      MURA-v1.1/train/XR_SHOULDER/patient00002/study...    train   \n",
       "4      MURA-v1.1/train/XR_SHOULDER/patient00002/study...    train   \n",
       "...                                                  ...      ...   \n",
       "40000  MURA-v1.1/valid/XR_FINGER/patient11967/study1_...    valid   \n",
       "40001  MURA-v1.1/valid/XR_FINGER/patient11967/study1_...    valid   \n",
       "40002  MURA-v1.1/valid/XR_FINGER/patient11738/study1_...    valid   \n",
       "40003  MURA-v1.1/valid/XR_FINGER/patient11738/study1_...    valid   \n",
       "40004  MURA-v1.1/valid/XR_FINGER/patient11738/study1_...    valid   \n",
       "\n",
       "         ImageType Diagnosis  \n",
       "0      XR_SHOULDER         1  \n",
       "1      XR_SHOULDER         1  \n",
       "2      XR_SHOULDER         1  \n",
       "3      XR_SHOULDER         1  \n",
       "4      XR_SHOULDER         1  \n",
       "...            ...       ...  \n",
       "40000    XR_FINGER         0  \n",
       "40001    XR_FINGER         0  \n",
       "40002    XR_FINGER         0  \n",
       "40003    XR_FINGER         0  \n",
       "40004    XR_FINGER         0  \n",
       "\n",
       "[40005 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creation of DataFrame\n",
    "df_train = pd.read_csv(\"MURA-v1.1/train_image_paths.csv\", header=None)\n",
    "df_val = pd.read_csv(\"MURA-v1.1/valid_image_paths.csv\", header=None)\n",
    "df = pd.concat([df_train, df_val], axis=0, ignore_index = True)\n",
    "#Split image path\n",
    "imageSplit= df[0].str.split('/', n=5, expand=True)\n",
    "df['ImageSet'] = imageSplit[1]\n",
    "df['ImageType'] = imageSplit[2]\n",
    "df['Diagnosis'] = imageSplit[4].str.split('_', n=1, expand=True)[1]\n",
    "df = df.rename(columns={0: 'ImagePath'})\n",
    "#Change positives to 1s and Negatives to 0\n",
    "df.loc[df['Diagnosis'] == 'positive', 'Diagnosis'] = 1\n",
    "df.loc[df['Diagnosis'] == 'negative', 'Diagnosis'] = 0\n",
    "\n",
    "#Deletion of extra variables to free space\n",
    "del df_train, df_val, imageSplit\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44d384c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.loc[(df['ImageType'] == 'XR_SHOULDER') & (df['ImageSet'] == 'train')]\n",
    "\n",
    "train_imagePath = df_train['ImagePath'].to_list()\n",
    "train_labels = df_train['Diagnosis'].to_list()\n",
    "\n",
    "df_valid = df.loc[(df['ImageType'] == 'XR_SHOULDER') & (df['ImageSet'] == 'valid')]\n",
    "val_imagePath = df_valid['ImagePath'].to_list()\n",
    "val_labels = df_valid['Diagnosis'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75c1a3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images Converted to cv2\n",
      "Images Converted to cv2\n"
     ]
    }
   ],
   "source": [
    "def convertImage(imagePaths):\n",
    "    images = []\n",
    "    for x in imagePaths:\n",
    "        image = cv2.imread(x)\n",
    "        image = cv2.resize(image, (227,227))\n",
    "        if image.shape[2] == 1:\n",
    "            img = np.dstack([image,image,image])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = image.astype(np.float32)/255\n",
    "        images.append(image)\n",
    "    print(\"Images Converted to cv2\")\n",
    "    return images\n",
    "    \n",
    "\n",
    "train_images = convertImage(train_imagePath)\n",
    "val_images = convertImage(val_imagePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "656995cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation of Alexnet Architecture\n",
    "model = keras.models.Sequential()\n",
    "num_output = 2\n",
    "model.add(Conv2D(filters = 96, input_shape = (227, 227, 3), \n",
    "            kernel_size = (11, 11), strides = (4, 4), \n",
    "            padding = 'valid'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size =(2,2), strides = (2,2), padding='valid'))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(filters = 256, kernel_size = (11, 11), \n",
    "            strides = (1, 1), padding = 'valid'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), \n",
    "            padding = 'valid'))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(filters = 384, kernel_size = (3, 3), \n",
    "            strides = (1, 1), padding = 'valid'))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(filters = 384, kernel_size = (3, 3), \n",
    "            strides = (1, 1), padding = 'valid'))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(filters = 256, kernel_size = (3, 3), \n",
    "            strides = (1, 1), padding = 'valid'))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), \n",
    "            padding = 'valid'))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(4096, input_shape = (224*224*3, )))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "  \n",
    "\n",
    "model.add(Dense(num_output))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f5b7080c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.array(train_images)\n",
    "val_images = np.array(val_images)\n",
    "train_labels = to_categorical(train_labels, num_classes=2)\n",
    "val_labels = to_categorical(val_labels, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9416f9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "17/17 [==============================] - 109s 6s/step - loss: 3.2338 - accuracy: 0.5046 - val_loss: 2.0835 - val_accuracy: 0.4902\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 107s 6s/step - loss: 0.8697 - accuracy: 0.5176 - val_loss: 2.3775 - val_accuracy: 0.4938\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 114s 7s/step - loss: 0.7762 - accuracy: 0.5353 - val_loss: 2.9686 - val_accuracy: 0.4991\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 115s 7s/step - loss: 0.7585 - accuracy: 0.5336 - val_loss: 0.7496 - val_accuracy: 0.5151\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 116s 7s/step - loss: 0.7458 - accuracy: 0.5372 - val_loss: 0.7370 - val_accuracy: 0.4991\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 118s 7s/step - loss: 0.7431 - accuracy: 0.5447 - val_loss: 0.7385 - val_accuracy: 0.4654\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 110s 6s/step - loss: 0.7228 - accuracy: 0.5668 - val_loss: 0.6887 - val_accuracy: 0.5471\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 110s 6s/step - loss: 0.7126 - accuracy: 0.5795 - val_loss: 0.7314 - val_accuracy: 0.4938\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 107s 6s/step - loss: 0.7174 - accuracy: 0.5823 - val_loss: 0.7049 - val_accuracy: 0.5115\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 107s 6s/step - loss: 0.6837 - accuracy: 0.6050 - val_loss: 0.7310 - val_accuracy: 0.5009\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 110s 6s/step - loss: 0.6677 - accuracy: 0.6242 - val_loss: 0.7848 - val_accuracy: 0.5044\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 111s 7s/step - loss: 0.6626 - accuracy: 0.6334 - val_loss: 0.7055 - val_accuracy: 0.5453\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 105s 6s/step - loss: 0.6603 - accuracy: 0.6365 - val_loss: 0.7311 - val_accuracy: 0.5080\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 103s 6s/step - loss: 0.6683 - accuracy: 0.6218 - val_loss: 0.8864 - val_accuracy: 0.4938\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 106s 6s/step - loss: 0.6611 - accuracy: 0.6305 - val_loss: 0.8764 - val_accuracy: 0.4991\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 103s 6s/step - loss: 0.6509 - accuracy: 0.6496 - val_loss: 0.8731 - val_accuracy: 0.5115\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 104s 6s/step - loss: 0.6281 - accuracy: 0.6578 - val_loss: 0.9597 - val_accuracy: 0.5151\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 105s 6s/step - loss: 0.6389 - accuracy: 0.6533 - val_loss: 0.7977 - val_accuracy: 0.5222\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 104s 6s/step - loss: 0.6574 - accuracy: 0.6402 - val_loss: 1.1080 - val_accuracy: 0.5027\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 109s 6s/step - loss: 0.6142 - accuracy: 0.6784 - val_loss: 1.0930 - val_accuracy: 0.5222\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 107s 6s/step - loss: 0.6379 - accuracy: 0.6674 - val_loss: 0.9898 - val_accuracy: 0.5044\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 111s 7s/step - loss: 0.6121 - accuracy: 0.6772 - val_loss: 1.1080 - val_accuracy: 0.5169\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 111s 6s/step - loss: 0.5999 - accuracy: 0.6833 - val_loss: 0.9409 - val_accuracy: 0.5027\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 104s 6s/step - loss: 0.5993 - accuracy: 0.6865 - val_loss: 0.9783 - val_accuracy: 0.5115\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 103s 6s/step - loss: 0.6069 - accuracy: 0.6818 - val_loss: 1.1683 - val_accuracy: 0.5044\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 110s 6s/step - loss: 0.5858 - accuracy: 0.6936 - val_loss: 1.1733 - val_accuracy: 0.5258\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 110s 6s/step - loss: 0.5807 - accuracy: 0.6958 - val_loss: 0.7013 - val_accuracy: 0.6146\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 108s 6s/step - loss: 0.5907 - accuracy: 0.6892 - val_loss: 0.8078 - val_accuracy: 0.5666\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 108s 6s/step - loss: 0.5513 - accuracy: 0.7229 - val_loss: 1.1825 - val_accuracy: 0.5115\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 102s 6s/step - loss: 0.5309 - accuracy: 0.7385 - val_loss: 0.8576 - val_accuracy: 0.5595\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 102s 6s/step - loss: 0.5199 - accuracy: 0.7373 - val_loss: 1.2430 - val_accuracy: 0.5009\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 102s 6s/step - loss: 0.5328 - accuracy: 0.7311 - val_loss: 1.1150 - val_accuracy: 0.5044\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 102s 6s/step - loss: 0.5144 - accuracy: 0.7477 - val_loss: 0.8408 - val_accuracy: 0.5613\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 102s 6s/step - loss: 0.5075 - accuracy: 0.7514 - val_loss: 1.4139 - val_accuracy: 0.5133\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 102s 6s/step - loss: 0.4743 - accuracy: 0.7682 - val_loss: 1.4844 - val_accuracy: 0.5151\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 102s 6s/step - loss: 0.4846 - accuracy: 0.7655 - val_loss: 1.2071 - val_accuracy: 0.5453\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 102s 6s/step - loss: 0.4479 - accuracy: 0.7870 - val_loss: 2.2874 - val_accuracy: 0.5098\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 104s 6s/step - loss: 0.4353 - accuracy: 0.7972 - val_loss: 4.3550 - val_accuracy: 0.5009\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 108s 6s/step - loss: 0.4012 - accuracy: 0.8079 - val_loss: 1.1193 - val_accuracy: 0.5702\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 108s 6s/step - loss: 0.3919 - accuracy: 0.8158 - val_loss: 2.7081 - val_accuracy: 0.5080\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 104s 6s/step - loss: 0.3537 - accuracy: 0.8391 - val_loss: 1.9911 - val_accuracy: 0.5187\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 102s 6s/step - loss: 0.3339 - accuracy: 0.8412 - val_loss: 2.4189 - val_accuracy: 0.5027\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 102s 6s/step - loss: 0.3050 - accuracy: 0.8588 - val_loss: 1.6535 - val_accuracy: 0.5187\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 102s 6s/step - loss: 0.2893 - accuracy: 0.8645 - val_loss: 2.2233 - val_accuracy: 0.5293\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 102s 6s/step - loss: 0.2719 - accuracy: 0.8752 - val_loss: 2.0546 - val_accuracy: 0.5613\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 102s 6s/step - loss: 0.3007 - accuracy: 0.8659 - val_loss: 1.8007 - val_accuracy: 0.5737\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 101s 6s/step - loss: 0.2522 - accuracy: 0.8885 - val_loss: 2.4223 - val_accuracy: 0.5275\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 104s 6s/step - loss: 0.2145 - accuracy: 0.9032 - val_loss: 2.1525 - val_accuracy: 0.5773\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 104s 6s/step - loss: 0.2045 - accuracy: 0.9079 - val_loss: 1.6563 - val_accuracy: 0.6004\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 102s 6s/step - loss: 0.2687 - accuracy: 0.8766 - val_loss: 2.4745 - val_accuracy: 0.5258\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images, train_labels, batch_size = 512, epochs = 50, validation_data = (val_images, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df81d73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
