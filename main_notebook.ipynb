{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2bc86acd",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78b7f7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SKill\\anaconda3\\envs\\DL\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import MURA\n",
    "import cv2\n",
    "import image_manipulation\n",
    "from multiprocessing import Pool\n",
    "from models import *\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import preprocessing\n",
    "import json\n",
    "from os import path, mkdir\n",
    "import re\n",
    "from PIL import Image\n",
    "\n",
    "import keras\n",
    "from argparse import ArgumentParser\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "22e578b7",
   "metadata": {},
   "source": [
    "# Model to Run\n",
    "This section lets the user edit on what model parameters to run, the model directory and parameters should exist prior to changing the file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afd350f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All editable variables\n",
    "model_file_path = \"models/VAE/dataset_2/300_64_4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5b73251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model parameters\n",
    "try:\n",
    "    params = json.load(open(model_file_path + '/parameters.json'))\n",
    "\n",
    "    # Model to use\n",
    "    model_is_VAE = params['is_VAE']\n",
    "    # Model parameters\n",
    "    multiplier = params['multiplier']\n",
    "    latent_size = params['latent_size']\n",
    "    input_shape = params['input_shape']\n",
    "\n",
    "    # Training parameters\n",
    "    epochs = params['num_epochs']\n",
    "    batch_size = params['batch_size']\n",
    "    learning_rate = params['learning_rate']\n",
    "\n",
    "    # Dataset Path\n",
    "    dataset_file_path = params['dataset_path']\n",
    "\n",
    "except:\n",
    "    raise Exception(\"No parameters.json file found in the model's directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1eda5e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(image):\n",
    "    image = image.astype(np.float32)\n",
    "    image = image / 255.0\n",
    "    return image\n",
    "\n",
    "\n",
    "def denormalize_image(image):\n",
    "    image = image * 255.0\n",
    "    image = image.astype(np.uint8)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae204155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each array contains the training, validation, and testing in order\n",
    "image_datasets = {'train': [], 'valid': []}\n",
    "for dataset_name in image_datasets.keys():\n",
    "    for image_path in glob.glob(f'{dataset_file_path}/{dataset_name}/*.png'):\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        # image = normalize_image(image)\n",
    "        image_datasets[dataset_name].append(image)\n",
    "    image_datasets[dataset_name] = np.array(image_datasets[dataset_name])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f69e69d0",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "This section creates and trains the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed03caa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder_decoder\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SKill\\anaconda3\\envs\\DL\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 64)        1024      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32, 32, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 16, 128)       131072    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16, 16, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 8, 256)         524288    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 8, 8, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 4, 4, 256)         1048576   \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 4, 4, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2048)              8388608   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 2048)             8192      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               262144    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2048)              264192    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 2048)             8192      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4096)              8388608   \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 8, 8, 256)        1048576   \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 8, 8, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 16, 16, 128)      524288    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 16, 16, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 32, 32, 64)       131072    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 32, 32, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 64, 64, 1)        1024      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " encoder (Sequential)        (None, 4096)              1707776   \n",
      "                                                                 \n",
      " latent_encoder (Sequential)  (None, 128)              8658944   \n",
      "                                                                 \n",
      " latent_decoder (Sequential)  (None, 4, 4, 256)        8660992   \n",
      "                                                                 \n",
      " decoder (Sequential)        (None, 64, 64, 1)         1706752   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,734,464\n",
      "Trainable params: 20,723,968\n",
      "Non-trainable params: 10,496\n",
      "_________________________________________________________________\n",
      "Model: \"vae\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_decoder (encoder_de  multiple                 20734464  \n",
      " coder)                                                          \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,734,470\n",
      "Trainable params: 20,723,968\n",
      "Non-trainable params: 10,502\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "59/59 [==============================] - 5s 32ms/step - mse_loss: 0.3246 - reconstruction_loss: -10.6594 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0836 - val_reconstruction_loss: -11.3887\n",
      "Epoch 2/300\n",
      "59/59 [==============================] - 2s 41ms/step - mse_loss: 0.0863 - reconstruction_loss: -10.7031 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0491 - val_reconstruction_loss: -11.3887\n",
      "Epoch 3/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0584 - reconstruction_loss: -10.7097 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0360 - val_reconstruction_loss: -11.3887\n",
      "Epoch 4/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0462 - reconstruction_loss: -10.7538 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0319 - val_reconstruction_loss: -11.4298\n",
      "Epoch 5/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0400 - reconstruction_loss: -10.8527 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0304 - val_reconstruction_loss: -11.4385\n",
      "Epoch 6/300\n",
      "59/59 [==============================] - 1s 21ms/step - mse_loss: 0.0355 - reconstruction_loss: -10.8570 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0247 - val_reconstruction_loss: -11.4438\n",
      "Epoch 7/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0312 - reconstruction_loss: -10.8583 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0230 - val_reconstruction_loss: -11.4422\n",
      "Epoch 8/300\n",
      "59/59 [==============================] - 1s 21ms/step - mse_loss: 0.0284 - reconstruction_loss: -10.8965 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0222 - val_reconstruction_loss: -11.4495\n",
      "Epoch 9/300\n",
      "59/59 [==============================] - 1s 21ms/step - mse_loss: 0.0260 - reconstruction_loss: -10.8883 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0207 - val_reconstruction_loss: -11.4497\n",
      "Epoch 10/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0264 - reconstruction_loss: -10.8838 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0225 - val_reconstruction_loss: -11.4514\n",
      "Epoch 11/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0233 - reconstruction_loss: -10.8874 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0177 - val_reconstruction_loss: -11.4526\n",
      "Epoch 12/300\n",
      "59/59 [==============================] - 1s 21ms/step - mse_loss: 0.0215 - reconstruction_loss: -10.9078 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0174 - val_reconstruction_loss: -11.4486\n",
      "Epoch 13/300\n",
      "59/59 [==============================] - 1s 22ms/step - mse_loss: 0.0210 - reconstruction_loss: -10.8937 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0226 - val_reconstruction_loss: -11.4411\n",
      "Epoch 14/300\n",
      "59/59 [==============================] - 1s 21ms/step - mse_loss: 0.0195 - reconstruction_loss: -10.9015 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0166 - val_reconstruction_loss: -11.4493\n",
      "Epoch 15/300\n",
      "59/59 [==============================] - 1s 21ms/step - mse_loss: 0.0183 - reconstruction_loss: -10.9087 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0161 - val_reconstruction_loss: -11.4514\n",
      "Epoch 16/300\n",
      "59/59 [==============================] - 1s 21ms/step - mse_loss: 0.0173 - reconstruction_loss: -10.9078 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0144 - val_reconstruction_loss: -11.4490\n",
      "Epoch 17/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0167 - reconstruction_loss: -10.9068 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0144 - val_reconstruction_loss: -11.4571\n",
      "Epoch 18/300\n",
      "59/59 [==============================] - 1s 22ms/step - mse_loss: 0.0163 - reconstruction_loss: -10.9012 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0141 - val_reconstruction_loss: -11.4486\n",
      "Epoch 19/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0162 - reconstruction_loss: -10.9089 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0133 - val_reconstruction_loss: -11.4505\n",
      "Epoch 20/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0158 - reconstruction_loss: -10.9073 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0133 - val_reconstruction_loss: -11.4574\n",
      "Epoch 21/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.1098 - reconstruction_loss: -10.8837 - kl_loss: 0.0000e+00 - val_mse_loss: 0.4934 - val_reconstruction_loss: -11.3887\n",
      "Epoch 22/300\n",
      "59/59 [==============================] - 1s 17ms/step - mse_loss: 0.1496 - reconstruction_loss: -10.7161 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0547 - val_reconstruction_loss: -11.3962\n",
      "Epoch 23/300\n",
      "59/59 [==============================] - 1s 16ms/step - mse_loss: 0.0507 - reconstruction_loss: -10.8276 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0341 - val_reconstruction_loss: -11.4300\n",
      "Epoch 24/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0417 - reconstruction_loss: -10.8429 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0304 - val_reconstruction_loss: -11.4343\n",
      "Epoch 25/300\n",
      "59/59 [==============================] - 1s 16ms/step - mse_loss: 0.0358 - reconstruction_loss: -10.8723 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0243 - val_reconstruction_loss: -11.4442\n",
      "Epoch 26/300\n",
      "59/59 [==============================] - 3s 56ms/step - mse_loss: 0.0307 - reconstruction_loss: -10.8738 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0228 - val_reconstruction_loss: -11.4502\n",
      "Epoch 27/300\n",
      "59/59 [==============================] - 1s 24ms/step - mse_loss: 0.0276 - reconstruction_loss: -10.8843 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0204 - val_reconstruction_loss: -11.4503\n",
      "Epoch 28/300\n",
      "59/59 [==============================] - 1s 22ms/step - mse_loss: 0.0249 - reconstruction_loss: -10.8929 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0198 - val_reconstruction_loss: -11.4497\n",
      "Epoch 29/300\n",
      "59/59 [==============================] - 1s 23ms/step - mse_loss: 0.0234 - reconstruction_loss: -10.8848 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0180 - val_reconstruction_loss: -11.4486\n",
      "Epoch 30/300\n",
      "59/59 [==============================] - 1s 25ms/step - mse_loss: 0.0220 - reconstruction_loss: -10.8870 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0166 - val_reconstruction_loss: -11.4537\n",
      "Epoch 31/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0208 - reconstruction_loss: -10.8935 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0166 - val_reconstruction_loss: -11.4512\n",
      "Epoch 32/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0198 - reconstruction_loss: -10.8913 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0161 - val_reconstruction_loss: -11.4556\n",
      "Epoch 33/300\n",
      "59/59 [==============================] - 1s 22ms/step - mse_loss: 0.0191 - reconstruction_loss: -10.9110 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0155 - val_reconstruction_loss: -11.4564\n",
      "Epoch 34/300\n",
      "59/59 [==============================] - 1s 23ms/step - mse_loss: 0.0179 - reconstruction_loss: -10.9027 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0157 - val_reconstruction_loss: -11.4553\n",
      "Epoch 35/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0176 - reconstruction_loss: -10.9107 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0152 - val_reconstruction_loss: -11.4571\n",
      "Epoch 36/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0171 - reconstruction_loss: -10.8934 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0150 - val_reconstruction_loss: -11.4562\n",
      "Epoch 37/300\n",
      "59/59 [==============================] - 1s 17ms/step - mse_loss: 0.0165 - reconstruction_loss: -10.9097 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0145 - val_reconstruction_loss: -11.4578\n",
      "Epoch 38/300\n",
      "59/59 [==============================] - 1s 17ms/step - mse_loss: 0.0161 - reconstruction_loss: -10.8988 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0136 - val_reconstruction_loss: -11.4595\n",
      "Epoch 39/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0154 - reconstruction_loss: -10.9149 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0132 - val_reconstruction_loss: -11.4579\n",
      "Epoch 40/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0152 - reconstruction_loss: -10.9038 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0129 - val_reconstruction_loss: -11.4570\n",
      "Epoch 41/300\n",
      "59/59 [==============================] - 1s 17ms/step - mse_loss: 0.0153 - reconstruction_loss: -10.9049 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0137 - val_reconstruction_loss: -11.4557\n",
      "Epoch 42/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0146 - reconstruction_loss: -10.9073 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0126 - val_reconstruction_loss: -11.4600\n",
      "Epoch 43/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0139 - reconstruction_loss: -10.9178 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0119 - val_reconstruction_loss: -11.4609\n",
      "Epoch 44/300\n",
      "59/59 [==============================] - 1s 17ms/step - mse_loss: 0.0139 - reconstruction_loss: -10.9077 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0115 - val_reconstruction_loss: -11.4615\n",
      "Epoch 45/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0139 - reconstruction_loss: -10.9138 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0111 - val_reconstruction_loss: -11.4595\n",
      "Epoch 46/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0134 - reconstruction_loss: -10.9141 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0104 - val_reconstruction_loss: -11.4656\n",
      "Epoch 47/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0133 - reconstruction_loss: -10.9135 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0115 - val_reconstruction_loss: -11.4606\n",
      "Epoch 48/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0134 - reconstruction_loss: -10.9170 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0117 - val_reconstruction_loss: -11.4605\n",
      "Epoch 49/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0130 - reconstruction_loss: -10.9147 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0103 - val_reconstruction_loss: -11.4611\n",
      "Epoch 50/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0124 - reconstruction_loss: -10.9213 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0103 - val_reconstruction_loss: -11.4644\n",
      "Epoch 51/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0123 - reconstruction_loss: -10.8998 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0095 - val_reconstruction_loss: -11.4631\n",
      "Epoch 52/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0119 - reconstruction_loss: -10.9224 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0096 - val_reconstruction_loss: -11.4608\n",
      "Epoch 53/300\n",
      "59/59 [==============================] - 1s 17ms/step - mse_loss: 0.0120 - reconstruction_loss: -10.9189 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0097 - val_reconstruction_loss: -11.4658\n",
      "Epoch 54/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0118 - reconstruction_loss: -10.9339 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0102 - val_reconstruction_loss: -11.4647\n",
      "Epoch 55/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0118 - reconstruction_loss: -10.9054 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0091 - val_reconstruction_loss: -11.4660\n",
      "Epoch 56/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0116 - reconstruction_loss: -10.9203 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0093 - val_reconstruction_loss: -11.4649\n",
      "Epoch 57/300\n",
      "59/59 [==============================] - 1s 17ms/step - mse_loss: 0.0112 - reconstruction_loss: -10.9315 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0085 - val_reconstruction_loss: -11.4670\n",
      "Epoch 58/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0110 - reconstruction_loss: -10.9181 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0093 - val_reconstruction_loss: -11.4635\n",
      "Epoch 59/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0111 - reconstruction_loss: -10.9261 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0090 - val_reconstruction_loss: -11.4658\n",
      "Epoch 60/300\n",
      "59/59 [==============================] - 1s 17ms/step - mse_loss: 0.0113 - reconstruction_loss: -10.9207 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0095 - val_reconstruction_loss: -11.4630\n",
      "Epoch 61/300\n",
      "59/59 [==============================] - 1s 17ms/step - mse_loss: 0.0110 - reconstruction_loss: -10.9237 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0098 - val_reconstruction_loss: -11.4633\n",
      "Epoch 62/300\n",
      "59/59 [==============================] - 1s 17ms/step - mse_loss: 0.0114 - reconstruction_loss: -10.9270 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0094 - val_reconstruction_loss: -11.4668\n",
      "Epoch 63/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0109 - reconstruction_loss: -10.9234 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0088 - val_reconstruction_loss: -11.4646\n",
      "Epoch 64/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0107 - reconstruction_loss: -10.9023 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0098 - val_reconstruction_loss: -11.4603\n",
      "Epoch 65/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0106 - reconstruction_loss: -10.9244 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0082 - val_reconstruction_loss: -11.4654\n",
      "Epoch 66/300\n",
      "59/59 [==============================] - 1s 22ms/step - mse_loss: 0.0104 - reconstruction_loss: -10.9166 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0086 - val_reconstruction_loss: -11.4671\n",
      "Epoch 67/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0103 - reconstruction_loss: -10.9349 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0085 - val_reconstruction_loss: -11.4660\n",
      "Epoch 68/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0101 - reconstruction_loss: -10.9094 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0081 - val_reconstruction_loss: -11.4668\n",
      "Epoch 69/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0104 - reconstruction_loss: -10.9378 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0085 - val_reconstruction_loss: -11.4626\n",
      "Epoch 70/300\n",
      "59/59 [==============================] - 1s 21ms/step - mse_loss: 0.0106 - reconstruction_loss: -10.9097 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0109 - val_reconstruction_loss: -11.4539\n",
      "Epoch 71/300\n",
      "59/59 [==============================] - 1s 21ms/step - mse_loss: 0.0111 - reconstruction_loss: -10.9255 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0090 - val_reconstruction_loss: -11.4692\n",
      "Epoch 72/300\n",
      "59/59 [==============================] - 1s 23ms/step - mse_loss: 0.0106 - reconstruction_loss: -10.9112 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0091 - val_reconstruction_loss: -11.4662\n",
      "Epoch 73/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0099 - reconstruction_loss: -10.9297 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0088 - val_reconstruction_loss: -11.4683\n",
      "Epoch 74/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0097 - reconstruction_loss: -10.9120 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0085 - val_reconstruction_loss: -11.4643\n",
      "Epoch 75/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0099 - reconstruction_loss: -10.9157 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0087 - val_reconstruction_loss: -11.4655\n",
      "Epoch 76/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0097 - reconstruction_loss: -10.9233 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0082 - val_reconstruction_loss: -11.4670\n",
      "Epoch 77/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0095 - reconstruction_loss: -10.9232 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0082 - val_reconstruction_loss: -11.4675\n",
      "Epoch 78/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0100 - reconstruction_loss: -10.9202 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0086 - val_reconstruction_loss: -11.4686\n",
      "Epoch 79/300\n",
      "59/59 [==============================] - 1s 21ms/step - mse_loss: 0.0097 - reconstruction_loss: -10.9245 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0086 - val_reconstruction_loss: -11.4640\n",
      "Epoch 80/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0094 - reconstruction_loss: -10.9188 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0084 - val_reconstruction_loss: -11.4643\n",
      "Epoch 81/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0092 - reconstruction_loss: -10.9414 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0083 - val_reconstruction_loss: -11.4657\n",
      "Epoch 82/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0090 - reconstruction_loss: -10.9288 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0086 - val_reconstruction_loss: -11.4689\n",
      "Epoch 83/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0089 - reconstruction_loss: -10.9313 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0082 - val_reconstruction_loss: -11.4651\n",
      "Epoch 84/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0088 - reconstruction_loss: -10.9119 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0082 - val_reconstruction_loss: -11.4684\n",
      "Epoch 85/300\n",
      "59/59 [==============================] - 1s 17ms/step - mse_loss: 0.0089 - reconstruction_loss: -10.9271 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0084 - val_reconstruction_loss: -11.4665\n",
      "Epoch 86/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0090 - reconstruction_loss: -10.9192 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0095 - val_reconstruction_loss: -11.4662\n",
      "Epoch 87/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0096 - reconstruction_loss: -10.9323 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0092 - val_reconstruction_loss: -11.4636\n",
      "Epoch 88/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0093 - reconstruction_loss: -10.9303 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0086 - val_reconstruction_loss: -11.4682\n",
      "Epoch 89/300\n",
      "59/59 [==============================] - 1s 22ms/step - mse_loss: 0.0094 - reconstruction_loss: -10.9179 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0078 - val_reconstruction_loss: -11.4655\n",
      "Epoch 90/300\n",
      "59/59 [==============================] - 1s 24ms/step - mse_loss: 0.0089 - reconstruction_loss: -10.9233 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0083 - val_reconstruction_loss: -11.4661\n",
      "Epoch 91/300\n",
      "59/59 [==============================] - 1s 22ms/step - mse_loss: 0.0090 - reconstruction_loss: -10.9353 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0085 - val_reconstruction_loss: -11.4673\n",
      "Epoch 92/300\n",
      "59/59 [==============================] - 1s 21ms/step - mse_loss: 0.0087 - reconstruction_loss: -10.9191 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0088 - val_reconstruction_loss: -11.4642\n",
      "Epoch 93/300\n",
      "59/59 [==============================] - 1s 21ms/step - mse_loss: 0.0086 - reconstruction_loss: -10.9277 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0089 - val_reconstruction_loss: -11.4634\n",
      "Epoch 94/300\n",
      "59/59 [==============================] - 3s 51ms/step - mse_loss: 0.0086 - reconstruction_loss: -10.9204 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0082 - val_reconstruction_loss: -11.4664\n",
      "Epoch 95/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0083 - reconstruction_loss: -10.9273 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0082 - val_reconstruction_loss: -11.4665\n",
      "Epoch 96/300\n",
      "59/59 [==============================] - 1s 21ms/step - mse_loss: 0.0082 - reconstruction_loss: -10.9285 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0079 - val_reconstruction_loss: -11.4679\n",
      "Epoch 97/300\n",
      "59/59 [==============================] - 1s 22ms/step - mse_loss: 0.0084 - reconstruction_loss: -10.9181 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0091 - val_reconstruction_loss: -11.4670\n",
      "Epoch 98/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0082 - reconstruction_loss: -10.9300 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0083 - val_reconstruction_loss: -11.4685\n",
      "Epoch 99/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0080 - reconstruction_loss: -10.9324 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0083 - val_reconstruction_loss: -11.4649\n",
      "Epoch 100/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0081 - reconstruction_loss: -10.9194 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0084 - val_reconstruction_loss: -11.4669\n",
      "Epoch 101/300\n",
      "59/59 [==============================] - 1s 21ms/step - mse_loss: 0.0080 - reconstruction_loss: -10.9291 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0096 - val_reconstruction_loss: -11.4648\n",
      "Epoch 102/300\n",
      "59/59 [==============================] - 4s 63ms/step - mse_loss: 0.0083 - reconstruction_loss: -10.9112 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0106 - val_reconstruction_loss: -11.4521\n",
      "Epoch 103/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0090 - reconstruction_loss: -10.9219 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0098 - val_reconstruction_loss: -11.4652\n",
      "Epoch 104/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0085 - reconstruction_loss: -10.9340 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0086 - val_reconstruction_loss: -11.4686\n",
      "Epoch 105/300\n",
      "59/59 [==============================] - 1s 21ms/step - mse_loss: 0.0090 - reconstruction_loss: -10.9181 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0088 - val_reconstruction_loss: -11.4654\n",
      "Epoch 106/300\n",
      "59/59 [==============================] - 1s 21ms/step - mse_loss: 0.0087 - reconstruction_loss: -10.9348 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0091 - val_reconstruction_loss: -11.4642\n",
      "Epoch 107/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0085 - reconstruction_loss: -10.9322 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0087 - val_reconstruction_loss: -11.4670\n",
      "Epoch 108/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0080 - reconstruction_loss: -10.9322 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0091 - val_reconstruction_loss: -11.4669\n",
      "Epoch 109/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0079 - reconstruction_loss: -10.9272 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0086 - val_reconstruction_loss: -11.4627\n",
      "Epoch 110/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0078 - reconstruction_loss: -10.9325 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0082 - val_reconstruction_loss: -11.4664\n",
      "Epoch 111/300\n",
      "59/59 [==============================] - 1s 17ms/step - mse_loss: 0.0078 - reconstruction_loss: -10.9302 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0092 - val_reconstruction_loss: -11.4650\n",
      "Epoch 112/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0077 - reconstruction_loss: -10.9357 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0087 - val_reconstruction_loss: -11.4664\n",
      "Epoch 113/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0075 - reconstruction_loss: -10.9467 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0085 - val_reconstruction_loss: -11.4640\n",
      "Epoch 114/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0074 - reconstruction_loss: -10.9188 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0081 - val_reconstruction_loss: -11.4661\n",
      "Epoch 115/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0076 - reconstruction_loss: -10.9205 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0088 - val_reconstruction_loss: -11.4651\n",
      "Epoch 116/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0076 - reconstruction_loss: -10.9224 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0086 - val_reconstruction_loss: -11.4654\n",
      "Epoch 117/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0074 - reconstruction_loss: -10.9117 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0082 - val_reconstruction_loss: -11.4650\n",
      "Epoch 118/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0073 - reconstruction_loss: -10.9351 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0086 - val_reconstruction_loss: -11.4654\n",
      "Epoch 119/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0074 - reconstruction_loss: -10.9356 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0083 - val_reconstruction_loss: -11.4652\n",
      "Epoch 120/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0074 - reconstruction_loss: -10.9406 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0087 - val_reconstruction_loss: -11.4633\n",
      "Epoch 121/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0074 - reconstruction_loss: -10.9433 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0082 - val_reconstruction_loss: -11.4637\n",
      "Epoch 122/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0075 - reconstruction_loss: -10.9319 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0082 - val_reconstruction_loss: -11.4630\n",
      "Epoch 123/300\n",
      "59/59 [==============================] - 1s 21ms/step - mse_loss: 0.0077 - reconstruction_loss: -10.9245 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0087 - val_reconstruction_loss: -11.4662\n",
      "Epoch 124/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0077 - reconstruction_loss: -10.9187 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0084 - val_reconstruction_loss: -11.4632\n",
      "Epoch 125/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0078 - reconstruction_loss: -10.9377 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0095 - val_reconstruction_loss: -11.4604\n",
      "Epoch 126/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0080 - reconstruction_loss: -10.9388 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0096 - val_reconstruction_loss: -11.4615\n",
      "Epoch 127/300\n",
      "59/59 [==============================] - 1s 21ms/step - mse_loss: 0.0077 - reconstruction_loss: -10.9208 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0095 - val_reconstruction_loss: -11.4595\n",
      "Epoch 128/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0074 - reconstruction_loss: -10.9342 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0095 - val_reconstruction_loss: -11.4630\n",
      "Epoch 129/300\n",
      "59/59 [==============================] - 1s 23ms/step - mse_loss: 0.0072 - reconstruction_loss: -10.9300 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0086 - val_reconstruction_loss: -11.4655\n",
      "Epoch 130/300\n",
      "59/59 [==============================] - 1s 21ms/step - mse_loss: 0.0071 - reconstruction_loss: -10.9232 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0092 - val_reconstruction_loss: -11.4611\n",
      "Epoch 131/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0071 - reconstruction_loss: -10.9232 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0087 - val_reconstruction_loss: -11.4645\n",
      "Epoch 132/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0080 - reconstruction_loss: -10.9335 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0102 - val_reconstruction_loss: -11.4603\n",
      "Epoch 133/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0078 - reconstruction_loss: -10.9237 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0095 - val_reconstruction_loss: -11.4641\n",
      "Epoch 134/300\n",
      "59/59 [==============================] - 1s 21ms/step - mse_loss: 0.0074 - reconstruction_loss: -10.9380 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0089 - val_reconstruction_loss: -11.4606\n",
      "Epoch 135/300\n",
      "59/59 [==============================] - 1s 21ms/step - mse_loss: 0.0070 - reconstruction_loss: -10.9231 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0089 - val_reconstruction_loss: -11.4635\n",
      "Epoch 136/300\n",
      "59/59 [==============================] - 1s 22ms/step - mse_loss: 0.0068 - reconstruction_loss: -10.9314 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0084 - val_reconstruction_loss: -11.4634\n",
      "Epoch 137/300\n",
      "59/59 [==============================] - 1s 22ms/step - mse_loss: 0.0066 - reconstruction_loss: -10.9395 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0087 - val_reconstruction_loss: -11.4646\n",
      "Epoch 138/300\n",
      "59/59 [==============================] - 1s 23ms/step - mse_loss: 0.0066 - reconstruction_loss: -10.9432 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0083 - val_reconstruction_loss: -11.4630\n",
      "Epoch 139/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0066 - reconstruction_loss: -10.9250 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0087 - val_reconstruction_loss: -11.4622\n",
      "Epoch 140/300\n",
      "59/59 [==============================] - 1s 21ms/step - mse_loss: 0.0066 - reconstruction_loss: -10.9401 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0084 - val_reconstruction_loss: -11.4636\n",
      "Epoch 141/300\n",
      "59/59 [==============================] - 1s 22ms/step - mse_loss: 0.0066 - reconstruction_loss: -10.9312 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0085 - val_reconstruction_loss: -11.4623\n",
      "Epoch 142/300\n",
      "59/59 [==============================] - 1s 22ms/step - mse_loss: 0.0068 - reconstruction_loss: -10.9238 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0081 - val_reconstruction_loss: -11.4637\n",
      "Epoch 143/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0068 - reconstruction_loss: -10.9427 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0087 - val_reconstruction_loss: -11.4626\n",
      "Epoch 144/300\n",
      "59/59 [==============================] - 1s 21ms/step - mse_loss: 0.0070 - reconstruction_loss: -10.9235 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0093 - val_reconstruction_loss: -11.4619\n",
      "Epoch 145/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0071 - reconstruction_loss: -10.9361 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0084 - val_reconstruction_loss: -11.4632\n",
      "Epoch 146/300\n",
      "59/59 [==============================] - 1s 24ms/step - mse_loss: 0.0073 - reconstruction_loss: -10.9372 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0093 - val_reconstruction_loss: -11.4640\n",
      "Epoch 147/300\n",
      "59/59 [==============================] - 1s 22ms/step - mse_loss: 0.0074 - reconstruction_loss: -10.9400 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0100 - val_reconstruction_loss: -11.4624\n",
      "Epoch 148/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0082 - reconstruction_loss: -10.9263 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0122 - val_reconstruction_loss: -11.4525\n",
      "Epoch 149/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0079 - reconstruction_loss: -10.9417 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0096 - val_reconstruction_loss: -11.4615\n",
      "Epoch 150/300\n",
      "59/59 [==============================] - 1s 17ms/step - mse_loss: 0.0073 - reconstruction_loss: -10.9323 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0091 - val_reconstruction_loss: -11.4615\n",
      "Epoch 151/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0067 - reconstruction_loss: -10.9316 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0091 - val_reconstruction_loss: -11.4639\n",
      "Epoch 152/300\n",
      "59/59 [==============================] - 1s 22ms/step - mse_loss: 0.0064 - reconstruction_loss: -10.9296 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0085 - val_reconstruction_loss: -11.4634\n",
      "Epoch 153/300\n",
      "59/59 [==============================] - 2s 35ms/step - mse_loss: 0.0062 - reconstruction_loss: -10.9322 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0086 - val_reconstruction_loss: -11.4634\n",
      "Epoch 154/300\n",
      "59/59 [==============================] - 1s 24ms/step - mse_loss: 0.0062 - reconstruction_loss: -10.9434 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0089 - val_reconstruction_loss: -11.4628\n",
      "Epoch 155/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0061 - reconstruction_loss: -10.9469 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0088 - val_reconstruction_loss: -11.4638\n",
      "Epoch 156/300\n",
      "59/59 [==============================] - 1s 22ms/step - mse_loss: 0.0062 - reconstruction_loss: -10.9198 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0091 - val_reconstruction_loss: -11.4640\n",
      "Epoch 157/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0062 - reconstruction_loss: -10.9285 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0087 - val_reconstruction_loss: -11.4626\n",
      "Epoch 158/300\n",
      "59/59 [==============================] - 1s 21ms/step - mse_loss: 0.0064 - reconstruction_loss: -10.9237 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0091 - val_reconstruction_loss: -11.4629\n",
      "Epoch 159/300\n",
      "59/59 [==============================] - 1s 23ms/step - mse_loss: 0.0066 - reconstruction_loss: -10.9126 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0094 - val_reconstruction_loss: -11.4615\n",
      "Epoch 160/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0065 - reconstruction_loss: -10.9274 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0085 - val_reconstruction_loss: -11.4618\n",
      "Epoch 161/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0065 - reconstruction_loss: -10.9286 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0092 - val_reconstruction_loss: -11.4600\n",
      "Epoch 162/300\n",
      "59/59 [==============================] - 1s 21ms/step - mse_loss: 0.0064 - reconstruction_loss: -10.9351 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0090 - val_reconstruction_loss: -11.4601\n",
      "Epoch 163/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0064 - reconstruction_loss: -10.9379 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0086 - val_reconstruction_loss: -11.4614\n",
      "Epoch 164/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0063 - reconstruction_loss: -10.9384 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0089 - val_reconstruction_loss: -11.4608\n",
      "Epoch 165/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0064 - reconstruction_loss: -10.9364 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0089 - val_reconstruction_loss: -11.4631\n",
      "Epoch 166/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0062 - reconstruction_loss: -10.9355 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0086 - val_reconstruction_loss: -11.4623\n",
      "Epoch 167/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0061 - reconstruction_loss: -10.9270 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0086 - val_reconstruction_loss: -11.4627\n",
      "Epoch 168/300\n",
      "59/59 [==============================] - 1s 17ms/step - mse_loss: 0.0062 - reconstruction_loss: -10.9444 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0096 - val_reconstruction_loss: -11.4620\n",
      "Epoch 169/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0061 - reconstruction_loss: -10.9257 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0085 - val_reconstruction_loss: -11.4611\n",
      "Epoch 170/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0062 - reconstruction_loss: -10.9459 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0096 - val_reconstruction_loss: -11.4627\n",
      "Epoch 171/300\n",
      "59/59 [==============================] - 8s 131ms/step - mse_loss: 0.0069 - reconstruction_loss: -10.9344 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0095 - val_reconstruction_loss: -11.4592\n",
      "Epoch 172/300\n",
      "59/59 [==============================] - 1s 17ms/step - mse_loss: 0.0071 - reconstruction_loss: -10.9349 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0089 - val_reconstruction_loss: -11.4603\n",
      "Epoch 173/300\n",
      "59/59 [==============================] - 1s 17ms/step - mse_loss: 0.0070 - reconstruction_loss: -10.9234 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0102 - val_reconstruction_loss: -11.4603\n",
      "Epoch 174/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0068 - reconstruction_loss: -10.9487 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0093 - val_reconstruction_loss: -11.4554\n",
      "Epoch 175/300\n",
      "59/59 [==============================] - 1s 21ms/step - mse_loss: 0.0065 - reconstruction_loss: -10.9094 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0085 - val_reconstruction_loss: -11.4651\n",
      "Epoch 176/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0063 - reconstruction_loss: -10.9358 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0094 - val_reconstruction_loss: -11.4599\n",
      "Epoch 177/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0062 - reconstruction_loss: -10.9351 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0094 - val_reconstruction_loss: -11.4599\n",
      "Epoch 178/300\n",
      "59/59 [==============================] - 1s 22ms/step - mse_loss: 0.0059 - reconstruction_loss: -10.9389 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0091 - val_reconstruction_loss: -11.4618\n",
      "Epoch 179/300\n",
      "59/59 [==============================] - 1s 21ms/step - mse_loss: 0.0058 - reconstruction_loss: -10.9087 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0091 - val_reconstruction_loss: -11.4623\n",
      "Epoch 180/300\n",
      "59/59 [==============================] - 1s 21ms/step - mse_loss: 0.0058 - reconstruction_loss: -10.9236 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0088 - val_reconstruction_loss: -11.4634\n",
      "Epoch 181/300\n",
      "59/59 [==============================] - 1s 21ms/step - mse_loss: 0.0057 - reconstruction_loss: -10.9318 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0085 - val_reconstruction_loss: -11.4622\n",
      "Epoch 182/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0058 - reconstruction_loss: -10.9433 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0091 - val_reconstruction_loss: -11.4593\n",
      "Epoch 183/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0058 - reconstruction_loss: -10.9479 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0089 - val_reconstruction_loss: -11.4604\n",
      "Epoch 184/300\n",
      "59/59 [==============================] - 1s 17ms/step - mse_loss: 0.0059 - reconstruction_loss: -10.9470 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0086 - val_reconstruction_loss: -11.4624\n",
      "Epoch 185/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0059 - reconstruction_loss: -10.9451 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0085 - val_reconstruction_loss: -11.4603\n",
      "Epoch 186/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0061 - reconstruction_loss: -10.9497 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0091 - val_reconstruction_loss: -11.4614\n",
      "Epoch 187/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0062 - reconstruction_loss: -10.9193 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0098 - val_reconstruction_loss: -11.4622\n",
      "Epoch 188/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0064 - reconstruction_loss: -10.9302 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0093 - val_reconstruction_loss: -11.4578\n",
      "Epoch 189/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0061 - reconstruction_loss: -10.9427 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0095 - val_reconstruction_loss: -11.4608\n",
      "Epoch 190/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0061 - reconstruction_loss: -10.9271 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0092 - val_reconstruction_loss: -11.4590\n",
      "Epoch 191/300\n",
      "59/59 [==============================] - 1s 17ms/step - mse_loss: 0.0062 - reconstruction_loss: -10.9315 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0088 - val_reconstruction_loss: -11.4617\n",
      "Epoch 192/300\n",
      "59/59 [==============================] - 1s 17ms/step - mse_loss: 0.0063 - reconstruction_loss: -10.9332 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0088 - val_reconstruction_loss: -11.4632\n",
      "Epoch 193/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0068 - reconstruction_loss: -10.9241 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0090 - val_reconstruction_loss: -11.4602\n",
      "Epoch 194/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0067 - reconstruction_loss: -10.9283 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0097 - val_reconstruction_loss: -11.4571\n",
      "Epoch 195/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0065 - reconstruction_loss: -10.9315 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0085 - val_reconstruction_loss: -11.4609\n",
      "Epoch 196/300\n",
      "59/59 [==============================] - 1s 21ms/step - mse_loss: 0.0059 - reconstruction_loss: -10.9345 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0090 - val_reconstruction_loss: -11.4595\n",
      "Epoch 197/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0057 - reconstruction_loss: -10.9279 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0089 - val_reconstruction_loss: -11.4620\n",
      "Epoch 198/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0055 - reconstruction_loss: -10.9375 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0088 - val_reconstruction_loss: -11.4607\n",
      "Epoch 199/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0054 - reconstruction_loss: -10.9418 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0087 - val_reconstruction_loss: -11.4620\n",
      "Epoch 200/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0054 - reconstruction_loss: -10.9179 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0086 - val_reconstruction_loss: -11.4622\n",
      "Epoch 201/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0054 - reconstruction_loss: -10.9409 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0087 - val_reconstruction_loss: -11.4618\n",
      "Epoch 202/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0053 - reconstruction_loss: -10.9263 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0086 - val_reconstruction_loss: -11.4608\n",
      "Epoch 203/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0053 - reconstruction_loss: -10.9456 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0087 - val_reconstruction_loss: -11.4622\n",
      "Epoch 204/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0054 - reconstruction_loss: -10.9231 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0088 - val_reconstruction_loss: -11.4610\n",
      "Epoch 205/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0054 - reconstruction_loss: -10.9302 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0085 - val_reconstruction_loss: -11.4615\n",
      "Epoch 206/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0054 - reconstruction_loss: -10.9415 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0089 - val_reconstruction_loss: -11.4614\n",
      "Epoch 207/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0054 - reconstruction_loss: -10.9383 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0091 - val_reconstruction_loss: -11.4589\n",
      "Epoch 208/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0057 - reconstruction_loss: -10.9311 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0098 - val_reconstruction_loss: -11.4600\n",
      "Epoch 209/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0067 - reconstruction_loss: -10.9419 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0095 - val_reconstruction_loss: -11.4568\n",
      "Epoch 210/300\n",
      "59/59 [==============================] - 1s 17ms/step - mse_loss: 0.0078 - reconstruction_loss: -10.9169 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0113 - val_reconstruction_loss: -11.4555\n",
      "Epoch 211/300\n",
      "59/59 [==============================] - 1s 17ms/step - mse_loss: 0.0082 - reconstruction_loss: -10.9236 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0102 - val_reconstruction_loss: -11.4546\n",
      "Epoch 212/300\n",
      "59/59 [==============================] - 1s 17ms/step - mse_loss: 0.0071 - reconstruction_loss: -10.9184 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0098 - val_reconstruction_loss: -11.4594\n",
      "Epoch 213/300\n",
      "59/59 [==============================] - 1s 17ms/step - mse_loss: 0.0061 - reconstruction_loss: -10.9099 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0095 - val_reconstruction_loss: -11.4569\n",
      "Epoch 214/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0057 - reconstruction_loss: -10.9310 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0091 - val_reconstruction_loss: -11.4613\n",
      "Epoch 215/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0055 - reconstruction_loss: -10.9297 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0090 - val_reconstruction_loss: -11.4616\n",
      "Epoch 216/300\n",
      "59/59 [==============================] - 1s 22ms/step - mse_loss: 0.0053 - reconstruction_loss: -10.9357 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0088 - val_reconstruction_loss: -11.4610\n",
      "Epoch 217/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0052 - reconstruction_loss: -10.9357 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0088 - val_reconstruction_loss: -11.4620\n",
      "Epoch 218/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0052 - reconstruction_loss: -10.9255 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0089 - val_reconstruction_loss: -11.4599\n",
      "Epoch 219/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0053 - reconstruction_loss: -10.9342 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0090 - val_reconstruction_loss: -11.4604\n",
      "Epoch 220/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0052 - reconstruction_loss: -10.9338 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0092 - val_reconstruction_loss: -11.4612\n",
      "Epoch 221/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0053 - reconstruction_loss: -10.9460 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0087 - val_reconstruction_loss: -11.4596\n",
      "Epoch 222/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0054 - reconstruction_loss: -10.9456 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0091 - val_reconstruction_loss: -11.4613\n",
      "Epoch 223/300\n",
      "59/59 [==============================] - 1s 17ms/step - mse_loss: 0.0055 - reconstruction_loss: -10.9401 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0089 - val_reconstruction_loss: -11.4571\n",
      "Epoch 224/300\n",
      "59/59 [==============================] - 1s 22ms/step - mse_loss: 0.0054 - reconstruction_loss: -10.9378 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0089 - val_reconstruction_loss: -11.4616\n",
      "Epoch 225/300\n",
      "59/59 [==============================] - 1s 21ms/step - mse_loss: 0.0053 - reconstruction_loss: -10.9426 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0084 - val_reconstruction_loss: -11.4571\n",
      "Epoch 226/300\n",
      "59/59 [==============================] - 1s 21ms/step - mse_loss: 0.0052 - reconstruction_loss: -10.9389 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0089 - val_reconstruction_loss: -11.4612\n",
      "Epoch 227/300\n",
      "59/59 [==============================] - 1s 22ms/step - mse_loss: 0.0051 - reconstruction_loss: -10.9509 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0088 - val_reconstruction_loss: -11.4571\n",
      "Epoch 228/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0051 - reconstruction_loss: -10.9286 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0089 - val_reconstruction_loss: -11.4593\n",
      "Epoch 229/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0053 - reconstruction_loss: -10.9285 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0094 - val_reconstruction_loss: -11.4541\n",
      "Epoch 230/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0055 - reconstruction_loss: -10.9296 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0098 - val_reconstruction_loss: -11.4620\n",
      "Epoch 231/300\n",
      "59/59 [==============================] - 2s 31ms/step - mse_loss: 0.0059 - reconstruction_loss: -10.9332 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0089 - val_reconstruction_loss: -11.4544\n",
      "Epoch 232/300\n",
      "59/59 [==============================] - 2s 26ms/step - mse_loss: 0.0063 - reconstruction_loss: -10.9293 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0094 - val_reconstruction_loss: -11.4516\n",
      "Epoch 233/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0060 - reconstruction_loss: -10.9254 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0095 - val_reconstruction_loss: -11.4541\n",
      "Epoch 234/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0059 - reconstruction_loss: -10.9340 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0093 - val_reconstruction_loss: -11.4619\n",
      "Epoch 235/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0055 - reconstruction_loss: -10.9427 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0087 - val_reconstruction_loss: -11.4612\n",
      "Epoch 236/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0053 - reconstruction_loss: -10.9245 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0092 - val_reconstruction_loss: -11.4596\n",
      "Epoch 237/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0052 - reconstruction_loss: -10.9499 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0090 - val_reconstruction_loss: -11.4574\n",
      "Epoch 238/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0051 - reconstruction_loss: -10.9357 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0088 - val_reconstruction_loss: -11.4614\n",
      "Epoch 239/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0050 - reconstruction_loss: -10.9429 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0085 - val_reconstruction_loss: -11.4624\n",
      "Epoch 240/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0050 - reconstruction_loss: -10.9470 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0086 - val_reconstruction_loss: -11.4594\n",
      "Epoch 241/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0051 - reconstruction_loss: -10.9383 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0088 - val_reconstruction_loss: -11.4597\n",
      "Epoch 242/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0051 - reconstruction_loss: -10.9449 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0090 - val_reconstruction_loss: -11.4610\n",
      "Epoch 243/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0051 - reconstruction_loss: -10.9349 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0089 - val_reconstruction_loss: -11.4607\n",
      "Epoch 244/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0051 - reconstruction_loss: -10.9440 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0091 - val_reconstruction_loss: -11.4582\n",
      "Epoch 245/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0052 - reconstruction_loss: -10.9281 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0091 - val_reconstruction_loss: -11.4601\n",
      "Epoch 246/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0053 - reconstruction_loss: -10.9370 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0087 - val_reconstruction_loss: -11.4573\n",
      "Epoch 247/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0052 - reconstruction_loss: -10.9223 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0093 - val_reconstruction_loss: -11.4598\n",
      "Epoch 248/300\n",
      "59/59 [==============================] - 1s 23ms/step - mse_loss: 0.0053 - reconstruction_loss: -10.9429 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0093 - val_reconstruction_loss: -11.4589\n",
      "Epoch 249/300\n",
      "59/59 [==============================] - 1s 21ms/step - mse_loss: 0.0053 - reconstruction_loss: -10.9508 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0092 - val_reconstruction_loss: -11.4612\n",
      "Epoch 250/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0054 - reconstruction_loss: -10.9396 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0097 - val_reconstruction_loss: -11.4612\n",
      "Epoch 251/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0056 - reconstruction_loss: -10.9164 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0094 - val_reconstruction_loss: -11.4573\n",
      "Epoch 252/300\n",
      "59/59 [==============================] - 1s 17ms/step - mse_loss: 0.0056 - reconstruction_loss: -10.9168 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0091 - val_reconstruction_loss: -11.4612\n",
      "Epoch 253/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0055 - reconstruction_loss: -10.9404 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0091 - val_reconstruction_loss: -11.4595\n",
      "Epoch 254/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0052 - reconstruction_loss: -10.9469 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0090 - val_reconstruction_loss: -11.4569\n",
      "Epoch 255/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0051 - reconstruction_loss: -10.9429 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0091 - val_reconstruction_loss: -11.4600\n",
      "Epoch 256/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0051 - reconstruction_loss: -10.9264 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0092 - val_reconstruction_loss: -11.4590\n",
      "Epoch 257/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0051 - reconstruction_loss: -10.9317 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0088 - val_reconstruction_loss: -11.4598\n",
      "Epoch 258/300\n",
      "59/59 [==============================] - 1s 21ms/step - mse_loss: 0.0050 - reconstruction_loss: -10.9458 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0092 - val_reconstruction_loss: -11.4592\n",
      "Epoch 259/300\n",
      "59/59 [==============================] - 1s 21ms/step - mse_loss: 0.0049 - reconstruction_loss: -10.9280 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0089 - val_reconstruction_loss: -11.4596\n",
      "Epoch 260/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0049 - reconstruction_loss: -10.9461 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0088 - val_reconstruction_loss: -11.4586\n",
      "Epoch 261/300\n",
      "59/59 [==============================] - 1s 22ms/step - mse_loss: 0.0048 - reconstruction_loss: -10.9388 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0090 - val_reconstruction_loss: -11.4572\n",
      "Epoch 262/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0050 - reconstruction_loss: -10.9455 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0089 - val_reconstruction_loss: -11.4612\n",
      "Epoch 263/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0049 - reconstruction_loss: -10.9437 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0092 - val_reconstruction_loss: -11.4589\n",
      "Epoch 264/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0051 - reconstruction_loss: -10.9376 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0085 - val_reconstruction_loss: -11.4611\n",
      "Epoch 265/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0050 - reconstruction_loss: -10.9544 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0090 - val_reconstruction_loss: -11.4611\n",
      "Epoch 266/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0050 - reconstruction_loss: -10.9466 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0090 - val_reconstruction_loss: -11.4588\n",
      "Epoch 267/300\n",
      "59/59 [==============================] - 1s 17ms/step - mse_loss: 0.0051 - reconstruction_loss: -10.9302 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0099 - val_reconstruction_loss: -11.4566\n",
      "Epoch 268/300\n",
      "59/59 [==============================] - 1s 17ms/step - mse_loss: 0.0058 - reconstruction_loss: -10.9333 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0095 - val_reconstruction_loss: -11.4576\n",
      "Epoch 269/300\n",
      "59/59 [==============================] - 1s 21ms/step - mse_loss: 0.0060 - reconstruction_loss: -10.9366 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0100 - val_reconstruction_loss: -11.4498\n",
      "Epoch 270/300\n",
      "59/59 [==============================] - 1s 21ms/step - mse_loss: 0.0061 - reconstruction_loss: -10.9211 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0098 - val_reconstruction_loss: -11.4585\n",
      "Epoch 271/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0063 - reconstruction_loss: -10.9368 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0096 - val_reconstruction_loss: -11.4580\n",
      "Epoch 272/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0061 - reconstruction_loss: -10.9293 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0101 - val_reconstruction_loss: -11.4594\n",
      "Epoch 273/300\n",
      "59/59 [==============================] - 1s 17ms/step - mse_loss: 0.0055 - reconstruction_loss: -10.9436 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0096 - val_reconstruction_loss: -11.4579\n",
      "Epoch 274/300\n",
      "59/59 [==============================] - 1s 17ms/step - mse_loss: 0.0053 - reconstruction_loss: -10.9428 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0089 - val_reconstruction_loss: -11.4585\n",
      "Epoch 275/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0048 - reconstruction_loss: -10.9473 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0090 - val_reconstruction_loss: -11.4593\n",
      "Epoch 276/300\n",
      "59/59 [==============================] - 1s 20ms/step - mse_loss: 0.0047 - reconstruction_loss: -10.9504 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0090 - val_reconstruction_loss: -11.4598\n",
      "Epoch 277/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0046 - reconstruction_loss: -10.9219 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0088 - val_reconstruction_loss: -11.4572\n",
      "Epoch 278/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0045 - reconstruction_loss: -10.9344 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0087 - val_reconstruction_loss: -11.4590\n",
      "Epoch 279/300\n",
      "59/59 [==============================] - 1s 17ms/step - mse_loss: 0.0046 - reconstruction_loss: -10.9262 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0088 - val_reconstruction_loss: -11.4594\n",
      "Epoch 280/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0045 - reconstruction_loss: -10.9408 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0088 - val_reconstruction_loss: -11.4586\n",
      "Epoch 281/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0045 - reconstruction_loss: -10.9555 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0092 - val_reconstruction_loss: -11.4581\n",
      "Epoch 282/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0045 - reconstruction_loss: -10.9498 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0090 - val_reconstruction_loss: -11.4589\n",
      "Epoch 283/300\n",
      "59/59 [==============================] - 1s 17ms/step - mse_loss: 0.0045 - reconstruction_loss: -10.9465 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0090 - val_reconstruction_loss: -11.4579\n",
      "Epoch 284/300\n",
      "59/59 [==============================] - 1s 17ms/step - mse_loss: 0.0046 - reconstruction_loss: -10.9209 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0091 - val_reconstruction_loss: -11.4596\n",
      "Epoch 285/300\n",
      "59/59 [==============================] - 2s 30ms/step - mse_loss: 0.0046 - reconstruction_loss: -10.9372 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0091 - val_reconstruction_loss: -11.4584\n",
      "Epoch 286/300\n",
      "59/59 [==============================] - 1s 17ms/step - mse_loss: 0.0047 - reconstruction_loss: -10.9470 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0092 - val_reconstruction_loss: -11.4572\n",
      "Epoch 287/300\n",
      "59/59 [==============================] - 1s 17ms/step - mse_loss: 0.0046 - reconstruction_loss: -10.9385 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0093 - val_reconstruction_loss: -11.4579\n",
      "Epoch 288/300\n",
      "59/59 [==============================] - 1s 17ms/step - mse_loss: 0.0049 - reconstruction_loss: -10.9362 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0095 - val_reconstruction_loss: -11.4584\n",
      "Epoch 289/300\n",
      "59/59 [==============================] - 1s 17ms/step - mse_loss: 0.0050 - reconstruction_loss: -10.9455 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0094 - val_reconstruction_loss: -11.4551\n",
      "Epoch 290/300\n",
      "59/59 [==============================] - 1s 17ms/step - mse_loss: 0.0049 - reconstruction_loss: -10.9349 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0091 - val_reconstruction_loss: -11.4583\n",
      "Epoch 291/300\n",
      "59/59 [==============================] - 1s 18ms/step - mse_loss: 0.0048 - reconstruction_loss: -10.9463 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0096 - val_reconstruction_loss: -11.4565\n",
      "Epoch 292/300\n",
      "59/59 [==============================] - 1s 17ms/step - mse_loss: 0.0049 - reconstruction_loss: -10.9289 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0096 - val_reconstruction_loss: -11.4556\n",
      "Epoch 293/300\n",
      "59/59 [==============================] - 1s 17ms/step - mse_loss: 0.0048 - reconstruction_loss: -10.9362 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0095 - val_reconstruction_loss: -11.4588\n",
      "Epoch 294/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0049 - reconstruction_loss: -10.9408 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0090 - val_reconstruction_loss: -11.4590\n",
      "Epoch 295/300\n",
      "59/59 [==============================] - 1s 17ms/step - mse_loss: 0.0048 - reconstruction_loss: -10.9335 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0092 - val_reconstruction_loss: -11.4570\n",
      "Epoch 296/300\n",
      "59/59 [==============================] - 1s 17ms/step - mse_loss: 0.0047 - reconstruction_loss: -10.9257 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0094 - val_reconstruction_loss: -11.4601\n",
      "Epoch 297/300\n",
      "59/59 [==============================] - 1s 17ms/step - mse_loss: 0.0048 - reconstruction_loss: -10.9415 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0095 - val_reconstruction_loss: -11.4573\n",
      "Epoch 298/300\n",
      "59/59 [==============================] - 1s 19ms/step - mse_loss: 0.0049 - reconstruction_loss: -10.9336 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0099 - val_reconstruction_loss: -11.4588\n",
      "Epoch 299/300\n",
      "59/59 [==============================] - 1s 23ms/step - mse_loss: 0.0048 - reconstruction_loss: -10.9400 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0096 - val_reconstruction_loss: -11.4573\n",
      "Epoch 300/300\n",
      "59/59 [==============================] - 1s 21ms/step - mse_loss: 0.0049 - reconstruction_loss: -10.9441 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0093 - val_reconstruction_loss: -11.4554\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    if model_is_VAE:\n",
    "        model = VAE(False, input_shape, multiplier, latent_size)\n",
    "    else:\n",
    "        model = UPAE(True, input_shape, multiplier, latent_size)\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model.build(input_shape=(None,) + tuple(input_shape))\n",
    "\n",
    "    model.compile(optimizer= optimizer, loss='mse'\n",
    "                  ,metrics=[tf.keras.metrics.Accuracy()])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    try:\n",
    "        model.load_weights(model_file_path + \"/model_weights\")\n",
    "        no_plots = True\n",
    "    except:\n",
    "        no_plots = False\n",
    "        train_data = image_datasets['train']\n",
    "        validation_data = image_datasets['valid']\n",
    "\n",
    "        # Where images of each epoch will be saved\n",
    "        save_directory = model_file_path + '/callback_images'\n",
    "        save_callback = SaveImageCallback(validation_data, save_directory=save_directory, vae=model_is_VAE)\n",
    "\n",
    "        EarlyStopping_callback = tf.keras.callbacks.EarlyStopping(monitor='mse_loss', patience=30,\n",
    "                                                                  restore_best_weights=True)\n",
    "\n",
    "        history_train = model.fit(train_data, \n",
    "                                epochs=epochs, \n",
    "                                batch_size=batch_size,\n",
    "                                validation_data=(validation_data, validation_data),\n",
    "                                callbacks=[save_callback, EarlyStopping_callback])\n",
    "        \n",
    "        # Saving the model's history\n",
    "        json.dump(history_train.history, open(model_file_path + '/history.json', 'w'))\n",
    "\n",
    "        #Save weights\n",
    "        model.save_weights(model_file_path + '/model_weights')\n",
    "   \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "076f2a29",
   "metadata": {},
   "source": [
    "# Creating of different Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8d99aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory for saving images\n",
    "save_directory = model_file_path + '/plots'\n",
    "if not os.path.exists(save_directory):\n",
    "    os.makedirs(save_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "813a0288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plot(history, metric, title, save_name):\n",
    "    x = range(50, len(history[metric]))\n",
    "    plt.plot(x, history[metric][50:], label=metric)\n",
    "    plt.plot(x, history[f'val_{metric}'][50:], label=f'val_{metric}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(metric)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{save_directory}/{save_name}', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "# Check if UPAE or not\n",
    "\n",
    "if no_plots:\n",
    "    pass\n",
    "elif model_is_VAE:\n",
    "    # Get history of data\n",
    "    history = history_train.history\n",
    "    # Create plot for mse_loss\n",
    "    create_plot(history, 'mse_loss', 'MSE Loss per Epoch', 'mse_loss.png')\n",
    "    # Create plot for reconstruction_loss\n",
    "    create_plot(history, 'reconstruction_loss', 'Reconstruction Loss per Epoch', 'reconstruction_loss.png')\n",
    "else:\n",
    "    # Get history of data\n",
    "    history = history_train.history\n",
    "    # Create plot for mse_loss\n",
    "    create_plot(history, 'mse_loss', 'MSE Loss per Epoch', 'mse_loss.png')\n",
    "    # Create plot for total loss\n",
    "    create_plot(history, 'total_loss', 'Total Loss per Epoch', 'total_loss.png')\n",
    "    # Create plot for loss1\n",
    "    create_plot(history, 'loss1', 'Loss 1 per Epoch', 'loss1.png')\n",
    "    # Create plot for loss2\n",
    "    create_plot(history, 'loss2', 'Loss 2 per Epoch', 'loss2.png')\n",
    "    # Create plot for binary_crossentropy\n",
    "#     create_plot(history, 'reconstruction_loss', 'Reconstruction Loss per Epoch', 'reconstruction_loss.png')\n",
    "#     # Create plot for accuracy\n",
    "#     create_plot(history, 'accuracy', 'Accuracy per Epoch', 'accuracy.png')\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b73f60ee",
   "metadata": {},
   "source": [
    "# Testing of the Model with the Test Set\n",
    "This section tests the model with the current test set\n",
    "TODO: \n",
    "- Get the label of each image in the test set\n",
    "- Test the images\n",
    "- Create Linear Regression for the abnormality score to get the threshold for determining abnormal or normal images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fbf61ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get labels of each image in the image_datasets['test']\n",
    "test_images = []\n",
    "labels = []\n",
    "for image_path in glob.glob(f'{dataset_file_path}/test/*.png'):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # image = normalize_image(image)\n",
    "    # Get if it contains positive or negative\n",
    "    if 'positive' in image_path:\n",
    "        test_images.append(image)\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        test_images.append(image)\n",
    "        labels.append(0)\n",
    "test_images = np.array(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7071dba6",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'reconstructed_float32' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history_valid \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(test_images, batch_size\u001b[39m=\u001b[39;49mbatch_size)\n",
      "File \u001b[1;32md:\\GithubRepos\\MURA-Classification\\models.py:268\u001b[0m, in \u001b[0;36mVAE.predict\u001b[1;34m(self, data, batch_size, forCallback)\u001b[0m\n\u001b[0;32m    265\u001b[0m reconstructed\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder_decoder(batch_data)\n\u001b[0;32m    267\u001b[0m \u001b[39m# Denormalize the image\u001b[39;00m\n\u001b[1;32m--> 268\u001b[0m reconstructed_float32 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdenormalize_image(reconstructed_float32)\n\u001b[0;32m    269\u001b[0m batch_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdenormalize_image(batch_data)\n\u001b[0;32m    272\u001b[0m \u001b[39m# reconstructed_float32 = tf.cast(reconstructed, tf.float32)\u001b[39;00m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'reconstructed_float32' referenced before assignment"
     ]
    }
   ],
   "source": [
    "history_valid = model.predict(test_images, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf1a839",
   "metadata": {},
   "outputs": [],
   "source": [
    "abnor_scores = history_valid[1]\n",
    "#converting to an array of numbers instead of tensor\n",
    "abnor_scores = [item.numpy() for item in abnor_scores if isinstance(item, tf.Tensor)]\n",
    "abnor_scores = [float(item) for item in abnor_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51319bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "abnor_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982d20ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = metrics.roc_auc_score(labels, abnor_scores)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(labels, abnor_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e864f539",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b41e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(labels, abnor_scores)\n",
    "idx = None\n",
    "min_diff = float('inf')\n",
    "for i in range(len(fpr)):\n",
    "    fnr = 1 - tpr[i]\n",
    "    diff = abs(fpr[i] - fnr)\n",
    "    if diff <= 5e-3:\n",
    "        idx = i\n",
    "        break\n",
    "    elif diff < min_diff:\n",
    "        min_diff = diff\n",
    "        idx = i\n",
    "assert idx is not None\n",
    "t = thresholds[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33476c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using threshold t , will be used to classify abnormality scores as normal or abnormal in the y_pred array;\n",
    "y_pred = np.zeros_like(labels)\n",
    "y_pred[abnor_scores < t] = 0\n",
    "y_pred[abnor_scores >= t] = 1\n",
    "\n",
    "\n",
    "# getting metrics score using y_pred which is now either 0  or 1\n",
    "pres = metrics.precision_score(labels, y_pred)\n",
    "sens = metrics.recall_score(labels, y_pred, pos_label=1)\n",
    "spec = metrics.recall_score(labels, y_pred, pos_label=0)\n",
    "f1 = metrics.f1_score(labels, y_pred)\n",
    "error_rate = fpr[idx]\n",
    "\n",
    "metrics_dict = {\n",
    "    \"Error rate\": error_rate,\n",
    "    \"Precision\": pres,\n",
    "    \"Sensitivity\": sens,\n",
    "    \"Specificity\": spec,\n",
    "    \"F1 score\": f1\n",
    "}\n",
    "\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Error rate: {}\".format(error_rate))\n",
    "print(\"Precision: {}\".format(pres))\n",
    "print(\"Sensitivity: {}\".format(sens))\n",
    "print(\"Specificity: {}\".format(spec))\n",
    "print(\"F1 score: {}\".format(f1))\n",
    "\n",
    "# Save the metrics to a JSON file\n",
    "with open(f\"{save_directory}/metrics.json\", \"w\") as json_file:\n",
    "    json.dump(metrics_dict, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99154c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(save_directory)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e380c523",
   "metadata": {},
   "source": [
    "# Creating Plot for abnormality scores of normal and abnormal images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed22a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram for Positives and Negatives of the testing set\n",
    "positive = []\n",
    "negative = []\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] == 1:\n",
    "        positive.append(abnor_scores[i])\n",
    "    else:\n",
    "        negative.append(abnor_scores[i])\n",
    "\n",
    "plt.hist(negative, color='blue', label='negative', bins=20)\n",
    "plt.hist(positive, color='red', label='positive', bins=20)\n",
    "\n",
    "# Get x and y labels\n",
    "plt.xlabel('Abnormality Score')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title(\"Abnormality Score and Correct Label Histogram\")\n",
    "plt.legend()\n",
    "plt.savefig(f'{save_directory}/testing_abnormality_scores.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca7b6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = []\n",
    "negative = []\n",
    "for i in range(len(labels)):\n",
    "    if abnor_scores[i] == 1:\n",
    "        positive.append(abnor_scores[i])\n",
    "    else:\n",
    "        negative.append(abnor_scores[i])\n",
    "\n",
    "\n",
    "plt.hist(positive, color='red', label='positive', bins=20)\n",
    "plt.hist(negative, color='blue', label='negative', bins=20)\n",
    "\n",
    "# Get x and y labels\n",
    "plt.xlabel('Abnormality Score')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title(\"Abnormality Score and Prediction Label Histogram\")\n",
    "plt.legend()\n",
    "plt.savefig(f'{save_directory}/testing_abnormality_scores_prediction.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f5369b0",
   "metadata": {},
   "source": [
    "# Saving of final reconstructed images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154822a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory in models folder for reconstructed images\n",
    "dataset_name = dataset_file_path.split('/')[-1]\n",
    "reconstructed_images_path = model_file_path + \"/\" + dataset_name\n",
    "if not path.exists(reconstructed_images_path):\n",
    "    mkdir(reconstructed_images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597def40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_compared_reconstructed_image(original_image, reconstructed_image, abnormality_score, file_path, image_index,\n",
    "                                      label, variance = None):\n",
    "    # Put Images in cv2\n",
    "    original_image = cv2.cvtColor(original_image, cv2.COLOR_GRAY2BGR)\n",
    "    reconstructed_image = cv2.cvtColor(reconstructed_image, cv2.COLOR_GRAY2BGR)\n",
    "    # Convert reconstructed image to uint8\n",
    "    reconstructed_image = reconstructed_image.astype(np.uint8)\n",
    "    # Denormalize all images\n",
    "    # original_image = denormalize_image(original_image)\n",
    "    # reconstructed_image = denormalize_image(reconstructed_image)\n",
    "\n",
    "    if variance is not None:\n",
    "        variance_image = cv2.cvtColor(variance, cv2.COLOR_GRAY2BGR)\n",
    "        variance_image = variance_image.astype(np.uint8)\n",
    "\n",
    "        reconstructed_variance_sub = np.abs(reconstructed_image - variance_image)\n",
    "\n",
    "        reconstruction_error = np.abs(original_image - reconstructed_variance_sub)\n",
    "        \n",
    "        # variance_image = denormalize_image(variance_image)\n",
    "        concatenated_img = cv2.hconcat((original_image, reconstructed_image, variance_image, reconstructed_variance_sub, \n",
    "                                        reconstruction_error))\n",
    "    else:\n",
    "        reconstruction_error = np.abs(original_image - reconstructed_image)\n",
    "        concatenated_img = cv2.hconcat((original_image, reconstructed_image, reconstruction_error))\n",
    "    # Save the image\n",
    "    cv2.imwrite(f'{file_path}/Image_{image_index}_{abnormality_score}_{label}.png', concatenated_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30e1b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_images)):\n",
    "    if model_is_VAE:\n",
    "        save_compared_reconstructed_image(test_images[i], np.array(history_valid[0][i]), history_valid[1][i],\n",
    "                                      reconstructed_images_path, i, labels[i])\n",
    "    else:\n",
    "        save_compared_reconstructed_image(test_images[i], np.array(history_valid[0][i]), history_valid[1][i],\n",
    "                                      reconstructed_images_path, i, labels[i],  np.array(history_valid[2][i]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d41fb188",
   "metadata": {},
   "source": [
    "# GIF for Callback_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d17c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_epoch(filename):\n",
    "    match = re.search(r'epoch_(\\d+)', filename)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return 0\n",
    "\n",
    "def create_gif(folder_path, output_path, duration=50):\n",
    "    images = []\n",
    "    \n",
    "    # Get all image file names from the folder\n",
    "    filenames = os.listdir(folder_path)\n",
    "    filenames = sorted(filenames, key=lambda x: extract_epoch(x))\n",
    "\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.png') or filename.endswith('.jpg'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            image = Image.open(file_path).convert('P')\n",
    "            images.append(image)\n",
    "    \n",
    "    # Save the images as a GIF\n",
    "    images[0].save(output_path, save_all=True, append_images=images[1:], optimize=False, duration=duration, loop=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafb861c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gif_folder_path = model_file_path + \"/\" + \"callback_images\"\n",
    "image_folders = ['image0', 'image1', 'image2']\n",
    "\n",
    "for i,folder in enumerate(image_folders):\n",
    "    curr_folder = gif_folder_path + \"/\" + folder\n",
    "    gif_output_path = gif_folder_path + \"/\" + f\"image{i}.gif\"\n",
    "    print(f\"Creating GIF for: image{i}\")\n",
    "    create_gif(curr_folder, gif_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87650927",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f17747",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
