{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "2bc86acd",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78b7f7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-20 12:20:32.721536: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-20 12:20:32.919233: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-20 12:20:32.940268: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-20 12:20:35.098756: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/cara/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import MURA\n",
    "import cv2\n",
    "import image_manipulation\n",
    "from multiprocessing import Pool\n",
    "from models import *\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import preprocessing\n",
    "import json\n",
    "from os import path, mkdir\n",
    "\n",
    "import keras\n",
    "from argparse import ArgumentParser\n",
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
=======
>>>>>>> origin/main
   "id": "22e578b7",
   "metadata": {},
   "source": [
    "# Model to Run\n",
    "This section lets the user edit on what model parameters to run, the model directory and parameters should exist prior to changing the file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afd350f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All editable variables\n",
    "model_file_path = \"models/model_3\"\n",
    "# If preprocessing needs to run\n",
    "run_preprocessing = False\n",
    "load_model = True\n",
    "save_weights = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2bc86acd",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "78b7f7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import MURA\n",
    "import cv2\n",
    "import image_manipulation\n",
    "from multiprocessing import Pool\n",
    "from models import *\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import preprocessing\n",
    "import json\n",
    "from os import path, mkdir\n",
    "from PIL import Image\n",
    "import re\n",
    "\n",
    "import keras\n",
    "from argparse import ArgumentParser\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5b73251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model parameters\n",
    "try:\n",
    "    params = json.load(open(model_file_path + '/parameters.json'))\n",
    "\n",
    "    # Model to use\n",
    "    model_is_VAE = params['is_VAE']\n",
    "    # Model parameters\n",
    "    multiplier = params['multiplier']\n",
    "    latent_size = params['latent_size']\n",
    "    input_shape = params['input_shape']\n",
    "\n",
    "    # Training parameters\n",
    "    epochs = params['num_epochs']\n",
    "    batch_size = params['batch_size']\n",
    "    learning_rate = params['learning_rate']\n",
    "\n",
    "    # Dataset Path\n",
    "    image_paths = MURA.MURA_DATASET()\n",
    "    dataset_file_path = params['dataset_path']\n",
    "    all_image_paths = image_paths.get_combined_image_paths()\n",
    "    all_image_paths = all_image_paths.to_numpy()[:,0]\n",
    "except:\n",
    "    raise Exception(\"No parameters.json file found in the model's directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dd25378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do preprocessing\n",
    "if run_preprocessing:\n",
    "    preprocess = preprocessing.preprocessing(input_path = all_image_paths, output_path = dataset_file_path)\n",
    "    if __name__ == '__main__':\n",
    "        preprocess.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae204155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each array contains the training, validation, and testing in order\n",
    "image_datasets = {'train': []}\n",
    "for dataset_name in image_datasets.keys():\n",
    "    for image_path in glob.glob(f'{dataset_file_path}/{dataset_name}/*.png'):\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image_datasets[dataset_name].append(image)\n",
    "    image_datasets[dataset_name] = np.array(image_datasets[dataset_name])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f69e69d0",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "This section creates and trains the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f906dcd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder_decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 64)        1088      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32, 32, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 16, 128)       131200    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16, 16, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 8, 256)         524544    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 8, 8, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 4, 4, 256)         1048832   \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 4, 4, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2048)              8390656   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 2048)             8192      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                131136    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2048)              133120    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 2048)             8192      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4096)              8392704   \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 8, 8, 256)        262400    \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 8, 8, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 16, 16, 128)      524416    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 16, 16, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 32, 32, 64)       131136    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 32, 32, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 64, 64, 2)        2050      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " encoder (Sequential)        (None, 4096)              1708480   \n",
      "                                                                 \n",
      " latent_encoder (Sequential)  (None, 64)               8529984   \n",
      "                                                                 \n",
      " z_mean (Dense)              multiple                  4160      \n",
      "                                                                 \n",
      " z_log_var (Dense)           multiple                  4160      \n",
      "                                                                 \n",
      " latent_decoder (Sequential)  (None, 4, 4, 256)        8534016   \n",
      "                                                                 \n",
      " decoder (Sequential)        (None, 64, 64, 2)         921794    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,702,594\n",
      "Trainable params: 19,692,098\n",
      "Non-trainable params: 10,496\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "2023-05-20 12:23:52.706269: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-05-20 12:23:53.107930: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 33554432 exceeds 10% of free system memory.\n",
      "2023-05-20 12:23:53.149808: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 33554432 exceeds 10% of free system memory.\n",
      "2023-05-20 12:23:53.164453: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 33554432 exceeds 10% of free system memory.\n",
      "2023-05-20 12:23:53.278125: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 33554432 exceeds 10% of free system memory.\n",
      "2023-05-20 12:23:53.313286: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 33554432 exceeds 10% of free system memory.\n"
=======
      "c:\\Users\\SKill\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
>>>>>>> origin/main
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"upae\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_decoder (encoder_de  multiple                 19702594  \n",
      " coder)                                                          \n",
      "                                                                 \n",
      "=================================================================\n",
<<<<<<< HEAD
      "Total params: 19,946,439\n",
      "Trainable params: 19,935,937\n",
      "Non-trainable params: 10,502\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "Vanilla Loss\n",
      "Data Shape:  (None, 64, 64)\n",
      "Reconstructed Shape:  (None, 64, 64)\n",
      "Vanilla Loss\n",
      "Data Shape:  (None, 64, 64)\n",
      "Reconstructed Shape:  (None, 64, 64)\n",
      "38/38 [==============================] - ETA: 0s - mse_loss: 7263.5889 - reconstruction_loss: -53.9568 - kl_loss: 0.0000e+004\n",
      "callback predict\n",
      "38/38 [==============================] - 48s 1s/step - mse_loss: 7263.5889 - reconstruction_loss: -53.9568 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00\n",
      "Epoch 2/3\n",
      "38/38 [==============================] - ETA: 0s - mse_loss: 2769.8525 - reconstruction_loss: -807.8527 - kl_loss: 0.0000e+004\n",
      "callback predict\n",
      "38/38 [==============================] - 53s 1s/step - mse_loss: 2769.8525 - reconstruction_loss: -807.8527 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00\n",
      "Epoch 3/3\n",
      "38/38 [==============================] - ETA: 0s - mse_loss: 1943.5594 - reconstruction_loss: -873.5311 - kl_loss: 0.0000e+004\n",
      "callback predict\n",
      "38/38 [==============================] - 44s 1s/step - mse_loss: 1943.5594 - reconstruction_loss: -873.5311 - kl_loss: 0.0000e+00 - val_mse_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00\n"
=======
      "Total params: 19,702,606\n",
      "Trainable params: 19,692,098\n",
      "Non-trainable params: 10,508\n",
      "_________________________________________________________________\n"
>>>>>>> origin/main
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    if model_is_VAE:\n",
    "        model = VAE(False, input_shape, multiplier, latent_size)\n",
    "    else:\n",
    "        model = UPAE(True, input_shape, multiplier, latent_size)\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model.build(input_shape=(None,) + tuple(input_shape))\n",
    "\n",
    "    model.compile(optimizer= optimizer, loss='mse'\n",
    "                  ,metrics=[tf.keras.metrics.Accuracy()])\n",
    "    \n",
    "    model.summary()\n",
    "\n",
    "    # Where images of each epoch will be saved\n",
    "    # save_directory = 'Images/images_epochs' #edited in models where automatically make folder if non existent\n",
    "    save_directory = model_file_path + '/callback_images'\n",
    "    save_callback = SaveImageCallback(image_datasets['train'], save_directory=save_directory)\n",
    "    \n",
    "    if load_model:\n",
    "        model.load_weights(model_file_path + '/model_weights')\n",
    "    else:\n",
    "        history_train = model.fit(image_datasets['train'], \n",
    "            epochs=epochs, \n",
    "            batch_size=batch_size,\n",
    "            validation_split=0.15,\n",
    "            callbacks=[save_callback])\n",
    "   \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b73f60ee",
   "metadata": {},
   "source": [
    "# Testing of the Model with the Test Set\n",
    "This section tests the model with the current test set\n",
    "TODO: \n",
    "- Get the label of each image in the test set\n",
    "- Test the images\n",
    "- Create Linear Regression for the abnormality score to get the threshold for determining abnormal or normal images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fbf61ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get labels of each image in the image_datasets['test']\n",
    "test_images = []\n",
    "labels = []\n",
    "for image_path in glob.glob(f'{dataset_file_path}/test/*.png'):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Get if it contains positive or negative\n",
    "    if 'positive' in image_path:\n",
    "        test_images.append(image)\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        test_images.append(image)\n",
    "        labels.append(0)\n",
    "test_images = np.array(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7071dba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not callback predict\n"
     ]
    }
   ],
   "source": [
    "reconstructed_images = model.predict(test_images, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddf1a839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histogram for Positives and Negatives of the testing set\n",
    "positive = []\n",
    "negative = []\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] == 1:\n",
    "        positive.append(reconstructed_images[1][i])\n",
    "    else:\n",
    "        negative.append(reconstructed_images[1][i])\n",
    "plt.hist(positive, color='red', label='positive')\n",
    "plt.hist(negative, color='blue', label='negative')\n",
    "# Get x and y labels\n",
    "plt.xlabel('Abnormality Score')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.legend()\n",
    "plt.savefig(f'{model_file_path}/testing_abnormality_scores.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa833ecb",
   "metadata": {},
   "source": [
    "# Getting of best threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ff3753dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image(score, threshold):\n",
    "    if score >= threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def get_threshold_range(abnormality_scores, num_std):\n",
    "    mean_score = np.mean(abnormality_scores)\n",
    "    std_score = np.std(abnormality_scores)\n",
    "\n",
    "    lower_threshold = mean_score - (num_std * std_score)\n",
    "    upper_threshold = mean_score + (num_std * std_score)\n",
    "\n",
    "    return lower_threshold, upper_threshold\n",
    "\n",
    "def calculate_f1_score(predicted_labels, true_labels):\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "\n",
    "    for predicted, true in zip(predicted_labels, true_labels):\n",
    "        if predicted == 1 and true == 1:\n",
    "            true_positives += 1\n",
    "        elif predicted == 1 and true == 0:\n",
    "            false_positives += 1\n",
    "        elif predicted == 0 and true == 1:\n",
    "            false_negatives += 1\n",
    "\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    return f1_score, precision, recall, true_positives, false_positives, false_negatives\n",
    "\n",
    "def find_optimal_threshold(abnormality_scores, labels):\n",
    "    best_threshold = None\n",
    "    best_metric = 0.0\n",
    "\n",
    "    # Get a range of threshold values\n",
    "    lower_threshold, upper_threshold = get_threshold_range(abnormality_scores, num_std=3)\n",
    "    threshold_range = np.linspace(lower_threshold, upper_threshold, 50)\n",
    "\n",
    "    \n",
    "    # Iterate over a range of threshold values\n",
    "    for threshold in threshold_range:\n",
    "        predicted_labels = [classify_image(score, threshold) for score in abnormality_scores]\n",
    "\n",
    "        # Evaluate performance metric (e.g., accuracy, precision, recall, F1 score)\n",
    "        metric, precision, recall, true_postivies, false_positives, false_negatives = calculate_f1_score(predicted_labels, labels)\n",
    "\n",
    "        # Update the best threshold if the metric improves\n",
    "        if metric > best_metric:\n",
    "            print(\"Current best Threshold: \", threshold, \"\\nCurrent best F1 Score: \", metric)\n",
    "            print(\"Current best Precision: \", precision, \"\\nCurrent best Recall: \", recall)\n",
    "            print(\"\\nCurrent best True Positives: \", true_postivies, \"\\nCurrent best False Positives: \", \n",
    "                  false_positives, \"\\nCurrent best False Negatives: \", false_negatives)\n",
    "            print()\n",
    "            best_metric = metric\n",
    "            best_threshold = threshold\n",
    "\n",
    "\n",
    "    return best_threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dcb40386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current best Threshold:  -12.835132598876953 \n",
      "Current best F1 Score:  0.8824539144712291\n",
      "Current best Precision:  0.78963536797115 \n",
      "Current best Recall:  1.0\n",
      "\n",
      "Current best True Positives:  5912 \n",
      "Current best False Positives:  1575 \n",
      "Current best False Negatives:  0\n",
      "\n",
      "Current best Threshold:  1.7968779583366548 \n",
      "Current best F1 Score:  0.8829731548642786\n",
      "Current best Precision:  0.7913148371531966 \n",
      "Current best Recall:  0.9986468200270636\n",
      "\n",
      "Current best True Positives:  5904 \n",
      "Current best False Positives:  1557 \n",
      "Current best False Negatives:  8\n",
      "\n",
      "Current best Threshold:  2.9224172319684705 \n",
      "Current best F1 Score:  0.883630372921971\n",
      "Current best Precision:  0.7927976350443429 \n",
      "Current best Recall:  0.9979702300405954\n",
      "\n",
      "Current best True Positives:  5900 \n",
      "Current best False Positives:  1542 \n",
      "Current best False Negatives:  12\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.9224172319684705"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_optimal_threshold(np.float32(reconstructed_images[1]), labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f5369b0",
   "metadata": {},
   "source": [
    "# Saving of final reconstructed images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "154822a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory in models folder for reconstructed images\n",
    "dataset_name = dataset_file_path.split('/')[-1]\n",
    "reconstructed_images_path = model_file_path + \"/\" + dataset_name\n",
    "if not path.exists(reconstructed_images_path):\n",
    "    mkdir(reconstructed_images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "597def40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_compared_reconstructed_image(original_image, reconstructed_image, abnormality_score, file_path, image_index,\n",
    "                                      label):\n",
    "    # Put Images in cv2\n",
    "    original_image = cv2.cvtColor(original_image, cv2.COLOR_GRAY2BGR)\n",
    "    reconstructed_image = cv2.cvtColor(reconstructed_image, cv2.COLOR_GRAY2BGR)\n",
    "    # Convert reconstructed image to uint8\n",
    "    reconstructed_image = reconstructed_image.astype(np.uint8)\n",
    "    concatenated_img = cv2.hconcat([original_image, reconstructed_image])\n",
    "    # Save the image\n",
    "    cv2.imwrite(f'{file_path}/Image_{image_index}_{abnormality_score}_{label}.png', concatenated_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d30e1b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_images)):\n",
    "    save_compared_reconstructed_image(test_images[i], np.array(reconstructed_images[0][i]), reconstructed_images[1][i],\n",
    "                                      reconstructed_images_path, i, labels[i])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d41fb188",
   "metadata": {},
   "source": [
    "# GIF for Callback_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "70d17c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_epoch(filename):\n",
    "    match = re.search(r'epoch_(\\d+)_', filename)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return 0\n",
    "\n",
    "def create_gif(folder_path, output_path, duration=50):\n",
    "    images = []\n",
    "    \n",
    "    # Get all image file names from the folder\n",
    "    filenames = os.listdir(folder_path)\n",
    "    filenames = sorted(filenames, key=lambda x: extract_epoch(x))\n",
    "\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.png') or filename.endswith('.jpg'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            image = Image.open(file_path)\n",
    "            images.append(image)\n",
    "    \n",
    "    # Save the images as a GIF\n",
    "    images[0].save(output_path, save_all=True, append_images=images[1:], optimize=False, duration=duration, loop=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dafb861c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating GIF for: image0\n",
      "Creating GIF for: image1\n",
      "Creating GIF for: image2\n",
      "Creating GIF for: image3\n"
     ]
    }
   ],
   "source": [
    "gif_folder_path = model_file_path + \"/\" + \"callback_images\"\n",
    "image_folders = ['image0', 'image1', 'image2', 'image3']\n",
    "\n",
    "for i,folder in enumerate(image_folders):\n",
    "    curr_folder = gif_folder_path + \"/\" + folder\n",
    "    gif_output_path = gif_folder_path + \"/\" + f\"image{i}.gif\"\n",
    "    print(f\"Creating GIF for: image{i}\")\n",
    "    create_gif(curr_folder, gif_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0a807607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models/model_3'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_file_path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72b430df",
   "metadata": {},
   "source": [
    "# Saving of Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "324861d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_weights:\n",
    "    model.save_weights(model_file_path + '/model_weights', save_format='tf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
