{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2bc86acd",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78b7f7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SKill\\anaconda3\\envs\\DL\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import MURA\n",
    "import cv2\n",
    "import image_manipulation\n",
    "from multiprocessing import Pool\n",
    "from models import *\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import preprocessing\n",
    "import json\n",
    "from os import path, mkdir\n",
    "import re\n",
    "from PIL import Image\n",
    "\n",
    "import keras\n",
    "from argparse import ArgumentParser\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c6deaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 9617764141396365167\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5718933504\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 14985457751044948844\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:2d:00.0, compute capability: 8.6\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "22e578b7",
   "metadata": {},
   "source": [
    "# Model to Run\n",
    "This section lets the user edit on what model parameters to run, the model directory and parameters should exist prior to changing the file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afd350f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All editable variables\n",
    "model_file_path = \"models/UPAE/dataset_2_quantization\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5b73251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model parameters\n",
    "try:\n",
    "    params = json.load(open(model_file_path + '/parameters.json'))\n",
    "\n",
    "    # Model to use\n",
    "    model_is_VAE = params['is_VAE']\n",
    "    # Model parameters\n",
    "    multiplier = params['multiplier']\n",
    "    latent_size = params['latent_size']\n",
    "    input_shape = params['input_shape']\n",
    "\n",
    "    # Training parameters\n",
    "    epochs = params['num_epochs']\n",
    "    batch_size = params['batch_size']\n",
    "    learning_rate = params['learning_rate']\n",
    "\n",
    "    # Dataset Path\n",
    "    dataset_file_path = params['dataset_path']\n",
    "\n",
    "except:\n",
    "    raise Exception(\"No parameters.json file found in the model's directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae204155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each array contains the training, validation, and testing in order\n",
    "image_datasets = {'train': [], 'test': [], 'valid': []}\n",
    "for dataset_name in image_datasets.keys():\n",
    "    for image_path in glob.glob(f'{dataset_file_path}/{dataset_name}/*.png'):\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image_datasets[dataset_name].append(image)\n",
    "    image_datasets[dataset_name] = np.array(image_datasets[dataset_name])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f69e69d0",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "This section creates and trains the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed03caa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder_decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 128)       2048      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32, 32, 128)      512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 16, 256)       524288    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16, 16, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 8, 512)         2097152   \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 8, 8, 512)        2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 4, 4, 512)         4194304   \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 4, 4, 512)        2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2048)              16777216  \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 2048)             8192      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               262144    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2048)              264192    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 2048)             8192      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8192)              16777216  \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 8, 8, 512)        1048576   \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 8, 8, 512)        2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 16, 16, 256)      2097152   \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 16, 16, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 32, 32, 128)      524288    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 32, 32, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 64, 64, 2)        4096      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " encoder (Sequential)        (None, 8192)              6823424   \n",
      "                                                                 \n",
      " latent_encoder (Sequential)  (None, 128)              17047552  \n",
      "                                                                 \n",
      " z_mean (Dense)              multiple                  16512     \n",
      "                                                                 \n",
      " z_log_var (Dense)           multiple                  16512     \n",
      "                                                                 \n",
      " latent_decoder (Sequential)  (None, 4, 4, 512)        17049600  \n",
      "                                                                 \n",
      " decoder (Sequential)        (None, 64, 64, 2)         3677696   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,631,296\n",
      "Trainable params: 44,618,496\n",
      "Non-trainable params: 12,800\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SKill\\anaconda3\\envs\\DL\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"upae\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_decoder (encoder_de  multiple                 44631296  \n",
      " coder)                                                          \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,631,308\n",
      "Trainable params: 44,618,496\n",
      "Non-trainable params: 12,812\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "59/59 [==============================] - 8s 72ms/step - mse_loss: 4149.2256 - total_loss: 124.9200 - loss1: 89.0828 - loss2: 35.8372 - reconstruction_loss: -375.3545 - accuracy: 0.0368 - val_mse_loss: 2416.9717 - val_total_loss: 12.4415 - val_loss1: 1.5772 - val_loss2: 10.8642 - val_reconstruction_loss: -493.4877 - val_accuracy: 3.0518e-05\n",
      "Epoch 2/300\n",
      "59/59 [==============================] - 2s 37ms/step - mse_loss: 3035.0681 - total_loss: 13.3826 - loss1: 2.1837 - loss2: 11.1989 - reconstruction_loss: -592.8058 - accuracy: 1.6459e-04 - val_mse_loss: 2130.3618 - val_total_loss: 12.1239 - val_loss1: 0.3621 - val_loss2: 11.7618 - val_reconstruction_loss: -493.5084 - val_accuracy: 3.0518e-05\n",
      "Epoch 3/300\n",
      "59/59 [==============================] - 2s 38ms/step - mse_loss: 2689.5486 - total_loss: 13.2085 - loss1: 1.8251 - loss2: 11.3834 - reconstruction_loss: -572.9996 - accuracy: 1.6446e-04 - val_mse_loss: 2056.2976 - val_total_loss: 11.0744 - val_loss1: 2.4380 - val_loss2: 8.6364 - val_reconstruction_loss: -493.5084 - val_accuracy: 3.0518e-05\n",
      "Epoch 4/300\n",
      "59/59 [==============================] - 2s 38ms/step - mse_loss: 2463.9612 - total_loss: 11.1087 - loss1: 1.4944 - loss2: 9.6143 - reconstruction_loss: -582.8669 - accuracy: 1.6446e-04 - val_mse_loss: 1949.1053 - val_total_loss: 9.0430 - val_loss1: 1.4924 - val_loss2: 7.5506 - val_reconstruction_loss: -493.5084 - val_accuracy: 3.0518e-05\n",
      "Epoch 5/300\n",
      "59/59 [==============================] - 2s 38ms/step - mse_loss: 2281.1218 - total_loss: 9.5435 - loss1: 1.1670 - loss2: 8.3764 - reconstruction_loss: -570.7626 - accuracy: 1.6446e-04 - val_mse_loss: 1868.3572 - val_total_loss: 8.7038 - val_loss1: 0.8745 - val_loss2: 7.8293 - val_reconstruction_loss: -493.5084 - val_accuracy: 3.0518e-05\n",
      "Epoch 6/300\n",
      "59/59 [==============================] - 2s 36ms/step - mse_loss: 2177.4604 - total_loss: 9.1061 - loss1: 1.1019 - loss2: 8.0042 - reconstruction_loss: -582.3629 - accuracy: 1.6446e-04 - val_mse_loss: 1799.5085 - val_total_loss: 8.6139 - val_loss1: 1.3243 - val_loss2: 7.2896 - val_reconstruction_loss: -493.5084 - val_accuracy: 3.0518e-05\n",
      "Epoch 7/300\n",
      "59/59 [==============================] - 2s 37ms/step - mse_loss: 2092.1038 - total_loss: 9.0290 - loss1: 1.0983 - loss2: 7.9307 - reconstruction_loss: -573.1414 - accuracy: 1.6446e-04 - val_mse_loss: 1698.6709 - val_total_loss: 8.5406 - val_loss1: 0.8358 - val_loss2: 7.7047 - val_reconstruction_loss: -493.5084 - val_accuracy: 3.0518e-05\n",
      "Epoch 8/300\n",
      "59/59 [==============================] - 2s 36ms/step - mse_loss: 1910.1141 - total_loss: 8.8620 - loss1: 1.0681 - loss2: 7.7939 - reconstruction_loss: -585.6313 - accuracy: 1.6446e-04 - val_mse_loss: 1420.4441 - val_total_loss: 8.3364 - val_loss1: 0.8389 - val_loss2: 7.4975 - val_reconstruction_loss: -493.5084 - val_accuracy: 3.0518e-05\n",
      "Epoch 9/300\n",
      "59/59 [==============================] - 2s 37ms/step - mse_loss: 1777.4449 - total_loss: 8.7572 - loss1: 1.0733 - loss2: 7.6839 - reconstruction_loss: -571.8880 - accuracy: 1.6446e-04 - val_mse_loss: 1272.9829 - val_total_loss: 8.2416 - val_loss1: 1.2800 - val_loss2: 6.9615 - val_reconstruction_loss: -493.5084 - val_accuracy: 3.0518e-05\n",
      "Epoch 10/300\n",
      "59/59 [==============================] - 2s 36ms/step - mse_loss: 1753.5885 - total_loss: 8.7496 - loss1: 1.0788 - loss2: 7.6707 - reconstruction_loss: -588.2990 - accuracy: 1.6446e-04 - val_mse_loss: 1250.8486 - val_total_loss: 8.3618 - val_loss1: 0.6229 - val_loss2: 7.7389 - val_reconstruction_loss: -493.5084 - val_accuracy: 3.0518e-05\n",
      "Epoch 11/300\n",
      "59/59 [==============================] - 2s 36ms/step - mse_loss: 1746.7002 - total_loss: 8.7283 - loss1: 1.0717 - loss2: 7.6566 - reconstruction_loss: -590.3218 - accuracy: 1.6446e-04 - val_mse_loss: 1269.2008 - val_total_loss: 8.3969 - val_loss1: 0.4954 - val_loss2: 7.9015 - val_reconstruction_loss: -493.5084 - val_accuracy: 3.0518e-05\n",
      "Epoch 12/300\n",
      "59/59 [==============================] - 2s 36ms/step - mse_loss: 1684.1636 - total_loss: 8.6991 - loss1: 1.0387 - loss2: 7.6604 - reconstruction_loss: -583.6605 - accuracy: 1.6446e-04 - val_mse_loss: 1185.0234 - val_total_loss: 8.1347 - val_loss1: 0.9842 - val_loss2: 7.1505 - val_reconstruction_loss: -493.5084 - val_accuracy: 3.0518e-05\n",
      "Epoch 13/300\n",
      "59/59 [==============================] - 2s 37ms/step - mse_loss: 1528.2345 - total_loss: 8.5150 - loss1: 1.0621 - loss2: 7.4529 - reconstruction_loss: -583.7127 - accuracy: 1.6446e-04 - val_mse_loss: 984.9590 - val_total_loss: 8.1951 - val_loss1: 0.4714 - val_loss2: 7.7237 - val_reconstruction_loss: -493.5084 - val_accuracy: 3.0518e-05\n",
      "Epoch 14/300\n",
      "59/59 [==============================] - 2s 36ms/step - mse_loss: 1318.3756 - total_loss: 8.3262 - loss1: 1.0283 - loss2: 7.2979 - reconstruction_loss: -586.7233 - accuracy: 1.6446e-04 - val_mse_loss: 884.6500 - val_total_loss: 7.8559 - val_loss1: 1.2602 - val_loss2: 6.5957 - val_reconstruction_loss: -493.5084 - val_accuracy: 3.0518e-05\n",
      "Epoch 15/300\n",
      "59/59 [==============================] - 2s 37ms/step - mse_loss: 1151.5529 - total_loss: 8.2134 - loss1: 1.0474 - loss2: 7.1660 - reconstruction_loss: -576.9953 - accuracy: 1.6446e-04 - val_mse_loss: 776.8175 - val_total_loss: 7.7707 - val_loss1: 1.4011 - val_loss2: 6.3696 - val_reconstruction_loss: -493.5084 - val_accuracy: 3.0518e-05\n",
      "Epoch 16/300\n",
      "59/59 [==============================] - 2s 38ms/step - mse_loss: 1051.4054 - total_loss: 8.1876 - loss1: 1.0588 - loss2: 7.1288 - reconstruction_loss: -570.4375 - accuracy: 1.6446e-04 - val_mse_loss: 706.1490 - val_total_loss: 7.6046 - val_loss1: 1.0180 - val_loss2: 6.5866 - val_reconstruction_loss: -493.5084 - val_accuracy: 3.0518e-05\n",
      "Epoch 17/300\n",
      "59/59 [==============================] - 2s 39ms/step - mse_loss: 926.5699 - total_loss: 7.9810 - loss1: 1.0477 - loss2: 6.9333 - reconstruction_loss: -580.2596 - accuracy: 1.6446e-04 - val_mse_loss: 779.8378 - val_total_loss: 7.8282 - val_loss1: 0.6210 - val_loss2: 7.2072 - val_reconstruction_loss: -493.5084 - val_accuracy: 3.0518e-05\n",
      "Epoch 18/300\n",
      "59/59 [==============================] - 2s 37ms/step - mse_loss: 802.8335 - total_loss: 7.8557 - loss1: 1.0472 - loss2: 6.8085 - reconstruction_loss: -582.2313 - accuracy: 1.7048e-04 - val_mse_loss: 570.0285 - val_total_loss: 7.4780 - val_loss1: 0.7241 - val_loss2: 6.7539 - val_reconstruction_loss: -493.5268 - val_accuracy: 1.8311e-04\n",
      "Epoch 19/300\n",
      "59/59 [==============================] - 2s 36ms/step - mse_loss: 689.9680 - total_loss: 7.6633 - loss1: 1.0300 - loss2: 6.6334 - reconstruction_loss: -579.5240 - accuracy: 7.1947e-04 - val_mse_loss: 500.9326 - val_total_loss: 7.2935 - val_loss1: 0.8422 - val_loss2: 6.4513 - val_reconstruction_loss: -493.5641 - val_accuracy: 0.0025\n",
      "Epoch 20/300\n",
      "59/59 [==============================] - 3s 43ms/step - mse_loss: 639.2000 - total_loss: 7.5749 - loss1: 1.0336 - loss2: 6.5413 - reconstruction_loss: -585.3947 - accuracy: 0.0024 - val_mse_loss: 460.8046 - val_total_loss: 7.2465 - val_loss1: 0.7006 - val_loss2: 6.5459 - val_reconstruction_loss: -493.6623 - val_accuracy: 0.0041\n",
      "Epoch 21/300\n",
      "59/59 [==============================] - 2s 38ms/step - mse_loss: 606.4352 - total_loss: 7.5096 - loss1: 1.0305 - loss2: 6.4791 - reconstruction_loss: -579.0708 - accuracy: 0.0133 - val_mse_loss: 555.0709 - val_total_loss: 7.4084 - val_loss1: 0.9174 - val_loss2: 6.4910 - val_reconstruction_loss: -494.1274 - val_accuracy: 0.0215\n",
      "Epoch 22/300\n",
      "59/59 [==============================] - 2s 36ms/step - mse_loss: 581.5150 - total_loss: 7.4288 - loss1: 1.0113 - loss2: 6.4174 - reconstruction_loss: -583.2496 - accuracy: 0.0418 - val_mse_loss: 446.1061 - val_total_loss: 7.1464 - val_loss1: 0.8703 - val_loss2: 6.2761 - val_reconstruction_loss: -495.1241 - val_accuracy: 0.0760\n",
      "Epoch 23/300\n",
      "59/59 [==============================] - 2s 36ms/step - mse_loss: 560.5302 - total_loss: 7.4033 - loss1: 1.0184 - loss2: 6.3849 - reconstruction_loss: -583.1869 - accuracy: 0.0879 - val_mse_loss: 444.2401 - val_total_loss: 7.2066 - val_loss1: 0.7006 - val_loss2: 6.5060 - val_reconstruction_loss: -495.9106 - val_accuracy: 0.1176\n",
      "Epoch 24/300\n",
      "59/59 [==============================] - 2s 35ms/step - mse_loss: 560.0623 - total_loss: 7.4516 - loss1: 1.0374 - loss2: 6.4142 - reconstruction_loss: -593.0927 - accuracy: 0.1223 - val_mse_loss: 409.8773 - val_total_loss: 7.0990 - val_loss1: 1.1900 - val_loss2: 5.9089 - val_reconstruction_loss: -496.5924 - val_accuracy: 0.1501\n",
      "Epoch 25/300\n",
      "59/59 [==============================] - 2s 35ms/step - mse_loss: 534.0743 - total_loss: 7.3687 - loss1: 1.0194 - loss2: 6.3493 - reconstruction_loss: -571.4861 - accuracy: 0.1448 - val_mse_loss: 433.9791 - val_total_loss: 7.1213 - val_loss1: 0.9990 - val_loss2: 6.1224 - val_reconstruction_loss: -497.1223 - val_accuracy: 0.2043\n",
      "Epoch 26/300\n",
      "59/59 [==============================] - 2s 35ms/step - mse_loss: 492.0795 - total_loss: 7.2571 - loss1: 1.0172 - loss2: 6.2398 - reconstruction_loss: -571.6344 - accuracy: 0.1937 - val_mse_loss: 378.6482 - val_total_loss: 6.9713 - val_loss1: 0.8325 - val_loss2: 6.1388 - val_reconstruction_loss: -497.9256 - val_accuracy: 0.2523\n",
      "Epoch 27/300\n",
      "59/59 [==============================] - 2s 35ms/step - mse_loss: 469.9424 - total_loss: 7.2235 - loss1: 1.0258 - loss2: 6.1978 - reconstruction_loss: -586.6399 - accuracy: 0.2290 - val_mse_loss: 358.0148 - val_total_loss: 7.0556 - val_loss1: 0.5967 - val_loss2: 6.4589 - val_reconstruction_loss: -498.0197 - val_accuracy: 0.2555\n",
      "Epoch 28/300\n",
      "59/59 [==============================] - 2s 35ms/step - mse_loss: 448.2476 - total_loss: 7.1709 - loss1: 1.0087 - loss2: 6.1622 - reconstruction_loss: -593.7877 - accuracy: 0.2489 - val_mse_loss: 360.2489 - val_total_loss: 6.9436 - val_loss1: 0.9055 - val_loss2: 6.0380 - val_reconstruction_loss: -498.1325 - val_accuracy: 0.2642\n",
      "Epoch 29/300\n",
      "59/59 [==============================] - 2s 35ms/step - mse_loss: 422.6891 - total_loss: 7.0969 - loss1: 1.0122 - loss2: 6.0847 - reconstruction_loss: -587.1578 - accuracy: 0.2677 - val_mse_loss: 322.8540 - val_total_loss: 6.8049 - val_loss1: 0.9941 - val_loss2: 5.8109 - val_reconstruction_loss: -498.6554 - val_accuracy: 0.3011\n",
      "Epoch 30/300\n",
      "59/59 [==============================] - 2s 36ms/step - mse_loss: 415.0815 - total_loss: 7.1116 - loss1: 1.0228 - loss2: 6.0888 - reconstruction_loss: -593.0345 - accuracy: 0.2717 - val_mse_loss: 356.2716 - val_total_loss: 6.9209 - val_loss1: 0.8494 - val_loss2: 6.0715 - val_reconstruction_loss: -498.0906 - val_accuracy: 0.3061\n",
      "Epoch 31/300\n",
      "59/59 [==============================] - 2s 37ms/step - mse_loss: 394.7169 - total_loss: 7.0487 - loss1: 1.0150 - loss2: 6.0336 - reconstruction_loss: -581.6702 - accuracy: 0.2827 - val_mse_loss: 311.5383 - val_total_loss: 6.8242 - val_loss1: 0.7870 - val_loss2: 6.0372 - val_reconstruction_loss: -498.4083 - val_accuracy: 0.3145\n",
      "Epoch 32/300\n",
      "59/59 [==============================] - 2s 38ms/step - mse_loss: 379.2400 - total_loss: 7.0040 - loss1: 1.0203 - loss2: 5.9838 - reconstruction_loss: -589.9620 - accuracy: 0.2869 - val_mse_loss: 321.5913 - val_total_loss: 6.7990 - val_loss1: 0.9646 - val_loss2: 5.8345 - val_reconstruction_loss: -498.9138 - val_accuracy: 0.3236\n",
      "Epoch 33/300\n",
      "59/59 [==============================] - 2s 40ms/step - mse_loss: 362.4208 - total_loss: 6.9451 - loss1: 1.0119 - loss2: 5.9332 - reconstruction_loss: -600.5168 - accuracy: 0.2965 - val_mse_loss: 309.8400 - val_total_loss: 6.8181 - val_loss1: 1.3456 - val_loss2: 5.4725 - val_reconstruction_loss: -499.0493 - val_accuracy: 0.3341\n",
      "Epoch 34/300\n",
      "59/59 [==============================] - 2s 35ms/step - mse_loss: 371.5467 - total_loss: 6.9948 - loss1: 1.0240 - loss2: 5.9708 - reconstruction_loss: -583.5338 - accuracy: 0.2919 - val_mse_loss: 300.6280 - val_total_loss: 6.7685 - val_loss1: 0.7771 - val_loss2: 5.9914 - val_reconstruction_loss: -498.6923 - val_accuracy: 0.2993\n",
      "Epoch 35/300\n",
      "59/59 [==============================] - 2s 38ms/step - mse_loss: 334.2902 - total_loss: 6.8605 - loss1: 1.0085 - loss2: 5.8520 - reconstruction_loss: -591.4947 - accuracy: 0.3028 - val_mse_loss: 265.0501 - val_total_loss: 6.6148 - val_loss1: 1.0721 - val_loss2: 5.5427 - val_reconstruction_loss: -498.9230 - val_accuracy: 0.3167\n",
      "Epoch 36/300\n",
      "59/59 [==============================] - 2s 36ms/step - mse_loss: 326.5938 - total_loss: 6.8378 - loss1: 1.0159 - loss2: 5.8219 - reconstruction_loss: -581.4104 - accuracy: 0.3053 - val_mse_loss: 273.7466 - val_total_loss: 6.6594 - val_loss1: 0.8203 - val_loss2: 5.8391 - val_reconstruction_loss: -499.1378 - val_accuracy: 0.3259\n",
      "Epoch 37/300\n",
      "59/59 [==============================] - 2s 35ms/step - mse_loss: 313.9428 - total_loss: 6.8186 - loss1: 1.0124 - loss2: 5.8062 - reconstruction_loss: -580.2415 - accuracy: 0.3127 - val_mse_loss: 289.7697 - val_total_loss: 6.7215 - val_loss1: 0.8265 - val_loss2: 5.8950 - val_reconstruction_loss: -499.0973 - val_accuracy: 0.3239\n",
      "Epoch 38/300\n",
      "59/59 [==============================] - 2s 34ms/step - mse_loss: 325.3238 - total_loss: 6.8578 - loss1: 1.0271 - loss2: 5.8307 - reconstruction_loss: -582.1905 - accuracy: 0.3097 - val_mse_loss: 277.8255 - val_total_loss: 6.6590 - val_loss1: 1.0183 - val_loss2: 5.6408 - val_reconstruction_loss: -499.2015 - val_accuracy: 0.3553\n",
      "Epoch 39/300\n",
      "59/59 [==============================] - 2s 36ms/step - mse_loss: 309.2499 - total_loss: 6.7855 - loss1: 1.0183 - loss2: 5.7672 - reconstruction_loss: -586.6543 - accuracy: 0.3172 - val_mse_loss: 315.8282 - val_total_loss: 6.8470 - val_loss1: 0.7047 - val_loss2: 6.1423 - val_reconstruction_loss: -498.8935 - val_accuracy: 0.3338\n",
      "Epoch 40/300\n",
      "59/59 [==============================] - 2s 34ms/step - mse_loss: 311.0653 - total_loss: 6.7966 - loss1: 1.0153 - loss2: 5.7813 - reconstruction_loss: -593.3825 - accuracy: 0.3216 - val_mse_loss: 342.6606 - val_total_loss: 7.0268 - val_loss1: 0.5610 - val_loss2: 6.4659 - val_reconstruction_loss: -499.2208 - val_accuracy: 0.3300\n",
      "Epoch 41/300\n",
      "59/59 [==============================] - 2s 34ms/step - mse_loss: 325.7156 - total_loss: 6.8663 - loss1: 1.0167 - loss2: 5.8496 - reconstruction_loss: -586.6938 - accuracy: 0.3243 - val_mse_loss: 254.4911 - val_total_loss: 6.5911 - val_loss1: 0.8934 - val_loss2: 5.6977 - val_reconstruction_loss: -499.6413 - val_accuracy: 0.3621\n",
      "Epoch 42/300\n",
      "59/59 [==============================] - 2s 35ms/step - mse_loss: 282.4320 - total_loss: 6.6952 - loss1: 1.0119 - loss2: 5.6833 - reconstruction_loss: -581.6946 - accuracy: 0.3336 - val_mse_loss: 253.9938 - val_total_loss: 6.5641 - val_loss1: 0.9652 - val_loss2: 5.5990 - val_reconstruction_loss: -499.5414 - val_accuracy: 0.3629\n",
      "Epoch 43/300\n",
      "59/59 [==============================] - 2s 35ms/step - mse_loss: 281.4019 - total_loss: 6.7055 - loss1: 1.0314 - loss2: 5.6741 - reconstruction_loss: -583.7424 - accuracy: 0.3396 - val_mse_loss: 241.6346 - val_total_loss: 6.6701 - val_loss1: 0.5717 - val_loss2: 6.0984 - val_reconstruction_loss: -499.3530 - val_accuracy: 0.3462\n",
      "Epoch 44/300\n",
      "59/59 [==============================] - 2s 34ms/step - mse_loss: 287.0358 - total_loss: 6.7448 - loss1: 1.0201 - loss2: 5.7247 - reconstruction_loss: -587.6721 - accuracy: 0.3392 - val_mse_loss: 270.6513 - val_total_loss: 6.6477 - val_loss1: 0.9299 - val_loss2: 5.7179 - val_reconstruction_loss: -500.0385 - val_accuracy: 0.3931\n",
      "Epoch 45/300\n",
      "59/59 [==============================] - 2s 34ms/step - mse_loss: 290.2773 - total_loss: 6.7343 - loss1: 1.0148 - loss2: 5.7196 - reconstruction_loss: -571.8613 - accuracy: 0.3389 - val_mse_loss: 233.4025 - val_total_loss: 6.5077 - val_loss1: 0.7814 - val_loss2: 5.7262 - val_reconstruction_loss: -499.8651 - val_accuracy: 0.3880\n",
      "Epoch 46/300\n",
      "59/59 [==============================] - 2s 36ms/step - mse_loss: 259.8531 - total_loss: 6.6333 - loss1: 1.0186 - loss2: 5.6147 - reconstruction_loss: -583.5442 - accuracy: 0.3523 - val_mse_loss: 264.7778 - val_total_loss: 6.9802 - val_loss1: 0.4041 - val_loss2: 6.5761 - val_reconstruction_loss: -499.9658 - val_accuracy: 0.4219\n",
      "Epoch 47/300\n",
      "59/59 [==============================] - 2s 34ms/step - mse_loss: 300.7737 - total_loss: 6.7990 - loss1: 1.0253 - loss2: 5.7737 - reconstruction_loss: -588.7077 - accuracy: 0.3409 - val_mse_loss: 247.3298 - val_total_loss: 6.5555 - val_loss1: 0.9902 - val_loss2: 5.5653 - val_reconstruction_loss: -499.8934 - val_accuracy: 0.4042\n",
      "Epoch 48/300\n",
      "59/59 [==============================] - 2s 34ms/step - mse_loss: 292.9359 - total_loss: 6.7881 - loss1: 1.0396 - loss2: 5.7485 - reconstruction_loss: -590.6762 - accuracy: 0.3485 - val_mse_loss: 280.2195 - val_total_loss: 6.6754 - val_loss1: 0.8925 - val_loss2: 5.7829 - val_reconstruction_loss: -499.7188 - val_accuracy: 0.3550\n",
      "Epoch 49/300\n",
      "59/59 [==============================] - 2s 35ms/step - mse_loss: 257.5809 - total_loss: 6.6079 - loss1: 1.0062 - loss2: 5.6017 - reconstruction_loss: -589.9700 - accuracy: 0.3528 - val_mse_loss: 211.9549 - val_total_loss: 6.4139 - val_loss1: 1.2225 - val_loss2: 5.1913 - val_reconstruction_loss: -500.1335 - val_accuracy: 0.3956\n",
      "Epoch 50/300\n",
      "59/59 [==============================] - 2s 35ms/step - mse_loss: 245.8561 - total_loss: 6.5571 - loss1: 1.0166 - loss2: 5.5404 - reconstruction_loss: -578.6327 - accuracy: 0.3636 - val_mse_loss: 202.3573 - val_total_loss: 6.4113 - val_loss1: 0.6877 - val_loss2: 5.7236 - val_reconstruction_loss: -499.9661 - val_accuracy: 0.3934\n",
      "Epoch 51/300\n",
      "59/59 [==============================] - 2s 35ms/step - mse_loss: 239.5280 - total_loss: 6.5400 - loss1: 1.0089 - loss2: 5.5311 - reconstruction_loss: -583.8731 - accuracy: 0.3681 - val_mse_loss: 211.5014 - val_total_loss: 6.3985 - val_loss1: 1.0409 - val_loss2: 5.3575 - val_reconstruction_loss: -499.9285 - val_accuracy: 0.3929\n",
      "Epoch 52/300\n",
      "59/59 [==============================] - 2s 35ms/step - mse_loss: 275.0347 - total_loss: 6.7311 - loss1: 1.0414 - loss2: 5.6897 - reconstruction_loss: -590.0708 - accuracy: 0.3630 - val_mse_loss: 215.0786 - val_total_loss: 6.5721 - val_loss1: 0.5328 - val_loss2: 6.0393 - val_reconstruction_loss: -500.1210 - val_accuracy: 0.4041\n",
      "Epoch 53/300\n",
      "59/59 [==============================] - 2s 34ms/step - mse_loss: 322.7569 - total_loss: 6.9463 - loss1: 1.0518 - loss2: 5.8945 - reconstruction_loss: -587.9358 - accuracy: 0.3470 - val_mse_loss: 217.6624 - val_total_loss: 6.4302 - val_loss1: 1.0854 - val_loss2: 5.3447 - val_reconstruction_loss: -499.9843 - val_accuracy: 0.3813\n",
      "Epoch 54/300\n",
      "59/59 [==============================] - 2s 35ms/step - mse_loss: 251.1010 - total_loss: 6.5988 - loss1: 1.0248 - loss2: 5.5739 - reconstruction_loss: -583.7219 - accuracy: 0.3646 - val_mse_loss: 199.0681 - val_total_loss: 6.3455 - val_loss1: 0.8824 - val_loss2: 5.4631 - val_reconstruction_loss: -500.1385 - val_accuracy: 0.4098\n",
      "Epoch 55/300\n",
      "59/59 [==============================] - 2s 35ms/step - mse_loss: 225.7586 - total_loss: 6.4621 - loss1: 1.0053 - loss2: 5.4568 - reconstruction_loss: -589.5808 - accuracy: 0.3797 - val_mse_loss: 185.3650 - val_total_loss: 6.2526 - val_loss1: 0.8874 - val_loss2: 5.3651 - val_reconstruction_loss: -500.3211 - val_accuracy: 0.4278\n",
      "Epoch 56/300\n",
      "59/59 [==============================] - 2s 34ms/step - mse_loss: 228.2962 - total_loss: 6.4916 - loss1: 1.0123 - loss2: 5.4793 - reconstruction_loss: -588.4717 - accuracy: 0.3857 - val_mse_loss: 208.3641 - val_total_loss: 6.4877 - val_loss1: 1.5124 - val_loss2: 4.9753 - val_reconstruction_loss: -500.0352 - val_accuracy: 0.3666\n",
      "Epoch 57/300\n",
      "59/59 [==============================] - 2s 34ms/step - mse_loss: 243.8250 - total_loss: 6.5716 - loss1: 1.0234 - loss2: 5.5482 - reconstruction_loss: -586.3322 - accuracy: 0.3813 - val_mse_loss: 224.4992 - val_total_loss: 6.4719 - val_loss1: 1.2930 - val_loss2: 5.1789 - val_reconstruction_loss: -500.1536 - val_accuracy: 0.4209\n",
      "Epoch 58/300\n",
      "59/59 [==============================] - 2s 34ms/step - mse_loss: 244.4297 - total_loss: 6.5751 - loss1: 1.0172 - loss2: 5.5580 - reconstruction_loss: -588.2718 - accuracy: 0.3841 - val_mse_loss: 216.1443 - val_total_loss: 6.4342 - val_loss1: 1.2828 - val_loss2: 5.1514 - val_reconstruction_loss: -500.2164 - val_accuracy: 0.3938\n",
      "Epoch 59/300\n",
      "59/59 [==============================] - 2s 35ms/step - mse_loss: 230.4028 - total_loss: 6.5114 - loss1: 1.0225 - loss2: 5.4889 - reconstruction_loss: -579.4657 - accuracy: 0.3843 - val_mse_loss: 222.8445 - val_total_loss: 6.5456 - val_loss1: 1.5378 - val_loss2: 5.0078 - val_reconstruction_loss: -500.4222 - val_accuracy: 0.4220\n",
      "Epoch 60/300\n",
      "59/59 [==============================] - 2s 35ms/step - mse_loss: 216.7220 - total_loss: 6.4325 - loss1: 1.0188 - loss2: 5.4137 - reconstruction_loss: -587.8747 - accuracy: 0.3890 - val_mse_loss: 217.5807 - val_total_loss: 6.4336 - val_loss1: 1.2682 - val_loss2: 5.1655 - val_reconstruction_loss: -500.1941 - val_accuracy: 0.4206\n",
      "Epoch 61/300\n",
      "59/59 [==============================] - 2s 35ms/step - mse_loss: 210.2330 - total_loss: 6.3902 - loss1: 1.0101 - loss2: 5.3800 - reconstruction_loss: -583.7513 - accuracy: 0.3942 - val_mse_loss: 173.4582 - val_total_loss: 6.1792 - val_loss1: 0.9768 - val_loss2: 5.2024 - val_reconstruction_loss: -500.0759 - val_accuracy: 0.4190\n",
      "Epoch 62/300\n",
      "59/59 [==============================] - 2s 36ms/step - mse_loss: 216.4576 - total_loss: 6.4308 - loss1: 1.0276 - loss2: 5.4032 - reconstruction_loss: -595.6839 - accuracy: 0.3944 - val_mse_loss: 192.2328 - val_total_loss: 6.3292 - val_loss1: 0.7646 - val_loss2: 5.5646 - val_reconstruction_loss: -500.4407 - val_accuracy: 0.4278\n",
      "Epoch 63/300\n",
      "59/59 [==============================] - 2s 35ms/step - mse_loss: 221.2938 - total_loss: 6.4802 - loss1: 1.0196 - loss2: 5.4605 - reconstruction_loss: -578.2786 - accuracy: 0.3922 - val_mse_loss: 188.0805 - val_total_loss: 6.4005 - val_loss1: 0.6048 - val_loss2: 5.7957 - val_reconstruction_loss: -499.1606 - val_accuracy: 0.4186\n",
      "Epoch 64/300\n",
      "59/59 [==============================] - 2s 36ms/step - mse_loss: 208.7132 - total_loss: 6.3985 - loss1: 1.0124 - loss2: 5.3861 - reconstruction_loss: -586.3532 - accuracy: 0.3961 - val_mse_loss: 196.4290 - val_total_loss: 6.4737 - val_loss1: 0.5448 - val_loss2: 5.9290 - val_reconstruction_loss: -498.1558 - val_accuracy: 0.4389\n",
      "Epoch 65/300\n",
      "59/59 [==============================] - 2s 34ms/step - mse_loss: 516.2877 - total_loss: 7.4458 - loss1: 1.1333 - loss2: 6.3126 - reconstruction_loss: -589.3195 - accuracy: 0.3660 - val_mse_loss: 694.4429 - val_total_loss: 7.9971 - val_loss1: 0.5556 - val_loss2: 7.4414 - val_reconstruction_loss: -485.3427 - val_accuracy: 0.1870\n",
      "Epoch 66/300\n",
      "59/59 [==============================] - 2s 34ms/step - mse_loss: 469.2217 - total_loss: 7.4111 - loss1: 1.0876 - loss2: 6.3235 - reconstruction_loss: -578.9281 - accuracy: 0.1887 - val_mse_loss: 260.5882 - val_total_loss: 6.7503 - val_loss1: 1.5170 - val_loss2: 5.2333 - val_reconstruction_loss: -499.1428 - val_accuracy: 0.3250\n",
      "Epoch 67/300\n",
      "59/59 [==============================] - 2s 34ms/step - mse_loss: 239.6661 - total_loss: 6.5503 - loss1: 1.0252 - loss2: 5.5251 - reconstruction_loss: -593.8804 - accuracy: 0.3630 - val_mse_loss: 252.8779 - val_total_loss: 6.6079 - val_loss1: 0.9177 - val_loss2: 5.6901 - val_reconstruction_loss: -500.1331 - val_accuracy: 0.3999\n",
      "Epoch 68/300\n",
      "59/59 [==============================] - 2s 35ms/step - mse_loss: 219.6213 - total_loss: 6.4552 - loss1: 1.0101 - loss2: 5.4450 - reconstruction_loss: -575.9104 - accuracy: 0.3972 - val_mse_loss: 223.1228 - val_total_loss: 6.5423 - val_loss1: 1.4448 - val_loss2: 5.0975 - val_reconstruction_loss: -499.0027 - val_accuracy: 0.4208\n",
      "Epoch 69/300\n",
      "59/59 [==============================] - 2s 39ms/step - mse_loss: 202.9622 - total_loss: 6.3725 - loss1: 1.0144 - loss2: 5.3581 - reconstruction_loss: -588.6768 - accuracy: 0.4049 - val_mse_loss: 167.0639 - val_total_loss: 6.1400 - val_loss1: 1.1221 - val_loss2: 5.0179 - val_reconstruction_loss: -500.3407 - val_accuracy: 0.4205\n",
      "Epoch 70/300\n",
      "59/59 [==============================] - 3s 59ms/step - mse_loss: 197.1166 - total_loss: 6.3238 - loss1: 1.0199 - loss2: 5.3039 - reconstruction_loss: -584.9256 - accuracy: 0.4049 - val_mse_loss: 168.1178 - val_total_loss: 6.2244 - val_loss1: 0.6844 - val_loss2: 5.5400 - val_reconstruction_loss: -499.7455 - val_accuracy: 0.4483\n",
      "Epoch 71/300\n",
      "59/59 [==============================] - 3s 49ms/step - mse_loss: 191.3154 - total_loss: 6.3138 - loss1: 1.0153 - loss2: 5.2985 - reconstruction_loss: -592.5604 - accuracy: 0.4078 - val_mse_loss: 165.6804 - val_total_loss: 6.2014 - val_loss1: 0.6958 - val_loss2: 5.5056 - val_reconstruction_loss: -500.2736 - val_accuracy: 0.4467\n",
      "Epoch 72/300\n",
      "59/59 [==============================] - 3s 42ms/step - mse_loss: 199.0635 - total_loss: 6.3762 - loss1: 1.0208 - loss2: 5.3554 - reconstruction_loss: -585.7849 - accuracy: 0.4044 - val_mse_loss: 196.4962 - val_total_loss: 6.3123 - val_loss1: 1.0518 - val_loss2: 5.2605 - val_reconstruction_loss: -499.7957 - val_accuracy: 0.4013\n",
      "Epoch 73/300\n",
      "59/59 [==============================] - 3s 58ms/step - mse_loss: 194.3824 - total_loss: 6.3071 - loss1: 1.0166 - loss2: 5.2905 - reconstruction_loss: -577.3919 - accuracy: 0.4010 - val_mse_loss: 193.6482 - val_total_loss: 6.3974 - val_loss1: 0.6413 - val_loss2: 5.7562 - val_reconstruction_loss: -500.4053 - val_accuracy: 0.4435\n",
      "Epoch 74/300\n",
      "59/59 [==============================] - 3s 50ms/step - mse_loss: 195.5396 - total_loss: 6.3346 - loss1: 1.0087 - loss2: 5.3259 - reconstruction_loss: -593.5262 - accuracy: 0.4017 - val_mse_loss: 193.8486 - val_total_loss: 6.5310 - val_loss1: 1.8325 - val_loss2: 4.6985 - val_reconstruction_loss: -499.8739 - val_accuracy: 0.4399\n",
      "Epoch 75/300\n",
      "59/59 [==============================] - 3s 42ms/step - mse_loss: 194.4542 - total_loss: 6.3330 - loss1: 1.0179 - loss2: 5.3151 - reconstruction_loss: -579.3521 - accuracy: 0.4045 - val_mse_loss: 173.0167 - val_total_loss: 6.1974 - val_loss1: 0.9221 - val_loss2: 5.2753 - val_reconstruction_loss: -499.9638 - val_accuracy: 0.4190\n",
      "Epoch 76/300\n",
      "59/59 [==============================] - 3s 49ms/step - mse_loss: 192.1872 - total_loss: 6.3080 - loss1: 1.0128 - loss2: 5.2951 - reconstruction_loss: -573.2636 - accuracy: 0.4039 - val_mse_loss: 185.5762 - val_total_loss: 6.2606 - val_loss1: 1.0504 - val_loss2: 5.2102 - val_reconstruction_loss: -498.9542 - val_accuracy: 0.4073\n",
      "Epoch 77/300\n",
      "59/59 [==============================] - 3s 54ms/step - mse_loss: 185.4806 - total_loss: 6.2768 - loss1: 1.0222 - loss2: 5.2545 - reconstruction_loss: -581.1871 - accuracy: 0.4022 - val_mse_loss: 174.6913 - val_total_loss: 6.2242 - val_loss1: 0.7409 - val_loss2: 5.4833 - val_reconstruction_loss: -499.6202 - val_accuracy: 0.4573\n",
      "Epoch 78/300\n",
      "59/59 [==============================] - 3s 50ms/step - mse_loss: 218.6584 - total_loss: 6.4759 - loss1: 1.0298 - loss2: 5.4461 - reconstruction_loss: -584.2388 - accuracy: 0.4032 - val_mse_loss: 586.4905 - val_total_loss: 7.8805 - val_loss1: 0.3555 - val_loss2: 7.5250 - val_reconstruction_loss: -499.9932 - val_accuracy: 0.4155\n",
      "Epoch 79/300\n",
      "59/59 [==============================] - 2s 39ms/step - mse_loss: 246.6183 - total_loss: 6.6669 - loss1: 1.0619 - loss2: 5.6051 - reconstruction_loss: -579.6681 - accuracy: 0.3717 - val_mse_loss: 206.9295 - val_total_loss: 6.3741 - val_loss1: 1.0069 - val_loss2: 5.3672 - val_reconstruction_loss: -499.0381 - val_accuracy: 0.4034\n",
      "Epoch 80/300\n",
      "59/59 [==============================] - 2s 39ms/step - mse_loss: 197.9821 - total_loss: 6.3473 - loss1: 1.0181 - loss2: 5.3292 - reconstruction_loss: -578.3159 - accuracy: 0.3993 - val_mse_loss: 179.5774 - val_total_loss: 6.2414 - val_loss1: 0.7803 - val_loss2: 5.4611 - val_reconstruction_loss: -499.3282 - val_accuracy: 0.4601\n",
      "Epoch 81/300\n",
      "59/59 [==============================] - 2s 39ms/step - mse_loss: 196.7194 - total_loss: 6.3470 - loss1: 1.0186 - loss2: 5.3284 - reconstruction_loss: -603.4394 - accuracy: 0.4000 - val_mse_loss: 195.9692 - val_total_loss: 6.3024 - val_loss1: 0.9384 - val_loss2: 5.3640 - val_reconstruction_loss: -500.1966 - val_accuracy: 0.4546\n",
      "Epoch 82/300\n",
      "59/59 [==============================] - 3s 45ms/step - mse_loss: 194.0369 - total_loss: 6.3586 - loss1: 1.0204 - loss2: 5.3381 - reconstruction_loss: -584.9252 - accuracy: 0.4022 - val_mse_loss: 213.9219 - val_total_loss: 6.3863 - val_loss1: 1.0247 - val_loss2: 5.3616 - val_reconstruction_loss: -499.8316 - val_accuracy: 0.4062\n",
      "Epoch 83/300\n",
      "59/59 [==============================] - 3s 43ms/step - mse_loss: 202.9928 - total_loss: 6.3851 - loss1: 1.0314 - loss2: 5.3537 - reconstruction_loss: -583.5585 - accuracy: 0.3989 - val_mse_loss: 164.1937 - val_total_loss: 6.1446 - val_loss1: 1.0058 - val_loss2: 5.1388 - val_reconstruction_loss: -499.3837 - val_accuracy: 0.4181\n",
      "Epoch 84/300\n",
      "59/59 [==============================] - 2s 41ms/step - mse_loss: 186.5010 - total_loss: 6.2970 - loss1: 1.0173 - loss2: 5.2797 - reconstruction_loss: -578.6615 - accuracy: 0.4044 - val_mse_loss: 171.4258 - val_total_loss: 6.2648 - val_loss1: 0.6806 - val_loss2: 5.5841 - val_reconstruction_loss: -499.8925 - val_accuracy: 0.4773\n",
      "Epoch 85/300\n",
      "59/59 [==============================] - 2s 42ms/step - mse_loss: 196.8154 - total_loss: 6.3661 - loss1: 1.0304 - loss2: 5.3357 - reconstruction_loss: -582.9629 - accuracy: 0.4001 - val_mse_loss: 193.4157 - val_total_loss: 6.4275 - val_loss1: 0.5710 - val_loss2: 5.8565 - val_reconstruction_loss: -500.2226 - val_accuracy: 0.4457\n",
      "Epoch 86/300\n",
      "59/59 [==============================] - 3s 43ms/step - mse_loss: 183.3269 - total_loss: 6.2771 - loss1: 1.0094 - loss2: 5.2677 - reconstruction_loss: -589.6199 - accuracy: 0.4041 - val_mse_loss: 168.7402 - val_total_loss: 6.1546 - val_loss1: 1.1265 - val_loss2: 5.0281 - val_reconstruction_loss: -500.0249 - val_accuracy: 0.4409\n",
      "Epoch 87/300\n",
      "59/59 [==============================] - 2s 42ms/step - mse_loss: 173.3388 - total_loss: 6.1954 - loss1: 1.0164 - loss2: 5.1791 - reconstruction_loss: -583.5325 - accuracy: 0.4079 - val_mse_loss: 178.4810 - val_total_loss: 6.2265 - val_loss1: 0.9138 - val_loss2: 5.3127 - val_reconstruction_loss: -497.4851 - val_accuracy: 0.4655\n",
      "Epoch 88/300\n",
      "59/59 [==============================] - 2s 39ms/step - mse_loss: 184.9724 - total_loss: 6.2789 - loss1: 1.0064 - loss2: 5.2725 - reconstruction_loss: -580.4698 - accuracy: 0.4034 - val_mse_loss: 197.0160 - val_total_loss: 6.4248 - val_loss1: 1.5726 - val_loss2: 4.8522 - val_reconstruction_loss: -499.7781 - val_accuracy: 0.3848\n",
      "Epoch 89/300\n",
      "59/59 [==============================] - 2s 38ms/step - mse_loss: 179.7496 - total_loss: 6.2508 - loss1: 1.0245 - loss2: 5.2262 - reconstruction_loss: -580.7368 - accuracy: 0.4062 - val_mse_loss: 165.2015 - val_total_loss: 6.1383 - val_loss1: 1.0580 - val_loss2: 5.0802 - val_reconstruction_loss: -499.7138 - val_accuracy: 0.4613\n",
      "Epoch 90/300\n",
      "59/59 [==============================] - 2s 41ms/step - mse_loss: 170.4708 - total_loss: 6.1882 - loss1: 1.0151 - loss2: 5.1731 - reconstruction_loss: -590.8219 - accuracy: 0.4106 - val_mse_loss: 178.7945 - val_total_loss: 6.3351 - val_loss1: 1.5911 - val_loss2: 4.7440 - val_reconstruction_loss: -498.9478 - val_accuracy: 0.4367\n",
      "Epoch 91/300\n",
      "59/59 [==============================] - 2s 42ms/step - mse_loss: 178.2323 - total_loss: 6.2567 - loss1: 1.0167 - loss2: 5.2399 - reconstruction_loss: -584.7133 - accuracy: 0.4083 - val_mse_loss: 188.4776 - val_total_loss: 6.2885 - val_loss1: 1.1244 - val_loss2: 5.1641 - val_reconstruction_loss: -499.7286 - val_accuracy: 0.4443\n",
      "Epoch 92/300\n",
      "59/59 [==============================] - 2s 40ms/step - mse_loss: 189.5139 - total_loss: 6.3391 - loss1: 1.0436 - loss2: 5.2956 - reconstruction_loss: -592.2470 - accuracy: 0.3973 - val_mse_loss: 167.5668 - val_total_loss: 6.1690 - val_loss1: 0.7977 - val_loss2: 5.3713 - val_reconstruction_loss: -499.9609 - val_accuracy: 0.4669\n",
      "Epoch 93/300\n",
      "59/59 [==============================] - 3s 46ms/step - mse_loss: 205.5473 - total_loss: 6.4210 - loss1: 1.0180 - loss2: 5.4030 - reconstruction_loss: -582.5997 - accuracy: 0.4005 - val_mse_loss: 186.4952 - val_total_loss: 6.7489 - val_loss1: 2.3057 - val_loss2: 4.4432 - val_reconstruction_loss: -499.1731 - val_accuracy: 0.3540\n",
      "Epoch 94/300\n",
      "59/59 [==============================] - 3s 47ms/step - mse_loss: 177.2702 - total_loss: 6.2421 - loss1: 1.0280 - loss2: 5.2141 - reconstruction_loss: -595.5099 - accuracy: 0.4074 - val_mse_loss: 172.1155 - val_total_loss: 6.2013 - val_loss1: 1.0732 - val_loss2: 5.1281 - val_reconstruction_loss: -499.8556 - val_accuracy: 0.4431\n",
      "Epoch 95/300\n",
      "59/59 [==============================] - 3s 44ms/step - mse_loss: 157.9266 - total_loss: 6.1169 - loss1: 1.0171 - loss2: 5.0998 - reconstruction_loss: -587.9897 - accuracy: 0.4168 - val_mse_loss: 175.0408 - val_total_loss: 6.1940 - val_loss1: 1.0496 - val_loss2: 5.1445 - val_reconstruction_loss: -498.9699 - val_accuracy: 0.4758\n",
      "Epoch 96/300\n",
      "59/59 [==============================] - 3s 50ms/step - mse_loss: 157.3895 - total_loss: 6.1044 - loss1: 1.0110 - loss2: 5.0933 - reconstruction_loss: -597.6711 - accuracy: 0.4142 - val_mse_loss: 150.2297 - val_total_loss: 6.0677 - val_loss1: 0.7821 - val_loss2: 5.2856 - val_reconstruction_loss: -500.4648 - val_accuracy: 0.4619\n",
      "Epoch 97/300\n",
      "59/59 [==============================] - 3s 48ms/step - mse_loss: 170.9271 - total_loss: 6.2056 - loss1: 1.0203 - loss2: 5.1853 - reconstruction_loss: -592.5272 - accuracy: 0.4073 - val_mse_loss: 154.9361 - val_total_loss: 6.0682 - val_loss1: 1.1573 - val_loss2: 4.9109 - val_reconstruction_loss: -499.6760 - val_accuracy: 0.4715\n",
      "Epoch 98/300\n",
      "59/59 [==============================] - 2s 40ms/step - mse_loss: 153.9179 - total_loss: 6.0847 - loss1: 1.0120 - loss2: 5.0727 - reconstruction_loss: -581.3038 - accuracy: 0.4158 - val_mse_loss: 171.6851 - val_total_loss: 6.1898 - val_loss1: 0.8203 - val_loss2: 5.3695 - val_reconstruction_loss: -499.3658 - val_accuracy: 0.4088\n",
      "Epoch 99/300\n",
      "59/59 [==============================] - 2s 40ms/step - mse_loss: 151.1989 - total_loss: 6.0864 - loss1: 1.0149 - loss2: 5.0716 - reconstruction_loss: -581.6117 - accuracy: 0.4169 - val_mse_loss: 179.9477 - val_total_loss: 6.2525 - val_loss1: 1.2066 - val_loss2: 5.0459 - val_reconstruction_loss: -498.2879 - val_accuracy: 0.4654\n",
      "Epoch 100/300\n",
      "59/59 [==============================] - 3s 54ms/step - mse_loss: 165.9586 - total_loss: 6.1651 - loss1: 1.0185 - loss2: 5.1466 - reconstruction_loss: -588.7821 - accuracy: 0.4036 - val_mse_loss: 174.7068 - val_total_loss: 6.3173 - val_loss1: 1.5965 - val_loss2: 4.7208 - val_reconstruction_loss: -499.1425 - val_accuracy: 0.4597\n",
      "Epoch 101/300\n",
      "59/59 [==============================] - 3s 49ms/step - mse_loss: 153.7863 - total_loss: 6.0865 - loss1: 1.0139 - loss2: 5.0726 - reconstruction_loss: -584.5974 - accuracy: 0.4168 - val_mse_loss: 214.4453 - val_total_loss: 6.5680 - val_loss1: 1.6948 - val_loss2: 4.8732 - val_reconstruction_loss: -499.2904 - val_accuracy: 0.4097\n",
      "Epoch 102/300\n",
      "59/59 [==============================] - 2s 38ms/step - mse_loss: 165.3668 - total_loss: 6.2008 - loss1: 1.0410 - loss2: 5.1598 - reconstruction_loss: -588.7119 - accuracy: 0.4066 - val_mse_loss: 165.3381 - val_total_loss: 6.2104 - val_loss1: 0.6554 - val_loss2: 5.5550 - val_reconstruction_loss: -499.2271 - val_accuracy: 0.4694\n",
      "Epoch 103/300\n",
      "59/59 [==============================] - 2s 40ms/step - mse_loss: 178.5567 - total_loss: 6.2761 - loss1: 1.0280 - loss2: 5.2481 - reconstruction_loss: -595.0019 - accuracy: 0.3997 - val_mse_loss: 185.1411 - val_total_loss: 6.2631 - val_loss1: 1.0536 - val_loss2: 5.2095 - val_reconstruction_loss: -499.1383 - val_accuracy: 0.4465\n",
      "Epoch 104/300\n",
      "59/59 [==============================] - 3s 49ms/step - mse_loss: 165.3566 - total_loss: 6.1657 - loss1: 1.0057 - loss2: 5.1600 - reconstruction_loss: -583.9798 - accuracy: 0.4122 - val_mse_loss: 155.1612 - val_total_loss: 6.1059 - val_loss1: 1.2998 - val_loss2: 4.8062 - val_reconstruction_loss: -498.8711 - val_accuracy: 0.4222\n",
      "Epoch 105/300\n",
      "59/59 [==============================] - 3s 46ms/step - mse_loss: 159.8403 - total_loss: 6.1320 - loss1: 1.0220 - loss2: 5.1100 - reconstruction_loss: -586.3595 - accuracy: 0.4120 - val_mse_loss: 210.0280 - val_total_loss: 6.4296 - val_loss1: 1.3936 - val_loss2: 5.0361 - val_reconstruction_loss: -497.8229 - val_accuracy: 0.4872\n",
      "Epoch 106/300\n",
      "59/59 [==============================] - 2s 42ms/step - mse_loss: 174.2341 - total_loss: 6.2408 - loss1: 1.0317 - loss2: 5.2091 - reconstruction_loss: -580.5577 - accuracy: 0.4077 - val_mse_loss: 206.9958 - val_total_loss: 6.3791 - val_loss1: 0.8967 - val_loss2: 5.4824 - val_reconstruction_loss: -499.2907 - val_accuracy: 0.4231\n",
      "Epoch 107/300\n",
      "59/59 [==============================] - 2s 38ms/step - mse_loss: 177.4092 - total_loss: 6.2788 - loss1: 1.0145 - loss2: 5.2643 - reconstruction_loss: -574.8129 - accuracy: 0.4066 - val_mse_loss: 179.6758 - val_total_loss: 6.3017 - val_loss1: 1.4505 - val_loss2: 4.8512 - val_reconstruction_loss: -499.6982 - val_accuracy: 0.4772\n",
      "Epoch 108/300\n",
      "59/59 [==============================] - 2s 38ms/step - mse_loss: 619.2849 - total_loss: 7.7259 - loss1: 1.1864 - loss2: 6.5395 - reconstruction_loss: -576.0589 - accuracy: 0.3212 - val_mse_loss: 617.6605 - val_total_loss: 7.7600 - val_loss1: 0.5102 - val_loss2: 7.2498 - val_reconstruction_loss: -496.4496 - val_accuracy: 0.1918\n",
      "Epoch 109/300\n",
      "59/59 [==============================] - 2s 37ms/step - mse_loss: 299.8956 - total_loss: 6.8447 - loss1: 1.0624 - loss2: 5.7823 - reconstruction_loss: -578.5065 - accuracy: 0.2417 - val_mse_loss: 193.0593 - val_total_loss: 6.3440 - val_loss1: 1.2723 - val_loss2: 5.0717 - val_reconstruction_loss: -499.4555 - val_accuracy: 0.4259\n",
      "Epoch 110/300\n",
      "59/59 [==============================] - 2s 37ms/step - mse_loss: 167.5663 - total_loss: 6.1828 - loss1: 1.0133 - loss2: 5.1696 - reconstruction_loss: -580.9972 - accuracy: 0.4036 - val_mse_loss: 183.8129 - val_total_loss: 6.3216 - val_loss1: 1.4105 - val_loss2: 4.9111 - val_reconstruction_loss: -499.5524 - val_accuracy: 0.4375\n",
      "Epoch 111/300\n",
      "59/59 [==============================] - 2s 37ms/step - mse_loss: 147.2080 - total_loss: 6.0415 - loss1: 1.0176 - loss2: 5.0239 - reconstruction_loss: -587.1645 - accuracy: 0.4202 - val_mse_loss: 164.4756 - val_total_loss: 6.3098 - val_loss1: 1.7315 - val_loss2: 4.5783 - val_reconstruction_loss: -499.6565 - val_accuracy: 0.4505\n",
      "Epoch 112/300\n",
      "59/59 [==============================] - 2s 36ms/step - mse_loss: 160.2812 - total_loss: 6.1448 - loss1: 1.0282 - loss2: 5.1167 - reconstruction_loss: -584.6300 - accuracy: 0.4186 - val_mse_loss: 193.2582 - val_total_loss: 6.2888 - val_loss1: 1.0172 - val_loss2: 5.2716 - val_reconstruction_loss: -499.2892 - val_accuracy: 0.4426\n",
      "Epoch 113/300\n",
      "59/59 [==============================] - 2s 36ms/step - mse_loss: 155.9468 - total_loss: 6.1090 - loss1: 1.0164 - loss2: 5.0926 - reconstruction_loss: -580.6101 - accuracy: 0.4188 - val_mse_loss: 157.3944 - val_total_loss: 6.1100 - val_loss1: 1.2726 - val_loss2: 4.8374 - val_reconstruction_loss: -499.5857 - val_accuracy: 0.4420\n",
      "Epoch 114/300\n",
      "59/59 [==============================] - 2s 38ms/step - mse_loss: 140.6664 - total_loss: 5.9941 - loss1: 1.0148 - loss2: 4.9793 - reconstruction_loss: -596.4763 - accuracy: 0.4238 - val_mse_loss: 166.2156 - val_total_loss: 6.1560 - val_loss1: 1.2408 - val_loss2: 4.9152 - val_reconstruction_loss: -498.7886 - val_accuracy: 0.4706\n",
      "Epoch 115/300\n",
      "59/59 [==============================] - 2s 37ms/step - mse_loss: 136.0237 - total_loss: 5.9571 - loss1: 1.0167 - loss2: 4.9404 - reconstruction_loss: -580.0289 - accuracy: 0.4234 - val_mse_loss: 160.2226 - val_total_loss: 6.0973 - val_loss1: 1.0972 - val_loss2: 5.0001 - val_reconstruction_loss: -498.8432 - val_accuracy: 0.4738\n",
      "Epoch 116/300\n",
      "59/59 [==============================] - 2s 40ms/step - mse_loss: 155.0383 - total_loss: 6.1063 - loss1: 1.0236 - loss2: 5.0827 - reconstruction_loss: -583.3122 - accuracy: 0.4143 - val_mse_loss: 182.9155 - val_total_loss: 6.2400 - val_loss1: 1.0403 - val_loss2: 5.1997 - val_reconstruction_loss: -498.4941 - val_accuracy: 0.4825\n",
      "Epoch 117/300\n",
      "59/59 [==============================] - 2s 38ms/step - mse_loss: 155.1408 - total_loss: 6.1118 - loss1: 1.0146 - loss2: 5.0972 - reconstruction_loss: -590.9920 - accuracy: 0.4207 - val_mse_loss: 177.7536 - val_total_loss: 6.2411 - val_loss1: 1.3385 - val_loss2: 4.9027 - val_reconstruction_loss: -499.1807 - val_accuracy: 0.3904\n",
      "Epoch 118/300\n",
      "59/59 [==============================] - 2s 35ms/step - mse_loss: 141.8074 - total_loss: 5.9909 - loss1: 1.0159 - loss2: 4.9750 - reconstruction_loss: -585.1817 - accuracy: 0.4212 - val_mse_loss: 155.7720 - val_total_loss: 6.0794 - val_loss1: 1.1517 - val_loss2: 4.9277 - val_reconstruction_loss: -499.5613 - val_accuracy: 0.4099\n",
      "Epoch 119/300\n",
      "59/59 [==============================] - 2s 34ms/step - mse_loss: 137.9871 - total_loss: 5.9787 - loss1: 1.0190 - loss2: 4.9597 - reconstruction_loss: -582.9147 - accuracy: 0.4185 - val_mse_loss: 159.8626 - val_total_loss: 6.0942 - val_loss1: 1.0482 - val_loss2: 5.0461 - val_reconstruction_loss: -499.2069 - val_accuracy: 0.4765\n",
      "Epoch 120/300\n",
      "59/59 [==============================] - 2s 36ms/step - mse_loss: 130.8053 - total_loss: 5.9146 - loss1: 1.0111 - loss2: 4.9035 - reconstruction_loss: -585.7204 - accuracy: 0.4258 - val_mse_loss: 162.9589 - val_total_loss: 6.1124 - val_loss1: 0.9479 - val_loss2: 5.1646 - val_reconstruction_loss: -499.2960 - val_accuracy: 0.4873\n",
      "Epoch 121/300\n",
      "59/59 [==============================] - 2s 35ms/step - mse_loss: 135.6079 - total_loss: 5.9649 - loss1: 1.0067 - loss2: 4.9582 - reconstruction_loss: -576.5571 - accuracy: 0.4258 - val_mse_loss: 159.6163 - val_total_loss: 6.1677 - val_loss1: 1.3966 - val_loss2: 4.7710 - val_reconstruction_loss: -499.5016 - val_accuracy: 0.4489\n",
      "Epoch 122/300\n",
      "59/59 [==============================] - 2s 35ms/step - mse_loss: 144.1932 - total_loss: 6.0232 - loss1: 1.0241 - loss2: 4.9991 - reconstruction_loss: -589.8133 - accuracy: 0.4211 - val_mse_loss: 162.7124 - val_total_loss: 6.1131 - val_loss1: 1.1027 - val_loss2: 5.0103 - val_reconstruction_loss: -498.5753 - val_accuracy: 0.4596\n",
      "Epoch 123/300\n",
      "59/59 [==============================] - 2s 36ms/step - mse_loss: 136.8838 - total_loss: 5.9626 - loss1: 1.0089 - loss2: 4.9536 - reconstruction_loss: -585.7826 - accuracy: 0.4225 - val_mse_loss: 164.3029 - val_total_loss: 6.2197 - val_loss1: 1.4386 - val_loss2: 4.7812 - val_reconstruction_loss: -498.7832 - val_accuracy: 0.4482\n",
      "Epoch 124/300\n",
      "59/59 [==============================] - 2s 37ms/step - mse_loss: 138.3834 - total_loss: 5.9928 - loss1: 1.0209 - loss2: 4.9719 - reconstruction_loss: -585.9445 - accuracy: 0.4232 - val_mse_loss: 182.1328 - val_total_loss: 6.2662 - val_loss1: 1.1356 - val_loss2: 5.1306 - val_reconstruction_loss: -498.6295 - val_accuracy: 0.4848\n",
      "Epoch 125/300\n",
      "59/59 [==============================] - 2s 35ms/step - mse_loss: 139.7539 - total_loss: 5.9930 - loss1: 1.0165 - loss2: 4.9766 - reconstruction_loss: -593.0869 - accuracy: 0.4214 - val_mse_loss: 153.8455 - val_total_loss: 6.2320 - val_loss1: 1.6978 - val_loss2: 4.5342 - val_reconstruction_loss: -499.2140 - val_accuracy: 0.4654\n",
      "Epoch 126/300\n",
      "59/59 [==============================] - 2s 36ms/step - mse_loss: 131.2844 - total_loss: 5.9244 - loss1: 1.0034 - loss2: 4.9210 - reconstruction_loss: -592.6231 - accuracy: 0.4237 - val_mse_loss: 180.9844 - val_total_loss: 6.5096 - val_loss1: 1.9801 - val_loss2: 4.5295 - val_reconstruction_loss: -498.1019 - val_accuracy: 0.4717\n",
      "Epoch 127/300\n",
      "59/59 [==============================] - 2s 39ms/step - mse_loss: 132.2047 - total_loss: 5.9392 - loss1: 1.0145 - loss2: 4.9247 - reconstruction_loss: -580.1560 - accuracy: 0.4226 - val_mse_loss: 152.9129 - val_total_loss: 6.6370 - val_loss1: 2.4285 - val_loss2: 4.2085 - val_reconstruction_loss: -499.3505 - val_accuracy: 0.4380\n",
      "Epoch 128/300\n",
      "59/59 [==============================] - 2s 35ms/step - mse_loss: 142.8023 - total_loss: 6.0347 - loss1: 1.0371 - loss2: 4.9976 - reconstruction_loss: -585.7075 - accuracy: 0.4207 - val_mse_loss: 348.4065 - val_total_loss: 6.9462 - val_loss1: 1.1424 - val_loss2: 5.8038 - val_reconstruction_loss: -496.4319 - val_accuracy: 0.3925\n",
      "Epoch 129/300\n",
      "59/59 [==============================] - 2s 36ms/step - mse_loss: 179.5069 - total_loss: 6.2835 - loss1: 1.0412 - loss2: 5.2423 - reconstruction_loss: -586.4261 - accuracy: 0.4082 - val_mse_loss: 177.2372 - val_total_loss: 6.2135 - val_loss1: 0.8782 - val_loss2: 5.3353 - val_reconstruction_loss: -498.6516 - val_accuracy: 0.4786\n",
      "Epoch 130/300\n",
      "59/59 [==============================] - 2s 35ms/step - mse_loss: 144.8661 - total_loss: 6.0702 - loss1: 1.0294 - loss2: 5.0408 - reconstruction_loss: -584.3907 - accuracy: 0.4160 - val_mse_loss: 165.8283 - val_total_loss: 6.1422 - val_loss1: 1.1090 - val_loss2: 5.0332 - val_reconstruction_loss: -498.1685 - val_accuracy: 0.3938\n",
      "Epoch 131/300\n",
      "59/59 [==============================] - 2s 36ms/step - mse_loss: 134.4047 - total_loss: 5.9687 - loss1: 1.0151 - loss2: 4.9537 - reconstruction_loss: -590.5482 - accuracy: 0.4223 - val_mse_loss: 162.8336 - val_total_loss: 6.1285 - val_loss1: 1.1688 - val_loss2: 4.9597 - val_reconstruction_loss: -499.1761 - val_accuracy: 0.4144\n",
      "Epoch 132/300\n",
      "59/59 [==============================] - 2s 38ms/step - mse_loss: 136.8425 - total_loss: 5.9637 - loss1: 1.0247 - loss2: 4.9391 - reconstruction_loss: -590.0579 - accuracy: 0.4221 - val_mse_loss: 191.4630 - val_total_loss: 6.3175 - val_loss1: 1.1584 - val_loss2: 5.1591 - val_reconstruction_loss: -496.6263 - val_accuracy: 0.4581\n",
      "Epoch 133/300\n",
      "59/59 [==============================] - 2s 38ms/step - mse_loss: 148.8108 - total_loss: 6.0784 - loss1: 1.0228 - loss2: 5.0556 - reconstruction_loss: -593.5720 - accuracy: 0.4217 - val_mse_loss: 184.9318 - val_total_loss: 6.2523 - val_loss1: 0.9416 - val_loss2: 5.3107 - val_reconstruction_loss: -497.2606 - val_accuracy: 0.4414\n",
      "Epoch 134/300\n",
      "59/59 [==============================] - 2s 37ms/step - mse_loss: 145.0508 - total_loss: 6.0374 - loss1: 1.0169 - loss2: 5.0205 - reconstruction_loss: -597.4716 - accuracy: 0.4170 - val_mse_loss: 173.8950 - val_total_loss: 6.2057 - val_loss1: 1.2444 - val_loss2: 4.9613 - val_reconstruction_loss: -499.4943 - val_accuracy: 0.4472\n",
      "Epoch 135/300\n",
      "59/59 [==============================] - 2s 37ms/step - mse_loss: 130.2485 - total_loss: 5.9258 - loss1: 1.0233 - loss2: 4.9025 - reconstruction_loss: -570.0680 - accuracy: 0.4256 - val_mse_loss: 166.2538 - val_total_loss: 6.3223 - val_loss1: 1.7355 - val_loss2: 4.5868 - val_reconstruction_loss: -498.1213 - val_accuracy: 0.4596\n",
      "Epoch 136/300\n",
      "59/59 [==============================] - 2s 36ms/step - mse_loss: 135.5768 - total_loss: 5.9751 - loss1: 1.0177 - loss2: 4.9574 - reconstruction_loss: -586.7898 - accuracy: 0.4234 - val_mse_loss: 179.5494 - val_total_loss: 6.5690 - val_loss1: 2.0760 - val_loss2: 4.4930 - val_reconstruction_loss: -498.0812 - val_accuracy: 0.4842\n",
      "Epoch 137/300\n",
      "59/59 [==============================] - 2s 38ms/step - mse_loss: 124.7548 - total_loss: 5.8674 - loss1: 1.0120 - loss2: 4.8555 - reconstruction_loss: -581.6975 - accuracy: 0.4284 - val_mse_loss: 166.6161 - val_total_loss: 6.2038 - val_loss1: 1.4240 - val_loss2: 4.7798 - val_reconstruction_loss: -498.2643 - val_accuracy: 0.4769\n",
      "Epoch 138/300\n",
      "59/59 [==============================] - 2s 34ms/step - mse_loss: 118.1678 - total_loss: 5.8049 - loss1: 1.0104 - loss2: 4.7946 - reconstruction_loss: -586.1356 - accuracy: 0.4310 - val_mse_loss: 160.4279 - val_total_loss: 6.1583 - val_loss1: 1.3815 - val_loss2: 4.7768 - val_reconstruction_loss: -498.8637 - val_accuracy: 0.4824\n",
      "Epoch 139/300\n",
      "59/59 [==============================] - 2s 37ms/step - mse_loss: 116.3742 - total_loss: 5.7959 - loss1: 1.0119 - loss2: 4.7840 - reconstruction_loss: -575.9225 - accuracy: 0.4327 - val_mse_loss: 166.2834 - val_total_loss: 6.2003 - val_loss1: 1.4087 - val_loss2: 4.7916 - val_reconstruction_loss: -499.2411 - val_accuracy: 0.4586\n",
      "Epoch 140/300\n",
      "59/59 [==============================] - 2s 37ms/step - mse_loss: 115.7268 - total_loss: 5.7984 - loss1: 1.0197 - loss2: 4.7787 - reconstruction_loss: -585.7378 - accuracy: 0.4299 - val_mse_loss: 178.5132 - val_total_loss: 6.2239 - val_loss1: 1.2283 - val_loss2: 4.9956 - val_reconstruction_loss: -499.2549 - val_accuracy: 0.4747\n",
      "Epoch 141/300\n",
      "59/59 [==============================] - 2s 34ms/step - mse_loss: 177.6573 - total_loss: 6.2597 - loss1: 1.0333 - loss2: 5.2263 - reconstruction_loss: -596.2995 - accuracy: 0.4068 - val_mse_loss: 185.5412 - val_total_loss: 6.2930 - val_loss1: 1.3400 - val_loss2: 4.9530 - val_reconstruction_loss: -497.6399 - val_accuracy: 0.4391\n",
      "Epoch 142/300\n",
      "59/59 [==============================] - 2s 34ms/step - mse_loss: 140.9744 - total_loss: 6.0066 - loss1: 1.0321 - loss2: 4.9745 - reconstruction_loss: -594.5849 - accuracy: 0.4182 - val_mse_loss: 174.2624 - val_total_loss: 6.1951 - val_loss1: 0.8669 - val_loss2: 5.3282 - val_reconstruction_loss: -498.5460 - val_accuracy: 0.4607\n",
      "Epoch 143/300\n",
      "59/59 [==============================] - 2s 34ms/step - mse_loss: 126.8492 - total_loss: 5.8929 - loss1: 1.0098 - loss2: 4.8831 - reconstruction_loss: -602.0391 - accuracy: 0.4279 - val_mse_loss: 182.6198 - val_total_loss: 6.2845 - val_loss1: 1.3942 - val_loss2: 4.8903 - val_reconstruction_loss: -498.9612 - val_accuracy: 0.4865\n",
      "Epoch 144/300\n",
      "59/59 [==============================] - 2s 34ms/step - mse_loss: 128.3075 - total_loss: 5.9166 - loss1: 1.0258 - loss2: 4.8907 - reconstruction_loss: -571.2452 - accuracy: 0.4284 - val_mse_loss: 165.5510 - val_total_loss: 6.1292 - val_loss1: 1.0785 - val_loss2: 5.0507 - val_reconstruction_loss: -498.6781 - val_accuracy: 0.4505\n",
      "Epoch 145/300\n",
      "59/59 [==============================] - 2s 33ms/step - mse_loss: 140.1041 - total_loss: 6.0415 - loss1: 1.0382 - loss2: 5.0033 - reconstruction_loss: -571.8719 - accuracy: 0.4236 - val_mse_loss: 212.4879 - val_total_loss: 6.4304 - val_loss1: 1.2497 - val_loss2: 5.1807 - val_reconstruction_loss: -497.9127 - val_accuracy: 0.4662\n",
      "Epoch 146/300\n",
      "59/59 [==============================] - 2s 34ms/step - mse_loss: 160.1996 - total_loss: 6.1438 - loss1: 1.0034 - loss2: 5.1404 - reconstruction_loss: -588.3779 - accuracy: 0.4171 - val_mse_loss: 211.8502 - val_total_loss: 7.1284 - val_loss1: 2.7336 - val_loss2: 4.3948 - val_reconstruction_loss: -498.5555 - val_accuracy: 0.4933\n",
      "Epoch 147/300\n",
      "59/59 [==============================] - 2s 36ms/step - mse_loss: 135.2997 - total_loss: 5.9581 - loss1: 1.0155 - loss2: 4.9426 - reconstruction_loss: -590.9293 - accuracy: 0.4281 - val_mse_loss: 187.9229 - val_total_loss: 6.7569 - val_loss1: 2.3426 - val_loss2: 4.4144 - val_reconstruction_loss: -498.1754 - val_accuracy: 0.4680\n",
      "Epoch 148/300\n",
      "59/59 [==============================] - 2s 35ms/step - mse_loss: 126.3943 - total_loss: 5.9140 - loss1: 1.0331 - loss2: 4.8810 - reconstruction_loss: -584.3177 - accuracy: 0.4319 - val_mse_loss: 163.1879 - val_total_loss: 6.1618 - val_loss1: 1.3411 - val_loss2: 4.8207 - val_reconstruction_loss: -498.7995 - val_accuracy: 0.4478\n",
      "Epoch 149/300\n",
      "59/59 [==============================] - 2s 34ms/step - mse_loss: 116.2466 - total_loss: 5.8018 - loss1: 1.0111 - loss2: 4.7907 - reconstruction_loss: -587.4453 - accuracy: 0.4319 - val_mse_loss: 164.9771 - val_total_loss: 6.3695 - val_loss1: 1.8785 - val_loss2: 4.4910 - val_reconstruction_loss: -499.5201 - val_accuracy: 0.4785\n",
      "Epoch 150/300\n",
      "59/59 [==============================] - 2s 37ms/step - mse_loss: 111.8969 - total_loss: 5.7537 - loss1: 1.0074 - loss2: 4.7463 - reconstruction_loss: -584.4050 - accuracy: 0.4375 - val_mse_loss: 174.7603 - val_total_loss: 6.6097 - val_loss1: 2.2333 - val_loss2: 4.3764 - val_reconstruction_loss: -497.9475 - val_accuracy: 0.4591\n",
      "Epoch 151/300\n",
      "59/59 [==============================] - 2s 35ms/step - mse_loss: 111.9955 - total_loss: 5.7688 - loss1: 1.0249 - loss2: 4.7439 - reconstruction_loss: -571.5676 - accuracy: 0.4367 - val_mse_loss: 173.8915 - val_total_loss: 6.2560 - val_loss1: 1.4685 - val_loss2: 4.7875 - val_reconstruction_loss: -498.8281 - val_accuracy: 0.4256\n",
      "Epoch 152/300\n",
      "59/59 [==============================] - 2s 35ms/step - mse_loss: 134.3239 - total_loss: 5.9782 - loss1: 1.0196 - loss2: 4.9587 - reconstruction_loss: -593.8886 - accuracy: 0.4246 - val_mse_loss: 200.6184 - val_total_loss: 6.6560 - val_loss1: 2.0346 - val_loss2: 4.6214 - val_reconstruction_loss: -497.4055 - val_accuracy: 0.4682\n",
      "Epoch 153/300\n",
      "59/59 [==============================] - 2s 36ms/step - mse_loss: 117.5746 - total_loss: 5.8129 - loss1: 1.0014 - loss2: 4.8114 - reconstruction_loss: -577.1518 - accuracy: 0.4330 - val_mse_loss: 184.9779 - val_total_loss: 7.0737 - val_loss1: 2.8869 - val_loss2: 4.1868 - val_reconstruction_loss: -498.2285 - val_accuracy: 0.4865\n",
      "Epoch 154/300\n",
      "59/59 [==============================] - 2s 36ms/step - mse_loss: 117.0095 - total_loss: 5.8316 - loss1: 1.0371 - loss2: 4.7945 - reconstruction_loss: -592.8168 - accuracy: 0.4363 - val_mse_loss: 168.8877 - val_total_loss: 6.1880 - val_loss1: 1.3131 - val_loss2: 4.8749 - val_reconstruction_loss: -497.8492 - val_accuracy: 0.4842\n",
      "Epoch 155/300\n",
      "59/59 [==============================] - 2s 36ms/step - mse_loss: 128.1021 - total_loss: 5.9286 - loss1: 1.0242 - loss2: 4.9044 - reconstruction_loss: -585.0802 - accuracy: 0.4295 - val_mse_loss: 190.3853 - val_total_loss: 6.8344 - val_loss1: 2.4565 - val_loss2: 4.3779 - val_reconstruction_loss: -498.8069 - val_accuracy: 0.4893\n",
      "Epoch 156/300\n",
      "59/59 [==============================] - 2s 35ms/step - mse_loss: 141.5160 - total_loss: 6.0400 - loss1: 1.0364 - loss2: 5.0036 - reconstruction_loss: -588.7190 - accuracy: 0.4269 - val_mse_loss: 194.7682 - val_total_loss: 6.3610 - val_loss1: 1.3351 - val_loss2: 5.0258 - val_reconstruction_loss: -498.9130 - val_accuracy: 0.4514\n",
      "Epoch 157/300\n",
      "59/59 [==============================] - 2s 35ms/step - mse_loss: 129.5977 - total_loss: 5.9335 - loss1: 1.0168 - loss2: 4.9167 - reconstruction_loss: -600.7542 - accuracy: 0.4286 - val_mse_loss: 167.2764 - val_total_loss: 6.1922 - val_loss1: 1.3282 - val_loss2: 4.8640 - val_reconstruction_loss: -499.0478 - val_accuracy: 0.4752\n",
      "Epoch 158/300\n",
      "59/59 [==============================] - 3s 48ms/step - mse_loss: 113.6421 - total_loss: 5.7737 - loss1: 1.0113 - loss2: 4.7624 - reconstruction_loss: -580.1451 - accuracy: 0.4377 - val_mse_loss: 169.0865 - val_total_loss: 6.5070 - val_loss1: 2.1162 - val_loss2: 4.3909 - val_reconstruction_loss: -499.1671 - val_accuracy: 0.4550\n",
      "Epoch 159/300\n",
      "59/59 [==============================] - 3s 58ms/step - mse_loss: 111.5886 - total_loss: 5.7635 - loss1: 1.0254 - loss2: 4.7380 - reconstruction_loss: -595.1974 - accuracy: 0.4392 - val_mse_loss: 167.3368 - val_total_loss: 6.3384 - val_loss1: 1.7743 - val_loss2: 4.5641 - val_reconstruction_loss: -499.5356 - val_accuracy: 0.4836\n",
      "Epoch 160/300\n",
      "59/59 [==============================] - 3s 46ms/step - mse_loss: 106.7104 - total_loss: 5.7015 - loss1: 1.0049 - loss2: 4.6966 - reconstruction_loss: -588.8866 - accuracy: 0.4413 - val_mse_loss: 167.9942 - val_total_loss: 6.1892 - val_loss1: 1.3458 - val_loss2: 4.8435 - val_reconstruction_loss: -498.3849 - val_accuracy: 0.4911\n",
      "Epoch 161/300\n",
      "59/59 [==============================] - 3s 47ms/step - mse_loss: 109.1474 - total_loss: 5.7449 - loss1: 1.0157 - loss2: 4.7292 - reconstruction_loss: -575.2886 - accuracy: 0.4390 - val_mse_loss: 204.5503 - val_total_loss: 7.8642 - val_loss1: 3.8651 - val_loss2: 3.9990 - val_reconstruction_loss: -497.4746 - val_accuracy: 0.4534\n",
      "Epoch 162/300\n",
      "59/59 [==============================] - 3s 50ms/step - mse_loss: 112.3512 - total_loss: 5.7760 - loss1: 1.0154 - loss2: 4.7606 - reconstruction_loss: -591.8394 - accuracy: 0.4367 - val_mse_loss: 172.7775 - val_total_loss: 7.1745 - val_loss1: 3.1535 - val_loss2: 4.0210 - val_reconstruction_loss: -498.2291 - val_accuracy: 0.4592\n",
      "Epoch 163/300\n",
      "59/59 [==============================] - 3s 48ms/step - mse_loss: 120.0709 - total_loss: 5.8554 - loss1: 1.0226 - loss2: 4.8327 - reconstruction_loss: -590.3364 - accuracy: 0.4336 - val_mse_loss: 188.8004 - val_total_loss: 6.8445 - val_loss1: 2.4949 - val_loss2: 4.3496 - val_reconstruction_loss: -498.4167 - val_accuracy: 0.4648\n",
      "Epoch 164/300\n",
      "59/59 [==============================] - 2s 38ms/step - mse_loss: 109.9423 - total_loss: 5.7608 - loss1: 1.0133 - loss2: 4.7476 - reconstruction_loss: -582.7932 - accuracy: 0.4387 - val_mse_loss: 181.6238 - val_total_loss: 7.0137 - val_loss1: 2.8442 - val_loss2: 4.1695 - val_reconstruction_loss: -499.3892 - val_accuracy: 0.4552\n",
      "Epoch 165/300\n",
      "59/59 [==============================] - 3s 44ms/step - mse_loss: 110.1033 - total_loss: 5.7602 - loss1: 1.0301 - loss2: 4.7301 - reconstruction_loss: -576.3904 - accuracy: 0.4401 - val_mse_loss: 190.3825 - val_total_loss: 7.2372 - val_loss1: 3.0966 - val_loss2: 4.1406 - val_reconstruction_loss: -499.4401 - val_accuracy: 0.4709\n",
      "Epoch 166/300\n",
      "59/59 [==============================] - 3s 50ms/step - mse_loss: 107.6814 - total_loss: 5.7232 - loss1: 1.0077 - loss2: 4.7155 - reconstruction_loss: -582.6358 - accuracy: 0.4400 - val_mse_loss: 185.8156 - val_total_loss: 6.9443 - val_loss1: 2.7040 - val_loss2: 4.2403 - val_reconstruction_loss: -498.6729 - val_accuracy: 0.4792\n",
      "Epoch 167/300\n",
      "59/59 [==============================] - 3s 44ms/step - mse_loss: 111.9438 - total_loss: 5.7667 - loss1: 1.0231 - loss2: 4.7437 - reconstruction_loss: -586.9805 - accuracy: 0.4409 - val_mse_loss: 169.4450 - val_total_loss: 6.5530 - val_loss1: 2.1699 - val_loss2: 4.3832 - val_reconstruction_loss: -498.8949 - val_accuracy: 0.4596\n",
      "Epoch 168/300\n",
      "59/59 [==============================] - 2s 38ms/step - mse_loss: 107.1058 - total_loss: 5.7280 - loss1: 1.0150 - loss2: 4.7130 - reconstruction_loss: -576.6742 - accuracy: 0.4413 - val_mse_loss: 183.1248 - val_total_loss: 6.9645 - val_loss1: 2.7449 - val_loss2: 4.2196 - val_reconstruction_loss: -499.2394 - val_accuracy: 0.4646\n",
      "Epoch 169/300\n",
      "59/59 [==============================] - 3s 43ms/step - mse_loss: 102.5898 - total_loss: 5.6892 - loss1: 1.0207 - loss2: 4.6684 - reconstruction_loss: -579.1731 - accuracy: 0.4428 - val_mse_loss: 178.6159 - val_total_loss: 6.3568 - val_loss1: 1.6300 - val_loss2: 4.7268 - val_reconstruction_loss: -499.1081 - val_accuracy: 0.4984\n",
      "Epoch 170/300\n",
      "59/59 [==============================] - 3s 49ms/step - mse_loss: 104.4579 - total_loss: 5.7206 - loss1: 1.0261 - loss2: 4.6945 - reconstruction_loss: -577.1867 - accuracy: 0.4433 - val_mse_loss: 194.5580 - val_total_loss: 6.7940 - val_loss1: 2.3752 - val_loss2: 4.4188 - val_reconstruction_loss: -499.0061 - val_accuracy: 0.4570\n",
      "Epoch 171/300\n",
      "59/59 [==============================] - 3s 46ms/step - mse_loss: 113.6521 - total_loss: 5.8201 - loss1: 1.0295 - loss2: 4.7906 - reconstruction_loss: -587.7133 - accuracy: 0.4405 - val_mse_loss: 169.5509 - val_total_loss: 6.2402 - val_loss1: 1.4860 - val_loss2: 4.7542 - val_reconstruction_loss: -498.6502 - val_accuracy: 0.4885\n",
      "Epoch 172/300\n",
      "59/59 [==============================] - 2s 39ms/step - mse_loss: 101.3848 - total_loss: 5.6649 - loss1: 1.0183 - loss2: 4.6466 - reconstruction_loss: -583.7986 - accuracy: 0.4439 - val_mse_loss: 177.3265 - val_total_loss: 6.2096 - val_loss1: 1.1775 - val_loss2: 5.0321 - val_reconstruction_loss: -497.9220 - val_accuracy: 0.4779\n",
      "Epoch 173/300\n",
      "59/59 [==============================] - 3s 45ms/step - mse_loss: 98.8718 - total_loss: 5.6386 - loss1: 1.0154 - loss2: 4.6231 - reconstruction_loss: -586.3284 - accuracy: 0.4433 - val_mse_loss: 192.6739 - val_total_loss: 6.3344 - val_loss1: 1.3882 - val_loss2: 4.9462 - val_reconstruction_loss: -498.5212 - val_accuracy: 0.4989\n",
      "Epoch 174/300\n",
      "59/59 [==============================] - 3s 53ms/step - mse_loss: 97.0098 - total_loss: 5.6111 - loss1: 1.0119 - loss2: 4.5992 - reconstruction_loss: -586.6265 - accuracy: 0.4455 - val_mse_loss: 170.5059 - val_total_loss: 6.2626 - val_loss1: 1.5376 - val_loss2: 4.7250 - val_reconstruction_loss: -498.5936 - val_accuracy: 0.4856\n",
      "Epoch 175/300\n",
      "59/59 [==============================] - 2s 40ms/step - mse_loss: 115.8522 - total_loss: 5.8345 - loss1: 1.0255 - loss2: 4.8090 - reconstruction_loss: -577.7578 - accuracy: 0.4384 - val_mse_loss: 205.6258 - val_total_loss: 7.1875 - val_loss1: 2.8828 - val_loss2: 4.3047 - val_reconstruction_loss: -498.4859 - val_accuracy: 0.4496\n",
      "Epoch 176/300\n",
      "59/59 [==============================] - 2s 38ms/step - mse_loss: 110.1288 - total_loss: 5.7767 - loss1: 1.0245 - loss2: 4.7522 - reconstruction_loss: -586.5475 - accuracy: 0.4385 - val_mse_loss: 208.0693 - val_total_loss: 6.7895 - val_loss1: 2.2331 - val_loss2: 4.5564 - val_reconstruction_loss: -498.9346 - val_accuracy: 0.4366\n",
      "Epoch 177/300\n",
      "59/59 [==============================] - 3s 44ms/step - mse_loss: 117.7287 - total_loss: 5.8125 - loss1: 1.0170 - loss2: 4.7954 - reconstruction_loss: -594.6909 - accuracy: 0.4375 - val_mse_loss: 188.1059 - val_total_loss: 6.7711 - val_loss1: 2.3793 - val_loss2: 4.3918 - val_reconstruction_loss: -498.4178 - val_accuracy: 0.4999\n",
      "Epoch 178/300\n",
      "59/59 [==============================] - 3s 48ms/step - mse_loss: 108.5615 - total_loss: 5.7355 - loss1: 1.0286 - loss2: 4.7069 - reconstruction_loss: -581.1759 - accuracy: 0.4427 - val_mse_loss: 180.6234 - val_total_loss: 6.3812 - val_loss1: 1.6915 - val_loss2: 4.6897 - val_reconstruction_loss: -498.8399 - val_accuracy: 0.4854\n",
      "Epoch 179/300\n",
      "59/59 [==============================] - 2s 40ms/step - mse_loss: 116.8754 - total_loss: 5.8430 - loss1: 1.0226 - loss2: 4.8204 - reconstruction_loss: -584.2629 - accuracy: 0.4370 - val_mse_loss: 186.4095 - val_total_loss: 6.5323 - val_loss1: 1.9462 - val_loss2: 4.5861 - val_reconstruction_loss: -498.9340 - val_accuracy: 0.4883\n",
      "Epoch 180/300\n",
      "59/59 [==============================] - 2s 38ms/step - mse_loss: 106.6780 - total_loss: 5.7264 - loss1: 1.0129 - loss2: 4.7135 - reconstruction_loss: -597.0369 - accuracy: 0.4409 - val_mse_loss: 178.4283 - val_total_loss: 6.5960 - val_loss1: 2.1704 - val_loss2: 4.4255 - val_reconstruction_loss: -499.0139 - val_accuracy: 0.4871\n",
      "Epoch 181/300\n",
      "59/59 [==============================] - 2s 42ms/step - mse_loss: 98.0588 - total_loss: 5.6349 - loss1: 1.0213 - loss2: 4.6136 - reconstruction_loss: -590.0070 - accuracy: 0.4466 - val_mse_loss: 187.4532 - val_total_loss: 6.4190 - val_loss1: 1.6775 - val_loss2: 4.7416 - val_reconstruction_loss: -498.8173 - val_accuracy: 0.4743\n",
      "Epoch 182/300\n",
      "59/59 [==============================] - 3s 46ms/step - mse_loss: 98.2962 - total_loss: 5.6219 - loss1: 1.0093 - loss2: 4.6127 - reconstruction_loss: -581.7377 - accuracy: 0.4471 - val_mse_loss: 175.1928 - val_total_loss: 6.6220 - val_loss1: 2.2302 - val_loss2: 4.3918 - val_reconstruction_loss: -499.3214 - val_accuracy: 0.4825\n",
      "Epoch 183/300\n",
      "59/59 [==============================] - 2s 41ms/step - mse_loss: 104.0776 - total_loss: 5.7045 - loss1: 1.0350 - loss2: 4.6695 - reconstruction_loss: -594.4126 - accuracy: 0.4452 - val_mse_loss: 172.4248 - val_total_loss: 6.1848 - val_loss1: 0.9653 - val_loss2: 5.2195 - val_reconstruction_loss: -499.7244 - val_accuracy: 0.4705\n",
      "Epoch 184/300\n",
      "59/59 [==============================] - 2s 40ms/step - mse_loss: 105.6425 - total_loss: 5.7136 - loss1: 1.0002 - loss2: 4.7134 - reconstruction_loss: -579.2179 - accuracy: 0.4435 - val_mse_loss: 190.4976 - val_total_loss: 6.6790 - val_loss1: 2.1847 - val_loss2: 4.4943 - val_reconstruction_loss: -497.8851 - val_accuracy: 0.4892\n",
      "Epoch 185/300\n",
      "59/59 [==============================] - 3s 48ms/step - mse_loss: 95.6041 - total_loss: 5.5983 - loss1: 1.0235 - loss2: 4.5748 - reconstruction_loss: -583.7502 - accuracy: 0.4485 - val_mse_loss: 161.3098 - val_total_loss: 6.2443 - val_loss1: 1.6347 - val_loss2: 4.6096 - val_reconstruction_loss: -498.8567 - val_accuracy: 0.4825\n",
      "Epoch 186/300\n",
      "59/59 [==============================] - 3s 56ms/step - mse_loss: 93.8221 - total_loss: 5.5756 - loss1: 0.9952 - loss2: 4.5804 - reconstruction_loss: -583.7119 - accuracy: 0.4478 - val_mse_loss: 168.0731 - val_total_loss: 6.9778 - val_loss1: 2.9081 - val_loss2: 4.0697 - val_reconstruction_loss: -499.1129 - val_accuracy: 0.4745\n",
      "Epoch 187/300\n",
      "59/59 [==============================] - 2s 38ms/step - mse_loss: 90.6854 - total_loss: 5.5379 - loss1: 1.0140 - loss2: 4.5239 - reconstruction_loss: -586.0230 - accuracy: 0.4497 - val_mse_loss: 185.0284 - val_total_loss: 6.7126 - val_loss1: 2.3231 - val_loss2: 4.3895 - val_reconstruction_loss: -498.3003 - val_accuracy: 0.4982\n",
      "Epoch 188/300\n",
      "59/59 [==============================] - 2s 39ms/step - mse_loss: 93.1832 - total_loss: 5.5742 - loss1: 1.0144 - loss2: 4.5598 - reconstruction_loss: -581.8562 - accuracy: 0.4491 - val_mse_loss: 191.7538 - val_total_loss: 6.7064 - val_loss1: 2.2435 - val_loss2: 4.4629 - val_reconstruction_loss: -497.9335 - val_accuracy: 0.4883\n",
      "Epoch 189/300\n",
      "59/59 [==============================] - 3s 49ms/step - mse_loss: 100.2282 - total_loss: 5.6493 - loss1: 1.0217 - loss2: 4.6277 - reconstruction_loss: -580.1690 - accuracy: 0.4477 - val_mse_loss: 184.5093 - val_total_loss: 6.4434 - val_loss1: 1.7735 - val_loss2: 4.6698 - val_reconstruction_loss: -498.6071 - val_accuracy: 0.4638\n",
      "Epoch 190/300\n",
      "59/59 [==============================] - 3s 51ms/step - mse_loss: 102.5426 - total_loss: 5.6809 - loss1: 1.0039 - loss2: 4.6771 - reconstruction_loss: -601.7749 - accuracy: 0.4464 - val_mse_loss: 195.5750 - val_total_loss: 7.1590 - val_loss1: 2.9378 - val_loss2: 4.2212 - val_reconstruction_loss: -498.9971 - val_accuracy: 0.4640\n",
      "Epoch 191/300\n",
      "59/59 [==============================] - 2s 37ms/step - mse_loss: 103.3399 - total_loss: 5.6971 - loss1: 1.0199 - loss2: 4.6772 - reconstruction_loss: -583.8362 - accuracy: 0.4450 - val_mse_loss: 193.3499 - val_total_loss: 6.6224 - val_loss1: 2.0430 - val_loss2: 4.5794 - val_reconstruction_loss: -497.5815 - val_accuracy: 0.4847\n",
      "Epoch 192/300\n",
      "59/59 [==============================] - 2s 38ms/step - mse_loss: 102.5064 - total_loss: 5.6887 - loss1: 1.0196 - loss2: 4.6691 - reconstruction_loss: -585.8410 - accuracy: 0.4468 - val_mse_loss: 203.8870 - val_total_loss: 7.7603 - val_loss1: 3.7301 - val_loss2: 4.0302 - val_reconstruction_loss: -498.6633 - val_accuracy: 0.4788\n",
      "Epoch 193/300\n",
      "59/59 [==============================] - 3s 47ms/step - mse_loss: 101.9700 - total_loss: 5.6841 - loss1: 1.0343 - loss2: 4.6498 - reconstruction_loss: -575.4990 - accuracy: 0.4469 - val_mse_loss: 183.7296 - val_total_loss: 6.7203 - val_loss1: 2.3262 - val_loss2: 4.3941 - val_reconstruction_loss: -498.6447 - val_accuracy: 0.4800\n",
      "Epoch 194/300\n",
      "59/59 [==============================] - 3s 47ms/step - mse_loss: 93.7492 - total_loss: 5.5882 - loss1: 1.0136 - loss2: 4.5747 - reconstruction_loss: -597.8313 - accuracy: 0.4486 - val_mse_loss: 179.2546 - val_total_loss: 6.7962 - val_loss1: 2.5150 - val_loss2: 4.2812 - val_reconstruction_loss: -500.2403 - val_accuracy: 0.4804\n",
      "Epoch 195/300\n",
      "59/59 [==============================] - 2s 38ms/step - mse_loss: 92.2667 - total_loss: 5.5643 - loss1: 1.0242 - loss2: 4.5401 - reconstruction_loss: -598.9979 - accuracy: 0.4509 - val_mse_loss: 171.1261 - val_total_loss: 6.1688 - val_loss1: 0.9997 - val_loss2: 5.1691 - val_reconstruction_loss: -499.5357 - val_accuracy: 0.4805\n",
      "Epoch 196/300\n",
      "59/59 [==============================] - 2s 39ms/step - mse_loss: 93.1758 - total_loss: 5.6006 - loss1: 1.0063 - loss2: 4.5943 - reconstruction_loss: -599.9216 - accuracy: 0.4511 - val_mse_loss: 186.8183 - val_total_loss: 6.4827 - val_loss1: 1.8563 - val_loss2: 4.6264 - val_reconstruction_loss: -499.4036 - val_accuracy: 0.4874\n",
      "Epoch 197/300\n",
      "59/59 [==============================] - 3s 51ms/step - mse_loss: 91.2533 - total_loss: 5.5575 - loss1: 1.0165 - loss2: 4.5410 - reconstruction_loss: -586.6903 - accuracy: 0.4524 - val_mse_loss: 180.1069 - val_total_loss: 6.4334 - val_loss1: 1.7370 - val_loss2: 4.6964 - val_reconstruction_loss: -499.8027 - val_accuracy: 0.4764\n",
      "Epoch 198/300\n",
      "59/59 [==============================] - 3s 51ms/step - mse_loss: 86.4712 - total_loss: 5.4905 - loss1: 1.0029 - loss2: 4.4876 - reconstruction_loss: -586.0133 - accuracy: 0.4546 - val_mse_loss: 169.7554 - val_total_loss: 6.9328 - val_loss1: 2.8082 - val_loss2: 4.1247 - val_reconstruction_loss: -499.1575 - val_accuracy: 0.4770\n",
      "Epoch 199/300\n",
      "59/59 [==============================] - 2s 39ms/step - mse_loss: 87.0889 - total_loss: 5.5107 - loss1: 1.0274 - loss2: 4.4834 - reconstruction_loss: -590.2496 - accuracy: 0.4534 - val_mse_loss: 176.4900 - val_total_loss: 6.5489 - val_loss1: 2.1114 - val_loss2: 4.4375 - val_reconstruction_loss: -499.5677 - val_accuracy: 0.4725\n",
      "Epoch 200/300\n",
      "59/59 [==============================] - 2s 38ms/step - mse_loss: 89.2777 - total_loss: 5.5457 - loss1: 1.0150 - loss2: 4.5307 - reconstruction_loss: -580.3911 - accuracy: 0.4527 - val_mse_loss: 185.4024 - val_total_loss: 6.2748 - val_loss1: 1.2723 - val_loss2: 5.0025 - val_reconstruction_loss: -498.3259 - val_accuracy: 0.4653\n",
      "Epoch 201/300\n",
      "59/59 [==============================] - 3s 55ms/step - mse_loss: 90.2111 - total_loss: 5.5649 - loss1: 1.0132 - loss2: 4.5516 - reconstruction_loss: -580.4236 - accuracy: 0.4514 - val_mse_loss: 181.2907 - val_total_loss: 6.8226 - val_loss1: 2.5475 - val_loss2: 4.2752 - val_reconstruction_loss: -499.2658 - val_accuracy: 0.4697\n",
      "Epoch 202/300\n",
      "59/59 [==============================] - 3s 47ms/step - mse_loss: 83.6980 - total_loss: 5.4670 - loss1: 1.0126 - loss2: 4.4544 - reconstruction_loss: -584.2906 - accuracy: 0.4533 - val_mse_loss: 174.9411 - val_total_loss: 6.8275 - val_loss1: 2.6160 - val_loss2: 4.2115 - val_reconstruction_loss: -499.5500 - val_accuracy: 0.4883\n",
      "Epoch 203/300\n",
      "59/59 [==============================] - 2s 38ms/step - mse_loss: 86.3847 - total_loss: 5.5028 - loss1: 1.0122 - loss2: 4.4906 - reconstruction_loss: -582.6820 - accuracy: 0.4510 - val_mse_loss: 174.3060 - val_total_loss: 6.5667 - val_loss1: 2.1440 - val_loss2: 4.4228 - val_reconstruction_loss: -499.7291 - val_accuracy: 0.4717\n",
      "Epoch 204/300\n",
      "59/59 [==============================] - 2s 41ms/step - mse_loss: 82.9449 - total_loss: 5.4512 - loss1: 1.0132 - loss2: 4.4380 - reconstruction_loss: -592.8245 - accuracy: 0.4541 - val_mse_loss: 188.2150 - val_total_loss: 6.8931 - val_loss1: 2.5797 - val_loss2: 4.3135 - val_reconstruction_loss: -498.1927 - val_accuracy: 0.4920\n",
      "Epoch 205/300\n",
      "59/59 [==============================] - 3s 47ms/step - mse_loss: 86.7147 - total_loss: 5.4966 - loss1: 1.0177 - loss2: 4.4789 - reconstruction_loss: -585.7213 - accuracy: 0.4524 - val_mse_loss: 183.6958 - val_total_loss: 6.6409 - val_loss1: 2.2083 - val_loss2: 4.4326 - val_reconstruction_loss: -498.8760 - val_accuracy: 0.4899\n",
      "Epoch 206/300\n",
      "59/59 [==============================] - 2s 42ms/step - mse_loss: 97.1185 - total_loss: 5.6240 - loss1: 1.0074 - loss2: 4.6166 - reconstruction_loss: -577.7048 - accuracy: 0.4498 - val_mse_loss: 209.1197 - val_total_loss: 7.5125 - val_loss1: 3.3660 - val_loss2: 4.1465 - val_reconstruction_loss: -498.4248 - val_accuracy: 0.5019\n",
      "Epoch 207/300\n",
      "59/59 [==============================] - 2s 38ms/step - mse_loss: 99.2756 - total_loss: 5.6543 - loss1: 1.0306 - loss2: 4.6237 - reconstruction_loss: -580.8474 - accuracy: 0.4497 - val_mse_loss: 206.0889 - val_total_loss: 6.9930 - val_loss1: 2.5779 - val_loss2: 4.4150 - val_reconstruction_loss: -499.1426 - val_accuracy: 0.4737\n",
      "Epoch 208/300\n",
      "59/59 [==============================] - 3s 45ms/step - mse_loss: 88.9160 - total_loss: 5.5507 - loss1: 1.0217 - loss2: 4.5290 - reconstruction_loss: -594.5804 - accuracy: 0.4498 - val_mse_loss: 190.7401 - val_total_loss: 6.6396 - val_loss1: 2.1353 - val_loss2: 4.5043 - val_reconstruction_loss: -499.0567 - val_accuracy: 0.4830\n",
      "Epoch 209/300\n",
      "59/59 [==============================] - 2s 36ms/step - mse_loss: 94.7604 - total_loss: 5.6223 - loss1: 1.0281 - loss2: 4.5942 - reconstruction_loss: -594.8098 - accuracy: 0.4502 - val_mse_loss: 201.0312 - val_total_loss: 7.0512 - val_loss1: 2.7326 - val_loss2: 4.3186 - val_reconstruction_loss: -497.7332 - val_accuracy: 0.4611\n",
      "Epoch 210/300\n",
      "59/59 [==============================] - 2s 36ms/step - mse_loss: 90.2122 - total_loss: 5.5431 - loss1: 1.0141 - loss2: 4.5290 - reconstruction_loss: -590.5268 - accuracy: 0.4492 - val_mse_loss: 183.0722 - val_total_loss: 7.1366 - val_loss1: 3.0204 - val_loss2: 4.1162 - val_reconstruction_loss: -499.1585 - val_accuracy: 0.4666\n",
      "Epoch 211/300\n",
      "59/59 [==============================] - 2s 38ms/step - mse_loss: 82.0448 - total_loss: 5.4443 - loss1: 1.0117 - loss2: 4.4326 - reconstruction_loss: -579.8081 - accuracy: 0.4529 - val_mse_loss: 196.2858 - val_total_loss: 7.2803 - val_loss1: 3.1153 - val_loss2: 4.1650 - val_reconstruction_loss: -499.4219 - val_accuracy: 0.4660\n",
      "Epoch 212/300\n",
      "59/59 [==============================] - 2s 38ms/step - mse_loss: 83.1392 - total_loss: 5.4521 - loss1: 1.0112 - loss2: 4.4409 - reconstruction_loss: -592.1661 - accuracy: 0.4524 - val_mse_loss: 191.3731 - val_total_loss: 7.3926 - val_loss1: 3.3175 - val_loss2: 4.0751 - val_reconstruction_loss: -499.3600 - val_accuracy: 0.4915\n",
      "Epoch 213/300\n",
      "59/59 [==============================] - 2s 38ms/step - mse_loss: 78.4705 - total_loss: 5.3968 - loss1: 1.0096 - loss2: 4.3872 - reconstruction_loss: -589.7980 - accuracy: 0.4555 - val_mse_loss: 188.8847 - val_total_loss: 6.6112 - val_loss1: 2.0934 - val_loss2: 4.5178 - val_reconstruction_loss: -499.7178 - val_accuracy: 0.4777\n",
      "Epoch 214/300\n",
      "59/59 [==============================] - 2s 37ms/step - mse_loss: 77.3514 - total_loss: 5.3984 - loss1: 1.0137 - loss2: 4.3847 - reconstruction_loss: -588.1006 - accuracy: 0.4555 - val_mse_loss: 167.2784 - val_total_loss: 6.4985 - val_loss1: 2.0985 - val_loss2: 4.4000 - val_reconstruction_loss: -498.9280 - val_accuracy: 0.4882\n",
      "Epoch 215/300\n",
      "59/59 [==============================] - 2s 38ms/step - mse_loss: 75.2285 - total_loss: 5.3560 - loss1: 1.0248 - loss2: 4.3312 - reconstruction_loss: -594.5027 - accuracy: 0.4571 - val_mse_loss: 191.0105 - val_total_loss: 6.6880 - val_loss1: 2.2131 - val_loss2: 4.4749 - val_reconstruction_loss: -498.9213 - val_accuracy: 0.4777\n",
      "Epoch 216/300\n",
      "59/59 [==============================] - 2s 36ms/step - mse_loss: 81.2798 - total_loss: 5.4452 - loss1: 1.0099 - loss2: 4.4353 - reconstruction_loss: -569.3379 - accuracy: 0.4530 - val_mse_loss: 181.4690 - val_total_loss: 6.6449 - val_loss1: 2.2264 - val_loss2: 4.4184 - val_reconstruction_loss: -499.5515 - val_accuracy: 0.4841\n",
      "Epoch 217/300\n",
      "59/59 [==============================] - 2s 38ms/step - mse_loss: 78.7926 - total_loss: 5.4004 - loss1: 1.0118 - loss2: 4.3886 - reconstruction_loss: -584.1472 - accuracy: 0.4535 - val_mse_loss: 174.0087 - val_total_loss: 6.3478 - val_loss1: 1.6998 - val_loss2: 4.6480 - val_reconstruction_loss: -499.1747 - val_accuracy: 0.4682\n",
      "Epoch 218/300\n",
      "59/59 [==============================] - 2s 38ms/step - mse_loss: 75.2234 - total_loss: 5.3757 - loss1: 1.0097 - loss2: 4.3660 - reconstruction_loss: -582.0720 - accuracy: 0.4549 - val_mse_loss: 178.6715 - val_total_loss: 7.2794 - val_loss1: 3.2684 - val_loss2: 4.0110 - val_reconstruction_loss: -499.3157 - val_accuracy: 0.4800\n",
      "Epoch 219/300\n",
      "59/59 [==============================] - 2s 36ms/step - mse_loss: 77.7636 - total_loss: 5.3836 - loss1: 1.0181 - loss2: 4.3655 - reconstruction_loss: -587.1382 - accuracy: 0.4554 - val_mse_loss: 196.9215 - val_total_loss: 6.9777 - val_loss1: 2.6503 - val_loss2: 4.3273 - val_reconstruction_loss: -499.3586 - val_accuracy: 0.4812\n",
      "Epoch 220/300\n",
      "59/59 [==============================] - 2s 39ms/step - mse_loss: 75.2289 - total_loss: 5.3483 - loss1: 1.0143 - loss2: 4.3341 - reconstruction_loss: -584.0357 - accuracy: 0.4547 - val_mse_loss: 185.3184 - val_total_loss: 7.0378 - val_loss1: 2.8458 - val_loss2: 4.1921 - val_reconstruction_loss: -499.2413 - val_accuracy: 0.4883\n",
      "Epoch 221/300\n",
      "59/59 [==============================] - 2s 35ms/step - mse_loss: 78.0535 - total_loss: 5.3986 - loss1: 1.0196 - loss2: 4.3791 - reconstruction_loss: -600.7175 - accuracy: 0.4525 - val_mse_loss: 191.9740 - val_total_loss: 6.5703 - val_loss1: 1.9702 - val_loss2: 4.6000 - val_reconstruction_loss: -497.7853 - val_accuracy: 0.4854\n",
      "Epoch 222/300\n",
      "59/59 [==============================] - 2s 35ms/step - mse_loss: 79.8286 - total_loss: 5.4424 - loss1: 1.0125 - loss2: 4.4299 - reconstruction_loss: -586.4881 - accuracy: 0.4534 - val_mse_loss: 196.9625 - val_total_loss: 7.9000 - val_loss1: 3.9926 - val_loss2: 3.9074 - val_reconstruction_loss: -498.5870 - val_accuracy: 0.4769\n",
      "Epoch 223/300\n",
      "59/59 [==============================] - 2s 36ms/step - mse_loss: 74.9105 - total_loss: 5.3509 - loss1: 1.0190 - loss2: 4.3319 - reconstruction_loss: -593.2563 - accuracy: 0.4536 - val_mse_loss: 203.6501 - val_total_loss: 7.8147 - val_loss1: 3.8322 - val_loss2: 3.9825 - val_reconstruction_loss: -498.6034 - val_accuracy: 0.4814\n",
      "Epoch 224/300\n",
      "59/59 [==============================] - 2s 37ms/step - mse_loss: 72.0939 - total_loss: 5.3101 - loss1: 1.0098 - loss2: 4.3003 - reconstruction_loss: -583.6611 - accuracy: 0.4547 - val_mse_loss: 196.9633 - val_total_loss: 7.4802 - val_loss1: 3.4017 - val_loss2: 4.0786 - val_reconstruction_loss: -498.6425 - val_accuracy: 0.4863\n",
      "Epoch 225/300\n",
      "59/59 [==============================] - 2s 37ms/step - mse_loss: 70.8589 - total_loss: 5.3001 - loss1: 1.0123 - loss2: 4.2878 - reconstruction_loss: -592.7633 - accuracy: 0.4561 - val_mse_loss: 202.0099 - val_total_loss: 6.5826 - val_loss1: 1.8818 - val_loss2: 4.7008 - val_reconstruction_loss: -499.3731 - val_accuracy: 0.4745\n",
      "Epoch 226/300\n",
      "59/59 [==============================] - 2s 35ms/step - mse_loss: 92.5495 - total_loss: 5.6049 - loss1: 1.0531 - loss2: 4.5518 - reconstruction_loss: -586.9858 - accuracy: 0.4499 - val_mse_loss: 213.7586 - val_total_loss: 6.5014 - val_loss1: 1.5701 - val_loss2: 4.9313 - val_reconstruction_loss: -499.4596 - val_accuracy: 0.4507\n",
      "Epoch 227/300\n",
      "59/59 [==============================] - 2s 35ms/step - mse_loss: 112.7809 - total_loss: 5.7585 - loss1: 1.0171 - loss2: 4.7414 - reconstruction_loss: -589.1709 - accuracy: 0.4446 - val_mse_loss: 193.6167 - val_total_loss: 6.6948 - val_loss1: 2.2043 - val_loss2: 4.4904 - val_reconstruction_loss: -499.0102 - val_accuracy: 0.4716\n",
      "Epoch 228/300\n",
      "59/59 [==============================] - 2s 35ms/step - mse_loss: 74.0254 - total_loss: 5.3611 - loss1: 1.0083 - loss2: 4.3528 - reconstruction_loss: -573.1226 - accuracy: 0.4524 - val_mse_loss: 182.3041 - val_total_loss: 6.9854 - val_loss1: 2.7938 - val_loss2: 4.1917 - val_reconstruction_loss: -498.7644 - val_accuracy: 0.4808\n",
      "Epoch 229/300\n",
      "59/59 [==============================] - 2s 36ms/step - mse_loss: 71.5149 - total_loss: 5.3084 - loss1: 1.0097 - loss2: 4.2987 - reconstruction_loss: -581.8055 - accuracy: 0.4559 - val_mse_loss: 179.4924 - val_total_loss: 7.8439 - val_loss1: 4.0222 - val_loss2: 3.8217 - val_reconstruction_loss: -499.4500 - val_accuracy: 0.4807\n",
      "Epoch 230/300\n",
      "59/59 [==============================] - 2s 34ms/step - mse_loss: 72.9939 - total_loss: 5.3404 - loss1: 1.0218 - loss2: 4.3187 - reconstruction_loss: -589.3971 - accuracy: 0.4544 - val_mse_loss: 185.3775 - val_total_loss: 7.8173 - val_loss1: 3.9546 - val_loss2: 3.8627 - val_reconstruction_loss: -499.1233 - val_accuracy: 0.4760\n",
      "Epoch 231/300\n",
      "59/59 [==============================] - 2s 37ms/step - mse_loss: 67.8392 - total_loss: 5.2602 - loss1: 1.0188 - loss2: 4.2414 - reconstruction_loss: -584.3403 - accuracy: 0.4566 - val_mse_loss: 174.3835 - val_total_loss: 7.2742 - val_loss1: 3.2928 - val_loss2: 3.9814 - val_reconstruction_loss: -498.6791 - val_accuracy: 0.4875\n",
      "Epoch 232/300\n",
      "59/59 [==============================] - 2s 37ms/step - mse_loss: 64.3268 - total_loss: 5.2228 - loss1: 1.0242 - loss2: 4.1985 - reconstruction_loss: -598.5751 - accuracy: 0.4586 - val_mse_loss: 197.7403 - val_total_loss: 7.6093 - val_loss1: 3.5741 - val_loss2: 4.0352 - val_reconstruction_loss: -498.3122 - val_accuracy: 0.4816\n",
      "Epoch 233/300\n",
      "59/59 [==============================] - 2s 36ms/step - mse_loss: 63.0667 - total_loss: 5.1799 - loss1: 1.0029 - loss2: 4.1770 - reconstruction_loss: -585.6628 - accuracy: 0.4580 - val_mse_loss: 187.0186 - val_total_loss: 8.1200 - val_loss1: 4.3415 - val_loss2: 3.7785 - val_reconstruction_loss: -499.8373 - val_accuracy: 0.4786\n",
      "Epoch 234/300\n",
      "59/59 [==============================] - 2s 35ms/step - mse_loss: 63.1464 - total_loss: 5.1838 - loss1: 1.0118 - loss2: 4.1720 - reconstruction_loss: -591.8391 - accuracy: 0.4571 - val_mse_loss: 192.4984 - val_total_loss: 7.2465 - val_loss1: 3.0942 - val_loss2: 4.1523 - val_reconstruction_loss: -499.1897 - val_accuracy: 0.4901\n",
      "Epoch 235/300\n",
      "59/59 [==============================] - 4s 60ms/step - mse_loss: 71.5721 - total_loss: 5.3089 - loss1: 1.0373 - loss2: 4.2716 - reconstruction_loss: -593.3446 - accuracy: 0.4566 - val_mse_loss: 195.3331 - val_total_loss: 6.9462 - val_loss1: 2.6159 - val_loss2: 4.3303 - val_reconstruction_loss: -499.8281 - val_accuracy: 0.4750\n",
      "Epoch 236/300\n",
      "59/59 [==============================] - 3s 47ms/step - mse_loss: 65.9152 - total_loss: 5.2417 - loss1: 0.9996 - loss2: 4.2421 - reconstruction_loss: -587.6847 - accuracy: 0.4564 - val_mse_loss: 201.5240 - val_total_loss: 7.8665 - val_loss1: 3.9140 - val_loss2: 3.9525 - val_reconstruction_loss: -499.2800 - val_accuracy: 0.4786\n",
      "Epoch 237/300\n",
      "59/59 [==============================] - 2s 38ms/step - mse_loss: 66.7631 - total_loss: 5.2467 - loss1: 1.0292 - loss2: 4.2175 - reconstruction_loss: -596.5389 - accuracy: 0.4567 - val_mse_loss: 202.2213 - val_total_loss: 7.3135 - val_loss1: 3.1293 - val_loss2: 4.1842 - val_reconstruction_loss: -496.4720 - val_accuracy: 0.4934\n",
      "Epoch 238/300\n",
      "59/59 [==============================] - 2s 39ms/step - mse_loss: 65.0135 - total_loss: 5.2188 - loss1: 1.0143 - loss2: 4.2045 - reconstruction_loss: -580.0368 - accuracy: 0.4563 - val_mse_loss: 194.4956 - val_total_loss: 7.3068 - val_loss1: 3.1741 - val_loss2: 4.1327 - val_reconstruction_loss: -499.4750 - val_accuracy: 0.4700\n",
      "Epoch 239/300\n",
      "59/59 [==============================] - 3s 49ms/step - mse_loss: 63.5357 - total_loss: 5.2010 - loss1: 1.0055 - loss2: 4.1956 - reconstruction_loss: -583.7232 - accuracy: 0.4559 - val_mse_loss: 187.6550 - val_total_loss: 7.7044 - val_loss1: 3.7895 - val_loss2: 3.9149 - val_reconstruction_loss: -498.3216 - val_accuracy: 0.4875\n",
      "Epoch 240/300\n",
      "59/59 [==============================] - 3s 53ms/step - mse_loss: 59.4281 - total_loss: 5.1088 - loss1: 1.0154 - loss2: 4.0934 - reconstruction_loss: -580.4086 - accuracy: 0.4600 - val_mse_loss: 194.5947 - val_total_loss: 7.1876 - val_loss1: 3.0079 - val_loss2: 4.1797 - val_reconstruction_loss: -499.2999 - val_accuracy: 0.4810\n",
      "Epoch 241/300\n",
      "59/59 [==============================] - 2s 33ms/step - mse_loss: 60.7197 - total_loss: 5.1362 - loss1: 1.0148 - loss2: 4.1213 - reconstruction_loss: -601.4979 - accuracy: 0.4600 - val_mse_loss: 209.2031 - val_total_loss: 7.5566 - val_loss1: 3.4303 - val_loss2: 4.1262 - val_reconstruction_loss: -499.4940 - val_accuracy: 0.4874\n",
      "Epoch 242/300\n",
      "59/59 [==============================] - 2s 31ms/step - mse_loss: 61.9432 - total_loss: 5.1763 - loss1: 1.0184 - loss2: 4.1579 - reconstruction_loss: -591.5435 - accuracy: 0.4579 - val_mse_loss: 184.7624 - val_total_loss: 7.2945 - val_loss1: 3.2456 - val_loss2: 4.0488 - val_reconstruction_loss: -497.1193 - val_accuracy: 0.4975\n",
      "Epoch 243/300\n",
      "59/59 [==============================] - 2s 36ms/step - mse_loss: 63.7952 - total_loss: 5.1997 - loss1: 1.0050 - loss2: 4.1946 - reconstruction_loss: -587.9882 - accuracy: 0.4588 - val_mse_loss: 184.6516 - val_total_loss: 8.0031 - val_loss1: 4.2018 - val_loss2: 3.8013 - val_reconstruction_loss: -498.4167 - val_accuracy: 0.4857\n",
      "Epoch 244/300\n",
      "59/59 [==============================] - 2s 37ms/step - mse_loss: 63.1935 - total_loss: 5.1913 - loss1: 1.0258 - loss2: 4.1655 - reconstruction_loss: -591.5390 - accuracy: 0.4580 - val_mse_loss: 191.6149 - val_total_loss: 8.0362 - val_loss1: 4.2063 - val_loss2: 3.8299 - val_reconstruction_loss: -498.9396 - val_accuracy: 0.4878\n",
      "Epoch 245/300\n",
      "59/59 [==============================] - 2s 34ms/step - mse_loss: 59.8041 - total_loss: 5.1364 - loss1: 1.0201 - loss2: 4.1163 - reconstruction_loss: -588.0544 - accuracy: 0.4585 - val_mse_loss: 189.2611 - val_total_loss: 7.8468 - val_loss1: 3.9759 - val_loss2: 3.8709 - val_reconstruction_loss: -498.7890 - val_accuracy: 0.4816\n",
      "Epoch 246/300\n",
      "59/59 [==============================] - 2s 32ms/step - mse_loss: 55.6946 - total_loss: 5.0540 - loss1: 1.0079 - loss2: 4.0461 - reconstruction_loss: -579.7196 - accuracy: 0.4601 - val_mse_loss: 185.7790 - val_total_loss: 7.2866 - val_loss1: 3.2202 - val_loss2: 4.0663 - val_reconstruction_loss: -500.3443 - val_accuracy: 0.4799\n",
      "Epoch 247/300\n",
      "59/59 [==============================] - 2s 33ms/step - mse_loss: 52.7727 - total_loss: 5.0026 - loss1: 1.0167 - loss2: 3.9859 - reconstruction_loss: -582.9236 - accuracy: 0.4618 - val_mse_loss: 189.1938 - val_total_loss: 6.7725 - val_loss1: 2.3949 - val_loss2: 4.3777 - val_reconstruction_loss: -498.4169 - val_accuracy: 0.4886\n",
      "Epoch 248/300\n",
      "59/59 [==============================] - 2s 39ms/step - mse_loss: 53.2286 - total_loss: 5.0092 - loss1: 1.0233 - loss2: 3.9859 - reconstruction_loss: -584.5650 - accuracy: 0.4603 - val_mse_loss: 193.2372 - val_total_loss: 7.7029 - val_loss1: 3.7484 - val_loss2: 3.9544 - val_reconstruction_loss: -496.4390 - val_accuracy: 0.4976\n",
      "Epoch 249/300\n",
      "59/59 [==============================] - 3s 46ms/step - mse_loss: 57.2216 - total_loss: 5.0872 - loss1: 1.0074 - loss2: 4.0799 - reconstruction_loss: -584.1857 - accuracy: 0.4602 - val_mse_loss: 191.7874 - val_total_loss: 7.2956 - val_loss1: 3.1900 - val_loss2: 4.1056 - val_reconstruction_loss: -498.6941 - val_accuracy: 0.4613\n",
      "Epoch 250/300\n",
      "59/59 [==============================] - 2s 41ms/step - mse_loss: 53.8870 - total_loss: 5.0553 - loss1: 1.0224 - loss2: 4.0329 - reconstruction_loss: -582.7841 - accuracy: 0.4603 - val_mse_loss: 211.2868 - val_total_loss: 8.0219 - val_loss1: 4.0273 - val_loss2: 3.9946 - val_reconstruction_loss: -498.6498 - val_accuracy: 0.4818\n",
      "Epoch 251/300\n",
      "59/59 [==============================] - 2s 37ms/step - mse_loss: 56.4971 - total_loss: 5.0765 - loss1: 1.0069 - loss2: 4.0696 - reconstruction_loss: -586.6391 - accuracy: 0.4585 - val_mse_loss: 193.6325 - val_total_loss: 6.8557 - val_loss1: 2.4825 - val_loss2: 4.3731 - val_reconstruction_loss: -498.7596 - val_accuracy: 0.4881\n",
      "Epoch 252/300\n",
      "59/59 [==============================] - 3s 43ms/step - mse_loss: 52.5924 - total_loss: 5.0121 - loss1: 1.0296 - loss2: 3.9825 - reconstruction_loss: -585.8064 - accuracy: 0.4612 - val_mse_loss: 187.7315 - val_total_loss: 8.1573 - val_loss1: 4.3797 - val_loss2: 3.7776 - val_reconstruction_loss: -498.9902 - val_accuracy: 0.4819\n",
      "Epoch 253/300\n",
      "59/59 [==============================] - 3s 49ms/step - mse_loss: 51.4668 - total_loss: 4.9659 - loss1: 1.0012 - loss2: 3.9648 - reconstruction_loss: -585.6050 - accuracy: 0.4614 - val_mse_loss: 190.5901 - val_total_loss: 8.3694 - val_loss1: 4.6355 - val_loss2: 3.7339 - val_reconstruction_loss: -498.9909 - val_accuracy: 0.4924\n",
      "Epoch 254/300\n",
      "59/59 [==============================] - 3s 53ms/step - mse_loss: 50.9161 - total_loss: 4.9598 - loss1: 1.0098 - loss2: 3.9499 - reconstruction_loss: -579.1687 - accuracy: 0.4613 - val_mse_loss: 188.4901 - val_total_loss: 8.6049 - val_loss1: 4.9512 - val_loss2: 3.6538 - val_reconstruction_loss: -497.3298 - val_accuracy: 0.4952\n",
      "Epoch 255/300\n",
      "59/59 [==============================] - 3s 51ms/step - mse_loss: 50.9334 - total_loss: 4.9608 - loss1: 1.0077 - loss2: 3.9530 - reconstruction_loss: -591.2561 - accuracy: 0.4612 - val_mse_loss: 212.3241 - val_total_loss: 9.8166 - val_loss1: 6.2690 - val_loss2: 3.5477 - val_reconstruction_loss: -497.1215 - val_accuracy: 0.4988\n",
      "Epoch 256/300\n",
      "59/59 [==============================] - 3s 48ms/step - mse_loss: 51.5213 - total_loss: 4.9837 - loss1: 1.0228 - loss2: 3.9609 - reconstruction_loss: -597.0221 - accuracy: 0.4610 - val_mse_loss: 191.1808 - val_total_loss: 7.8050 - val_loss1: 3.8976 - val_loss2: 3.9075 - val_reconstruction_loss: -499.5378 - val_accuracy: 0.4739\n",
      "Epoch 257/300\n",
      "59/59 [==============================] - 3s 45ms/step - mse_loss: 63.1128 - total_loss: 5.1896 - loss1: 1.0339 - loss2: 4.1557 - reconstruction_loss: -580.2023 - accuracy: 0.4599 - val_mse_loss: 208.2959 - val_total_loss: 7.5003 - val_loss1: 3.3532 - val_loss2: 4.1471 - val_reconstruction_loss: -495.5720 - val_accuracy: 0.5022\n",
      "Epoch 258/300\n",
      "59/59 [==============================] - 2s 39ms/step - mse_loss: 58.9032 - total_loss: 5.1140 - loss1: 1.0141 - loss2: 4.0999 - reconstruction_loss: -589.1757 - accuracy: 0.4588 - val_mse_loss: 252.4258 - val_total_loss: 9.3241 - val_loss1: 5.4561 - val_loss2: 3.8680 - val_reconstruction_loss: -494.6852 - val_accuracy: 0.5016\n",
      "Epoch 259/300\n",
      "59/59 [==============================] - 2s 40ms/step - mse_loss: 57.0511 - total_loss: 5.0981 - loss1: 1.0230 - loss2: 4.0751 - reconstruction_loss: -576.6131 - accuracy: 0.4579 - val_mse_loss: 204.0397 - val_total_loss: 7.1303 - val_loss1: 2.8384 - val_loss2: 4.2919 - val_reconstruction_loss: -499.0986 - val_accuracy: 0.4943\n",
      "Epoch 260/300\n",
      "59/59 [==============================] - 3s 47ms/step - mse_loss: 52.1164 - total_loss: 4.9915 - loss1: 1.0110 - loss2: 3.9805 - reconstruction_loss: -590.3792 - accuracy: 0.4608 - val_mse_loss: 192.0999 - val_total_loss: 9.0091 - val_loss1: 5.4226 - val_loss2: 3.5864 - val_reconstruction_loss: -499.4363 - val_accuracy: 0.4798\n",
      "Epoch 261/300\n",
      "59/59 [==============================] - 3s 45ms/step - mse_loss: 48.1726 - total_loss: 4.9021 - loss1: 1.0113 - loss2: 3.8908 - reconstruction_loss: -582.1558 - accuracy: 0.4623 - val_mse_loss: 177.1050 - val_total_loss: 7.6055 - val_loss1: 3.7276 - val_loss2: 3.8778 - val_reconstruction_loss: -499.4139 - val_accuracy: 0.4818\n",
      "Epoch 262/300\n",
      "59/59 [==============================] - 2s 38ms/step - mse_loss: 52.0902 - total_loss: 4.9910 - loss1: 1.0124 - loss2: 3.9786 - reconstruction_loss: -582.8421 - accuracy: 0.4619 - val_mse_loss: 205.4419 - val_total_loss: 7.9183 - val_loss1: 3.9313 - val_loss2: 3.9870 - val_reconstruction_loss: -499.7890 - val_accuracy: 0.4766\n",
      "Epoch 263/300\n",
      "59/59 [==============================] - 2s 39ms/step - mse_loss: 53.5563 - total_loss: 5.0279 - loss1: 1.0198 - loss2: 4.0081 - reconstruction_loss: -587.8254 - accuracy: 0.4604 - val_mse_loss: 195.2267 - val_total_loss: 8.4436 - val_loss1: 4.7099 - val_loss2: 3.7337 - val_reconstruction_loss: -499.5946 - val_accuracy: 0.4766\n",
      "Epoch 264/300\n",
      "59/59 [==============================] - 3s 48ms/step - mse_loss: 52.4445 - total_loss: 4.9990 - loss1: 1.0108 - loss2: 3.9882 - reconstruction_loss: -590.0877 - accuracy: 0.4600 - val_mse_loss: 195.9557 - val_total_loss: 10.2073 - val_loss1: 6.8387 - val_loss2: 3.3687 - val_reconstruction_loss: -499.3953 - val_accuracy: 0.4851\n",
      "Epoch 265/300\n",
      "59/59 [==============================] - 3s 44ms/step - mse_loss: 50.1774 - total_loss: 4.9802 - loss1: 1.0375 - loss2: 3.9427 - reconstruction_loss: -584.0374 - accuracy: 0.4605 - val_mse_loss: 181.0521 - val_total_loss: 7.8862 - val_loss1: 4.0892 - val_loss2: 3.7970 - val_reconstruction_loss: -499.4726 - val_accuracy: 0.4863\n",
      "Epoch 266/300\n",
      "59/59 [==============================] - 2s 38ms/step - mse_loss: 48.5599 - total_loss: 4.9194 - loss1: 1.0087 - loss2: 3.9107 - reconstruction_loss: -585.4961 - accuracy: 0.4614 - val_mse_loss: 186.3156 - val_total_loss: 7.2200 - val_loss1: 3.1173 - val_loss2: 4.1027 - val_reconstruction_loss: -499.3536 - val_accuracy: 0.4761\n",
      "Epoch 267/300\n",
      "59/59 [==============================] - 2s 40ms/step - mse_loss: 45.1460 - total_loss: 4.8443 - loss1: 1.0141 - loss2: 3.8302 - reconstruction_loss: -590.4837 - accuracy: 0.4630 - val_mse_loss: 181.5480 - val_total_loss: 8.1540 - val_loss1: 4.4278 - val_loss2: 3.7262 - val_reconstruction_loss: -499.1774 - val_accuracy: 0.4861\n",
      "Epoch 268/300\n",
      "59/59 [==============================] - 3s 46ms/step - mse_loss: 42.2935 - total_loss: 4.7710 - loss1: 1.0073 - loss2: 3.7637 - reconstruction_loss: -577.1435 - accuracy: 0.4629 - val_mse_loss: 187.1016 - val_total_loss: 7.8293 - val_loss1: 3.9665 - val_loss2: 3.8628 - val_reconstruction_loss: -498.9750 - val_accuracy: 0.4864\n",
      "Epoch 269/300\n",
      "59/59 [==============================] - 3s 50ms/step - mse_loss: 43.6009 - total_loss: 4.8102 - loss1: 1.0218 - loss2: 3.7884 - reconstruction_loss: -592.1808 - accuracy: 0.4635 - val_mse_loss: 196.3511 - val_total_loss: 8.9521 - val_loss1: 5.3390 - val_loss2: 3.6130 - val_reconstruction_loss: -498.6950 - val_accuracy: 0.4844\n",
      "Epoch 270/300\n",
      "59/59 [==============================] - 2s 39ms/step - mse_loss: 45.8774 - total_loss: 4.8639 - loss1: 1.0053 - loss2: 3.8586 - reconstruction_loss: -598.6109 - accuracy: 0.4611 - val_mse_loss: 187.9152 - val_total_loss: 8.9411 - val_loss1: 5.3734 - val_loss2: 3.5677 - val_reconstruction_loss: -498.1462 - val_accuracy: 0.4866\n",
      "Epoch 271/300\n",
      "59/59 [==============================] - 2s 41ms/step - mse_loss: 42.0533 - total_loss: 4.7657 - loss1: 1.0159 - loss2: 3.7497 - reconstruction_loss: -589.7986 - accuracy: 0.4630 - val_mse_loss: 179.0999 - val_total_loss: 8.2208 - val_loss1: 4.5372 - val_loss2: 3.6836 - val_reconstruction_loss: -498.9613 - val_accuracy: 0.4910\n",
      "Epoch 272/300\n",
      "59/59 [==============================] - 3s 48ms/step - mse_loss: 41.8645 - total_loss: 4.7631 - loss1: 1.0102 - loss2: 3.7529 - reconstruction_loss: -584.5947 - accuracy: 0.4641 - val_mse_loss: 180.9800 - val_total_loss: 7.2694 - val_loss1: 3.2365 - val_loss2: 4.0330 - val_reconstruction_loss: -499.3324 - val_accuracy: 0.4977\n",
      "Epoch 273/300\n",
      "59/59 [==============================] - 3s 45ms/step - mse_loss: 48.7117 - total_loss: 4.9130 - loss1: 1.0099 - loss2: 3.9031 - reconstruction_loss: -584.5780 - accuracy: 0.4607 - val_mse_loss: 206.3520 - val_total_loss: 8.6196 - val_loss1: 4.8616 - val_loss2: 3.7580 - val_reconstruction_loss: -499.8941 - val_accuracy: 0.4736\n",
      "Epoch 274/300\n",
      "59/59 [==============================] - 2s 38ms/step - mse_loss: 48.8656 - total_loss: 4.9303 - loss1: 1.0310 - loss2: 3.8992 - reconstruction_loss: -578.6002 - accuracy: 0.4620 - val_mse_loss: 186.6093 - val_total_loss: 6.8463 - val_loss1: 2.5269 - val_loss2: 4.3195 - val_reconstruction_loss: -499.6700 - val_accuracy: 0.4818\n",
      "Epoch 275/300\n",
      "59/59 [==============================] - 2s 41ms/step - mse_loss: 43.4785 - total_loss: 4.8019 - loss1: 0.9966 - loss2: 3.8053 - reconstruction_loss: -574.5342 - accuracy: 0.4629 - val_mse_loss: 179.6540 - val_total_loss: 8.6142 - val_loss1: 5.0278 - val_loss2: 3.5864 - val_reconstruction_loss: -499.0641 - val_accuracy: 0.4967\n",
      "Epoch 276/300\n",
      "59/59 [==============================] - 3s 48ms/step - mse_loss: 38.9299 - total_loss: 4.6766 - loss1: 1.0075 - loss2: 3.6691 - reconstruction_loss: -590.3107 - accuracy: 0.4643 - val_mse_loss: 186.0587 - val_total_loss: 8.6819 - val_loss1: 5.0691 - val_loss2: 3.6128 - val_reconstruction_loss: -499.4839 - val_accuracy: 0.4771\n",
      "Epoch 277/300\n",
      "59/59 [==============================] - 3s 43ms/step - mse_loss: 42.5451 - total_loss: 4.7872 - loss1: 1.0301 - loss2: 3.7571 - reconstruction_loss: -585.2851 - accuracy: 0.4641 - val_mse_loss: 181.6639 - val_total_loss: 7.3809 - val_loss1: 3.3827 - val_loss2: 3.9983 - val_reconstruction_loss: -499.4259 - val_accuracy: 0.4720\n",
      "Epoch 278/300\n",
      "59/59 [==============================] - 2s 38ms/step - mse_loss: 48.5262 - total_loss: 4.9189 - loss1: 1.0054 - loss2: 3.9135 - reconstruction_loss: -587.1084 - accuracy: 0.4614 - val_mse_loss: 187.6597 - val_total_loss: 8.1755 - val_loss1: 4.4176 - val_loss2: 3.7580 - val_reconstruction_loss: -499.6170 - val_accuracy: 0.4668\n",
      "Epoch 279/300\n",
      "59/59 [==============================] - 2s 42ms/step - mse_loss: 38.8452 - total_loss: 4.6833 - loss1: 1.0048 - loss2: 3.6785 - reconstruction_loss: -587.6762 - accuracy: 0.4627 - val_mse_loss: 185.9623 - val_total_loss: 8.7569 - val_loss1: 5.1598 - val_loss2: 3.5971 - val_reconstruction_loss: -499.7603 - val_accuracy: 0.4821\n",
      "Epoch 280/300\n",
      "59/59 [==============================] - 3s 54ms/step - mse_loss: 43.9398 - total_loss: 4.8123 - loss1: 1.0142 - loss2: 3.7981 - reconstruction_loss: -588.4283 - accuracy: 0.4629 - val_mse_loss: 183.0064 - val_total_loss: 8.3561 - val_loss1: 4.6802 - val_loss2: 3.6759 - val_reconstruction_loss: -499.4982 - val_accuracy: 0.4887\n",
      "Epoch 281/300\n",
      "59/59 [==============================] - 3s 44ms/step - mse_loss: 41.4300 - total_loss: 4.7531 - loss1: 1.0101 - loss2: 3.7430 - reconstruction_loss: -587.8041 - accuracy: 0.4636 - val_mse_loss: 198.6530 - val_total_loss: 8.5260 - val_loss1: 4.7795 - val_loss2: 3.7464 - val_reconstruction_loss: -498.9488 - val_accuracy: 0.4727\n",
      "Epoch 282/300\n",
      "59/59 [==============================] - 2s 38ms/step - mse_loss: 43.8076 - total_loss: 4.8147 - loss1: 1.0242 - loss2: 3.7905 - reconstruction_loss: -584.0136 - accuracy: 0.4620 - val_mse_loss: 185.0425 - val_total_loss: 8.2555 - val_loss1: 4.5312 - val_loss2: 3.7242 - val_reconstruction_loss: -499.6611 - val_accuracy: 0.4769\n",
      "Epoch 283/300\n",
      "59/59 [==============================] - 3s 45ms/step - mse_loss: 41.0003 - total_loss: 4.7376 - loss1: 1.0113 - loss2: 3.7263 - reconstruction_loss: -584.1729 - accuracy: 0.4635 - val_mse_loss: 187.4642 - val_total_loss: 8.1474 - val_loss1: 4.3837 - val_loss2: 3.7636 - val_reconstruction_loss: -498.9479 - val_accuracy: 0.4799\n",
      "Epoch 284/300\n",
      "59/59 [==============================] - 3s 48ms/step - mse_loss: 44.6122 - total_loss: 4.8337 - loss1: 1.0111 - loss2: 3.8226 - reconstruction_loss: -591.1680 - accuracy: 0.4609 - val_mse_loss: 178.7332 - val_total_loss: 8.8747 - val_loss1: 5.3583 - val_loss2: 3.5164 - val_reconstruction_loss: -499.5573 - val_accuracy: 0.4798\n",
      "Epoch 285/300\n",
      "59/59 [==============================] - 2s 42ms/step - mse_loss: 38.0650 - total_loss: 4.6610 - loss1: 1.0084 - loss2: 3.6526 - reconstruction_loss: -590.1059 - accuracy: 0.4646 - val_mse_loss: 185.2792 - val_total_loss: 8.8009 - val_loss1: 5.2267 - val_loss2: 3.5742 - val_reconstruction_loss: -498.9111 - val_accuracy: 0.4891\n",
      "Epoch 286/300\n",
      "59/59 [==============================] - 2s 39ms/step - mse_loss: 35.3386 - total_loss: 4.5913 - loss1: 1.0086 - loss2: 3.5827 - reconstruction_loss: -584.4448 - accuracy: 0.4653 - val_mse_loss: 188.0219 - val_total_loss: 7.7397 - val_loss1: 3.8402 - val_loss2: 3.8995 - val_reconstruction_loss: -498.8221 - val_accuracy: 0.4856\n",
      "Epoch 287/300\n",
      "59/59 [==============================] - 3s 45ms/step - mse_loss: 36.6188 - total_loss: 4.6250 - loss1: 1.0209 - loss2: 3.6041 - reconstruction_loss: -585.6389 - accuracy: 0.4645 - val_mse_loss: 180.2790 - val_total_loss: 8.3039 - val_loss1: 4.6381 - val_loss2: 3.6658 - val_reconstruction_loss: -497.6241 - val_accuracy: 0.4937\n",
      "Epoch 288/300\n",
      "59/59 [==============================] - 3s 54ms/step - mse_loss: 40.5371 - total_loss: 4.7269 - loss1: 0.9960 - loss2: 3.7309 - reconstruction_loss: -584.6472 - accuracy: 0.4634 - val_mse_loss: 179.4410 - val_total_loss: 8.3226 - val_loss1: 4.6655 - val_loss2: 3.6571 - val_reconstruction_loss: -499.0161 - val_accuracy: 0.4879\n",
      "Epoch 289/300\n",
      "59/59 [==============================] - 2s 40ms/step - mse_loss: 36.2903 - total_loss: 4.6129 - loss1: 1.0180 - loss2: 3.5950 - reconstruction_loss: -577.5039 - accuracy: 0.4649 - val_mse_loss: 184.7598 - val_total_loss: 9.0918 - val_loss1: 5.5871 - val_loss2: 3.5048 - val_reconstruction_loss: -498.9676 - val_accuracy: 0.4888\n",
      "Epoch 290/300\n",
      "59/59 [==============================] - 2s 39ms/step - mse_loss: 35.2503 - total_loss: 4.5889 - loss1: 1.0197 - loss2: 3.5693 - reconstruction_loss: -577.2264 - accuracy: 0.4651 - val_mse_loss: 182.3468 - val_total_loss: 8.9090 - val_loss1: 5.3782 - val_loss2: 3.5308 - val_reconstruction_loss: -499.8584 - val_accuracy: 0.4816\n",
      "Epoch 291/300\n",
      "59/59 [==============================] - 3s 48ms/step - mse_loss: 43.3752 - total_loss: 4.8269 - loss1: 1.0090 - loss2: 3.8179 - reconstruction_loss: -591.7892 - accuracy: 0.4609 - val_mse_loss: 192.8984 - val_total_loss: 9.5087 - val_loss1: 6.0207 - val_loss2: 3.4880 - val_reconstruction_loss: -499.4961 - val_accuracy: 0.4717\n",
      "Epoch 292/300\n",
      "59/59 [==============================] - 3s 52ms/step - mse_loss: 42.6259 - total_loss: 4.7988 - loss1: 1.0194 - loss2: 3.7794 - reconstruction_loss: -584.1506 - accuracy: 0.4577 - val_mse_loss: 177.7924 - val_total_loss: 8.1458 - val_loss1: 4.4459 - val_loss2: 3.6998 - val_reconstruction_loss: -499.1765 - val_accuracy: 0.4895\n",
      "Epoch 293/300\n",
      "59/59 [==============================] - 2s 38ms/step - mse_loss: 36.4218 - total_loss: 4.6309 - loss1: 1.0147 - loss2: 3.6162 - reconstruction_loss: -592.0722 - accuracy: 0.4627 - val_mse_loss: 180.8747 - val_total_loss: 9.5067 - val_loss1: 6.1081 - val_loss2: 3.3987 - val_reconstruction_loss: -499.9864 - val_accuracy: 0.4836\n",
      "Epoch 294/300\n",
      "59/59 [==============================] - 2s 39ms/step - mse_loss: 36.8692 - total_loss: 4.6303 - loss1: 1.0100 - loss2: 3.6203 - reconstruction_loss: -591.1427 - accuracy: 0.4647 - val_mse_loss: 188.0836 - val_total_loss: 8.2444 - val_loss1: 4.4980 - val_loss2: 3.7464 - val_reconstruction_loss: -498.1594 - val_accuracy: 0.4910\n",
      "Epoch 295/300\n",
      "59/59 [==============================] - 3s 48ms/step - mse_loss: 35.9028 - total_loss: 4.5995 - loss1: 1.0066 - loss2: 3.5930 - reconstruction_loss: -582.8601 - accuracy: 0.4644 - val_mse_loss: 178.2347 - val_total_loss: 8.5113 - val_loss1: 4.8949 - val_loss2: 3.6164 - val_reconstruction_loss: -499.0638 - val_accuracy: 0.4919\n",
      "Epoch 296/300\n",
      "59/59 [==============================] - 3s 48ms/step - mse_loss: 39.6800 - total_loss: 4.7065 - loss1: 1.0181 - loss2: 3.6884 - reconstruction_loss: -594.7255 - accuracy: 0.4633 - val_mse_loss: 183.9618 - val_total_loss: 8.3226 - val_loss1: 4.6276 - val_loss2: 3.6950 - val_reconstruction_loss: -499.0562 - val_accuracy: 0.4796\n",
      "Epoch 297/300\n",
      "59/59 [==============================] - 3s 48ms/step - mse_loss: 36.7680 - total_loss: 4.6327 - loss1: 1.0085 - loss2: 3.6242 - reconstruction_loss: -583.3368 - accuracy: 0.4630 - val_mse_loss: 200.4799 - val_total_loss: 8.7456 - val_loss1: 5.0518 - val_loss2: 3.6938 - val_reconstruction_loss: -498.1022 - val_accuracy: 0.4943\n",
      "Epoch 298/300\n",
      "59/59 [==============================] - 2s 40ms/step - mse_loss: 36.4744 - total_loss: 4.6273 - loss1: 1.0133 - loss2: 3.6139 - reconstruction_loss: -584.8558 - accuracy: 0.4653 - val_mse_loss: 178.6048 - val_total_loss: 8.3856 - val_loss1: 4.7461 - val_loss2: 3.6394 - val_reconstruction_loss: -498.9751 - val_accuracy: 0.4825\n",
      "Epoch 299/300\n",
      "59/59 [==============================] - 3s 50ms/step - mse_loss: 34.9314 - total_loss: 4.5890 - loss1: 1.0083 - loss2: 3.5808 - reconstruction_loss: -596.6460 - accuracy: 0.4657 - val_mse_loss: 172.7854 - val_total_loss: 9.2061 - val_loss1: 5.8083 - val_loss2: 3.3978 - val_reconstruction_loss: -499.5015 - val_accuracy: 0.4874\n",
      "Epoch 300/300\n",
      "59/59 [==============================] - 3s 46ms/step - mse_loss: 36.4818 - total_loss: 4.6237 - loss1: 1.0080 - loss2: 3.6157 - reconstruction_loss: -598.4609 - accuracy: 0.4647 - val_mse_loss: 180.1942 - val_total_loss: 10.7350 - val_loss1: 7.5432 - val_loss2: 3.1918 - val_reconstruction_loss: -498.9379 - val_accuracy: 0.4913\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    if model_is_VAE:\n",
    "        model = VAE(False, input_shape, multiplier, latent_size)\n",
    "    else:\n",
    "        model = UPAE(True, input_shape, multiplier, latent_size)\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model.build(input_shape=(None,) + tuple(input_shape))\n",
    "\n",
    "    model.compile(optimizer= optimizer, loss='mse'\n",
    "                  ,metrics=[tf.keras.metrics.Accuracy()])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    try:\n",
    "        model.load_weights(model_file_path + \"/model_weights\")\n",
    "    except:\n",
    "        train_data = image_datasets['train']\n",
    "        validation_data = image_datasets['valid']\n",
    "\n",
    "        # Where images of each epoch will be saved\n",
    "        save_directory = model_file_path + '/callback_images'\n",
    "        save_callback = SaveImageCallback(validation_data, save_directory=save_directory, vae=model_is_VAE)\n",
    "\n",
    "        EarlyStopping_callback = tf.keras.callbacks.EarlyStopping(monitor='mse_loss', patience=30,\n",
    "                                                                  restore_best_weights=True)\n",
    "\n",
    "        history_train = model.fit(train_data, \n",
    "                                epochs=epochs, \n",
    "                                batch_size=batch_size,\n",
    "                                validation_data=(validation_data, validation_data),\n",
    "                                callbacks=[save_callback, EarlyStopping_callback])\n",
    "        \n",
    "        # Saving the model's history\n",
    "        json.dump(history_train.history, open(model_file_path + '/history.json', 'w'))\n",
    "\n",
    "        #Save weights\n",
    "        model.save_weights(model_file_path + '/model_weights')\n",
    "   \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "076f2a29",
   "metadata": {},
   "source": [
    "# Creating of different Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8d99aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory for saving images\n",
    "save_directory = model_file_path + '/plots'\n",
    "if not os.path.exists(save_directory):\n",
    "    os.makedirs(save_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "813a0288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get history of data\n",
    "history = history_train.history\n",
    "\n",
    "def create_plot(history, metric, title, save_name):\n",
    "    x = range(50, len(history[metric]))\n",
    "    plt.plot(x, history[metric][50:], label=metric)\n",
    "    plt.plot(x, history[f'val_{metric}'][50:], label=f'val_{metric}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(metric)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{save_directory}/{save_name}', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "# Check if UPAE or not\n",
    "if model_is_VAE:\n",
    "    # Create plot for mse_loss\n",
    "    create_plot(history, 'mse_loss', 'MSE Loss per Epoch', 'mse_loss.png')\n",
    "    # Create plot for reconstruction_loss\n",
    "    create_plot(history, 'reconstruction_loss', 'Reconstruction Loss per Epoch', 'reconstruction_loss.png')\n",
    "    # Create plot for kl_loss\n",
    "    create_plot(history, 'kl_loss', 'KL Loss per Epoch', 'kl_loss.png')\n",
    "else:\n",
    "    # Create plot for mse_loss\n",
    "    create_plot(history, 'mse_loss', 'MSE Loss per Epoch', 'mse_loss.png')\n",
    "    # Create plot for total loss\n",
    "    create_plot(history, 'total_loss', 'Total Loss per Epoch', 'total_loss.png')\n",
    "    # Create plot for loss1\n",
    "    create_plot(history, 'loss1', 'Loss 1 per Epoch', 'loss1.png')\n",
    "    # Create plot for loss2\n",
    "    create_plot(history, 'loss2', 'Loss 2 per Epoch', 'loss2.png')\n",
    "    # Create plot for binary_crossentropy\n",
    "#     create_plot(history, 'reconstruction_loss', 'Reconstruction Loss per Epoch', 'reconstruction_loss.png')\n",
    "#     # Create plot for accuracy\n",
    "#     create_plot(history, 'accuracy', 'Accuracy per Epoch', 'accuracy.png')\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b73f60ee",
   "metadata": {},
   "source": [
    "# Testing of the Model with the Test Set\n",
    "This section tests the model with the current test set\n",
    "TODO: \n",
    "- Get the label of each image in the test set\n",
    "- Test the images\n",
    "- Create Linear Regression for the abnormality score to get the threshold for determining abnormal or normal images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fbf61ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get labels of each image in the image_datasets['test']\n",
    "test_images = []\n",
    "labels = []\n",
    "for image_path in glob.glob(f'{dataset_file_path}/test/*.png'):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Get if it contains positive or negative\n",
    "    if 'positive' in image_path:\n",
    "        test_images.append(image)\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        test_images.append(image)\n",
    "        labels.append(0)\n",
    "test_images = np.array(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7071dba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_valid = model.predict(image_datasets['test'], batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddf1a839",
   "metadata": {},
   "outputs": [],
   "source": [
    "abnor_scores = history_valid[1]\n",
    "#converting to an array of numbers instead of tensor\n",
    "abnor_scores = [item.numpy() for item in abnor_scores if isinstance(item, tf.Tensor)]\n",
    "abnor_scores = [float(item) for item in abnor_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "982d20ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = metrics.roc_auc_score(labels, abnor_scores)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(labels, abnor_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51b41e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting roc_curve output\n",
    "fpr, tpr, thresholds = metrics.roc_curve(labels, abnor_scores)\n",
    "idx = None\n",
    "\n",
    "#Computation for the threshold\n",
    "lowest = 1 - tpr[0]\n",
    "lowest = abs(fpr[0] - lowest)\n",
    "for i in range(len(fpr)):\n",
    "    fnr = 1 - tpr[i]\n",
    "    curr_value = abs(fpr[i] - fnr)\n",
    "    if curr_value < lowest:\n",
    "        idx = i\n",
    "        break\n",
    "assert idx is not None\n",
    "t = thresholds[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f33476c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate: 0.01098901098901099\n",
      "Precision: 0.0\n",
      "Sensitivity: 0.0\n",
      "Specificity: 0.989010989010989\n",
      "F1 score: 0.0\n"
     ]
    }
   ],
   "source": [
    "#using threshold t , will be used to classify abnormality scores as normal or abnormal in the y_pred array;\n",
    "y_pred = np.zeros_like(labels)\n",
    "y_pred[abnor_scores < t] = 0\n",
    "y_pred[abnor_scores >= t] = 1\n",
    "\n",
    "\n",
    "# getting metrics score using y_pred which is now either 0  or 1\n",
    "pres = metrics.precision_score(labels, y_pred)\n",
    "sens = metrics.recall_score(labels, y_pred, pos_label=1)\n",
    "spec = metrics.recall_score(labels, y_pred, pos_label=0)\n",
    "f1 = metrics.f1_score(labels, y_pred)\n",
    "error_rate = fpr[idx]\n",
    "\n",
    "metrics_dict = {\n",
    "    \"Error rate\": error_rate,\n",
    "    \"Precision\": pres,\n",
    "    \"Sensitivity\": sens,\n",
    "    \"Specificity\": spec,\n",
    "    \"F1 score\": f1\n",
    "}\n",
    "\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Error rate: {}\".format(error_rate))\n",
    "print(\"Precision: {}\".format(pres))\n",
    "print(\"Sensitivity: {}\".format(sens))\n",
    "print(\"Specificity: {}\".format(spec))\n",
    "print(\"F1 score: {}\".format(f1))\n",
    "\n",
    "# Save the metrics to a JSON file\n",
    "with open(f\"{save_directory}/metrics.json\", \"w\") as json_file:\n",
    "    json.dump(metrics_dict, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f99154c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/UPAE/dataset_2_quantization/plots\n"
     ]
    }
   ],
   "source": [
    "print(save_directory)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e380c523",
   "metadata": {},
   "source": [
    "# Creating Plot for abnormality scores of normal and abnormal images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ed22a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histogram for Positives and Negatives of the testing set\n",
    "positive = []\n",
    "negative = []\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] == 1:\n",
    "        positive.append(abnor_scores[i])\n",
    "    else:\n",
    "        negative.append(abnor_scores[i])\n",
    "plt.hist(negative, color='blue', label='negative', bins=20)\n",
    "plt.hist(positive, color='red', label='positive',bins=20)\n",
    "# Get x and y labels\n",
    "plt.xlabel('Abnormality Score')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title(\"Abnormality Score and Correct Label Histogram\")\n",
    "plt.legend()\n",
    "plt.savefig(f'{save_directory}/testing_abnormality_scores.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dca7b6b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "positive = []\n",
    "negative = []\n",
    "for i in range(len(labels)):\n",
    "    if abnor_scores[i] == 1:\n",
    "        positive.append(abnor_scores[i])\n",
    "    else:\n",
    "        negative.append(abnor_scores[i])\n",
    "plt.hist(negative, color='blue', label='negative', bins=20)\n",
    "plt.hist(positive, color='red', label='positive', bins=20)\n",
    "# Get x and y labels\n",
    "plt.xlabel('Abnormality Score')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title(\"Abnormality Score and Prediction Label Histogram\")\n",
    "plt.legend()\n",
    "plt.savefig(f'{save_directory}/testing_abnormality_scores_prediction.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f5369b0",
   "metadata": {},
   "source": [
    "# Saving of final reconstructed images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "154822a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory in models folder for reconstructed images\n",
    "dataset_name = dataset_file_path.split('/')[-1]\n",
    "reconstructed_images_path = model_file_path + \"/\" + dataset_name\n",
    "if not path.exists(reconstructed_images_path):\n",
    "    mkdir(reconstructed_images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "597def40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_compared_reconstructed_image(original_image, reconstructed_image, abnormality_score, file_path, image_index,\n",
    "                                      label, variance = None):\n",
    "    # Put Images in cv2\n",
    "    original_image = cv2.cvtColor(original_image, cv2.COLOR_GRAY2BGR)\n",
    "    reconstructed_image = cv2.cvtColor(reconstructed_image, cv2.COLOR_GRAY2BGR)\n",
    "    # Convert reconstructed image to uint8\n",
    "    reconstructed_image = reconstructed_image.astype(np.uint8)\n",
    "    if variance is not None:\n",
    "        variance_image = cv2.cvtColor(variance, cv2.COLOR_GRAY2BGR)\n",
    "        variance_image = variance_image.astype(np.uint8)\n",
    "        concatenated_img = cv2.hconcat((original_image, reconstructed_image, variance_image))\n",
    "    else:\n",
    "        concatenated_img = cv2.hconcat([original_image, reconstructed_image])\n",
    "    # Save the image\n",
    "    cv2.imwrite(f'{file_path}/Image_{image_index}_{abnormality_score}_{label}.png', concatenated_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d30e1b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_images)):\n",
    "    if model_is_VAE:\n",
    "        save_compared_reconstructed_image(test_images[i], np.array(history_valid[0][i]), history_valid[1][i],\n",
    "                                      reconstructed_images_path, i, labels[i])\n",
    "    else:\n",
    "        save_compared_reconstructed_image(test_images[i], np.array(history_valid[0][i]), history_valid[1][i],\n",
    "                                      reconstructed_images_path, i, labels[i],  np.array(history_valid[2][i]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d41fb188",
   "metadata": {},
   "source": [
    "# GIF for Callback_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70d17c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_epoch(filename):\n",
    "    match = re.search(r'epoch_(\\d+)', filename)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return 0\n",
    "\n",
    "def create_gif(folder_path, output_path, duration=50):\n",
    "    images = []\n",
    "    \n",
    "    # Get all image file names from the folder\n",
    "    filenames = os.listdir(folder_path)\n",
    "    filenames = sorted(filenames, key=lambda x: extract_epoch(x))\n",
    "\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.png') or filename.endswith('.jpg'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            image = Image.open(file_path).convert('P')\n",
    "            images.append(image)\n",
    "    \n",
    "    # Save the images as a GIF\n",
    "    images[0].save(output_path, save_all=True, append_images=images[1:], optimize=False, duration=duration, loop=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dafb861c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating GIF for: image0\n",
      "Creating GIF for: image1\n",
      "Creating GIF for: image2\n"
     ]
    }
   ],
   "source": [
    "gif_folder_path = model_file_path + \"/\" + \"callback_images\"\n",
    "image_folders = ['image0', 'image1', 'image2']\n",
    "\n",
    "for i,folder in enumerate(image_folders):\n",
    "    curr_folder = gif_folder_path + \"/\" + folder\n",
    "    gif_output_path = gif_folder_path + \"/\" + f\"image{i}.gif\"\n",
    "    print(f\"Creating GIF for: image{i}\")\n",
    "    create_gif(curr_folder, gif_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87650927",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f17747",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
