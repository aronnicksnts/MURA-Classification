{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2bc86acd",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b7f7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import MURA\n",
    "import cv2\n",
    "import image_manipulation\n",
    "from multiprocessing import Pool\n",
    "from models import VAE, UPAE\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import preprocessing\n",
    "import json\n",
    "from os import path, mkdir\n",
    "\n",
    "import keras\n",
    "from argparse import ArgumentParser\n",
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "22e578b7",
   "metadata": {},
   "source": [
    "# Model to Run\n",
    "This section lets the user edit on what model parameters to run, the model directory and parameters should exist prior to changing the file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd350f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All editable variables\n",
    "model_file_path = \"models/model_1\"\n",
    "# If preprocessing needs to run\n",
    "run_preprocessing = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b73251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model parameters\n",
    "try:\n",
    "    params = json.load(open(model_file_path + '/parameters.json'))\n",
    "\n",
    "    # Model parameters\n",
    "    multiplier = params['multiplier']\n",
    "    latent_size = params['latent_size']\n",
    "    input_shape = params['input_shape']\n",
    "\n",
    "    # Training parameters\n",
    "    epochs = params['num_epochs']\n",
    "    batch_size = params['batch_size']\n",
    "    learning_rate = params['learning_rate']\n",
    "\n",
    "    # Dataset Path\n",
    "    image_paths = MURA.MURA_DATASET()\n",
    "    dataset_file_path = params['dataset_path']\n",
    "    all_image_paths = image_paths.get_combined_image_paths()\n",
    "    all_image_paths = all_image_paths.to_numpy()[:,0]\n",
    "except:\n",
    "    raise Exception(\"No parameters.json file found in the model's directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd25378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do preprocessing\n",
    "if run_preprocessing:\n",
    "    preprocess = preprocessing.preprocessing(input_path = all_image_paths, output_path = dataset_file_path)\n",
    "    if __name__ == '__main__':\n",
    "        preprocess.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894555aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each array contains the training, validation, and testing in order\n",
    "image_datasets = {'train': [],\n",
    "                'valid': [],\n",
    "                'test': []}\n",
    "for dataset_name in image_datasets.keys():\n",
    "    for image_path in glob.glob(f'{dataset_file_path}/{dataset_name}/*.png'):\n",
    "        image_datasets[dataset_name].append(cv2.imread(image_path))\n",
    "    image_datasets[dataset_name] = np.array(image_datasets[dataset_name])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f69e69d0",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "This section creates and trains the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f906dcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    #for either VAE or UPAE\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument('--u', dest='u', action='store_true') # use uncertainty\n",
    "    opt, unknown = parser.parse_known_args()\n",
    "\n",
    "    #preprocessing and augmentation\n",
    "    # image_datasets = data_preparation()\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    if opt.u is False:\n",
    "        model = VAE(opt.u, input_shape, multiplier, latent_size)\n",
    "    elif opt.u is True:\n",
    "        model = UPAE(opt.u, input_shape, multiplier, latent_size)\n",
    "\n",
    "    model.build(input_shape=(None, 64, 64, 3))\n",
    "\n",
    "    model.compile(optimizer= optimizer\n",
    "                  ,metrics=[tf.keras.metrics.Accuracy()])\n",
    "\n",
    "\n",
    "    # plot_model(model, 'autoencoder_compress.png', show_shapes=True)\n",
    "    #training on training set.\n",
    "    history_train = model.fit(image_datasets['train'], \n",
    "                epochs=epochs, \n",
    "                batch_size=batch_size)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a96a1d3c",
   "metadata": {},
   "source": [
    "# Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7071dba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_valid = model.predict(image_datasets['valid'], batch_size=batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "353efa2a",
   "metadata": {},
   "source": [
    "# Plots Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b363b159",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = history_train.history['binary_crossentropy: ']\n",
    "# valid_loss = history_valid.history['binary_crossentropy: ']\n",
    "\n",
    "plt.plot(train_loss , label='train')\n",
    "# plt.plot(valid_loss , label='test')\n",
    "plt.title('Train vs Validation Loss')\n",
    "plt.ylabel('Reconstruction Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f5369b0",
   "metadata": {},
   "source": [
    "# Saving of final reconstructed images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154822a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory in models folder for reconstructed images\n",
    "dataset_name = dataset_file_path.split('/')[-1]\n",
    "reconstructed_images_path = model_file_path + \"/\" + dataset_name\n",
    "if not path.exists(reconstructed_images_path):\n",
    "    mkdir(reconstructed_images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7d13db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(len(history_valid)):\n",
    "    fig, axs = plt.subplots(1,2, figsize=(8,4))\n",
    "    axs[0].imshow(image_datasets['valid'][x])\n",
    "    axs[0].set_title('Original Image')\n",
    "    new_image = np.clip(np.floor(history_valid[x]), 0, 255).astype(np.uint8)\n",
    "    axs[1].imshow(new_image)\n",
    "    axs[1].set_title('Reconstructed Image')\n",
    "    plt.savefig(f'{reconstructed_images_path}/Valid_Image_{x}.png')\n",
    "    plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72b430df",
   "metadata": {},
   "source": [
    "# Saving of Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324861d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(model_file_path + '/model_weights.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f90fc7ab",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
